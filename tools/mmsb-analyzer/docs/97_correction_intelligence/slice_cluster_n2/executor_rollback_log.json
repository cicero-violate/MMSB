{
  "version": "1.0",
  "timestamp": "2026-01-01T05:52:25.501087200+00:00",
  "actions": [
    {
      "action_id": "move_emit_verification_policy_to_src/620_correction_plan_serializer.rs",
      "mutations": [],
      "applied": true,
      "errors": []
    },
    {
      "action_id": "move_write_intelligence_outputs_to_src/620_correction_plan_serializer.rs",
      "mutations": [],
      "applied": false,
      "errors": []
    },
    {
      "action_id": "move_strip_numeric_prefix_to_src/330_report.rs",
      "mutations": [],
      "applied": true,
      "errors": []
    },
    {
      "action_id": "move_compress_path_to_src/330_report.rs",
      "mutations": [],
      "applied": false,
      "errors": []
    },
    {
      "action_id": "move_collect_directory_files_to_src/330_report.rs",
      "mutations": [],
      "applied": false,
      "errors": []
    },
    {
      "action_id": "move_path_common_prefix_len_to_src/330_report.rs",
      "mutations": [],
      "applied": false,
      "errors": []
    },
    {
      "action_id": "move_compute_move_metrics_to_src/330_report.rs",
      "mutations": [],
      "applied": true,
      "errors": []
    },
    {
      "action_id": "move_generate_canonical_name_to_src/330_report.rs",
      "mutations": [],
      "applied": false,
      "errors": []
    },
    {
      "action_id": "move_collect_directory_moves_to_src/330_report.rs",
      "mutations": [],
      "applied": true,
      "errors": []
    },
    {
      "action_id": "move_write_structural_batches_to_src/330_report.rs",
      "mutations": [],
      "applied": true,
      "errors": []
    },
    {
      "action_id": "move_write_cluster_batches_to_src/330_report.rs",
      "mutations": [],
      "applied": true,
      "errors": []
    },
    {
      "action_id": "move_resolve_required_layer_path_to_src/330_report.rs",
      "mutations": [],
      "applied": true,
      "errors": []
    },
    {
      "action_id": "move_collect_move_items_to_src/330_report.rs",
      "mutations": [
        {
          "type": "FileEdit",
          "path": "tools/mmsb-analyzer/src/220_utilities.rs",
          "original_content": "//! Utility functions shared across modules\n\nuse std::collections::{BTreeSet};\nuse std::path::{Path};\nuse crate::types::{DirectoryAnalysis, FunctionPlacement, PlacementStatus};\nuse crate::report::{PlanItem, Priority, ActionKind};\n#[allow(unused_imports)] pub use crate::report::resolve_required_layer_path;\n#[allow(unused_imports)] pub use crate::report::write_cluster_batches;\n#[allow(unused_imports)] pub use crate::report::write_structural_batches;\n#[allow(unused_imports)] pub use crate::report::compute_move_metrics;\n#[allow(unused_imports)] pub use crate::report::path_common_prefix_len;\n#[allow(unused_imports)] pub use crate::report::collect_directory_files;\n/// Compress absolute paths to MMSB-relative format\n#[allow(unused_imports)] pub use crate::report::compress_path;\n\n\n// Layer helpers live in 070_layer_utilities.rs.\n\n\n\n\n\n\n\n\n\npub fn collect_move_items(\n    placements: &[FunctionPlacement],\n    utility_names: &BTreeSet<String>,\n    directory: &DirectoryAnalysis,\n    root_path: &Path,\n) -> Vec<PlanItem> {\n    let mut items = Vec::new();\n    for placement in placements {\n        match &placement.placement_status {\n            PlacementStatus::ShouldMove { reason, impact } => {\n                let priority = if *impact >= 0.5 {\n                    Priority::Critical\n                } else if *impact >= 0.2 {\n                    Priority::High\n                } else if *impact >= 0.1 {\n                    Priority::Medium\n                } else {\n                    Priority::Low\n                };\n                let (impact_weight, benefit, cost, callers, caller_files, outgoing_files) =\n                    compute_move_metrics(placement);\n                let to = placement\n                    .suggested_file\n                    .as_ref()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .unwrap_or_else(|| \"-\".to_string());\n                items.push(PlanItem {\n                    kind: ActionKind::Cohesion,\n                    priority,\n                    description: format!(\n                        \"`{}` from `{}` to `{}`: {} (impact {:.2})\",\n                        placement.name,\n                        compress_path(placement.current_file.to_string_lossy().as_ref()),\n                        to,\n                        reason,\n                        impact\n                    ),\n                    command: String::new(),\n                    current_layer: None,\n                    required_layer: None,\n                    is_utility: utility_names.contains(&placement.name),\n                    impact_weight,\n                    benefit,\n                    cost,\n                    callers,\n                    caller_files,\n                    current_file: Some(placement.current_file.clone()),\n                    target_file: placement.suggested_file.clone(),\n                    outgoing_files,\n                    name: Some(placement.name.clone()),\n                    cluster_cohesion: 0.0,\n                    member_count: 0,\n                });\n            }\n            PlacementStatus::LayerViolation {\n                current_layer,\n                required_layer,\n            } => {\n                let target_path = resolve_required_layer_path(\n                    required_layer,\n                    &placement.current_file,\n                    directory,\n                    root_path,\n                );\n                let to = compress_path(target_path.to_string_lossy().as_ref());\n                let (impact_weight, benefit, cost, callers, caller_files, outgoing_files) =\n                    compute_move_metrics(placement);\n                items.push(PlanItem {\n                    kind: ActionKind::Structural,\n                    priority: Priority::Critical,\n                    description: format!(\n                        \"`{}` from `{}` to `{}`: layer violation {} -> {}\",\n                        placement.name,\n                        compress_path(placement.current_file.to_string_lossy().as_ref()),\n                        to,\n                        current_layer,\n                        required_layer\n                    ),\n                    command: String::new(),\n                    current_layer: Some(current_layer.clone()),\n                    required_layer: Some(required_layer.clone()),\n                    is_utility: utility_names.contains(&placement.name),\n                    impact_weight,\n                    benefit,\n                    cost,\n                    callers,\n                    caller_files,\n                    current_file: Some(placement.current_file.clone()),\n                    target_file: Some(target_path),\n                    outgoing_files,\n                    name: Some(placement.name.clone()),\n                    cluster_cohesion: 0.0,\n                    member_count: 0,\n                });\n            }\n            _ => {}\n        }\n    }\n    items\n}\n\n\n\n",
          "updated_content": "//! Utility functions shared across modules\n\n#[allow(unused_imports)] pub use crate::report::collect_move_items;\n#[allow(unused_imports)] pub use crate::report::resolve_required_layer_path;\n#[allow(unused_imports)] pub use crate::report::write_cluster_batches;\n#[allow(unused_imports)] pub use crate::report::write_structural_batches;\n#[allow(unused_imports)] pub use crate::report::compute_move_metrics;\n#[allow(unused_imports)] pub use crate::report::path_common_prefix_len;\n#[allow(unused_imports)] pub use crate::report::collect_directory_files;\n/// Compress absolute paths to MMSB-relative format\n#[allow(unused_imports)] pub use crate::report::compress_path;\n\n\n// Layer helpers live in 070_layer_utilities.rs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
        },
        {
          "type": "FileEdit",
          "path": "tools/mmsb-analyzer/src/330_report.rs",
          "original_content": "//! Markdown report generation\n\nuse crate::cluster_008::collect_cluster_plans;\nuse crate::layer_core::{sort_structural_items};\nuse crate::utilities::{collect_move_items};\nuse crate::control_flow::ControlFlowAnalyzer;\nuse crate::dependency::{LayerGraph, build_directory_entry_map, build_file_dependency_graph, collect_naming_warnings};\nuse crate::file_ordering::DirectoryMove;\nuse crate::types::{\n    AnalysisResult,\n    CallGraphNode,\n    CodeElement,\n    DirectoryAnalysis,\n    ElementType,\n    FileOrderingResult,\n    FunctionCfg,\n    FunctionCluster,\n    FunctionPlacement,\n    Language,\n    PlacementStatus,\n    Visibility,\n};\nuse std::cmp::Ordering;\nuse std::collections::{BTreeMap, BTreeSet, HashMap, HashSet};\nuse std::fs;\nuse std::path::{Path, PathBuf};\nuse walkdir::WalkDir;\nuse crate::cluster_006::strip_numeric_prefix;\n\ntype Result<T> = anyhow::Result<T>;\nfn display_path(path: &Path, root_path: &Path) -> String {\n    let relative = path.strip_prefix(root_path).unwrap_or(path);\n    relative.to_string_lossy().to_string()\n}\n\nfn placement_status_label(status: &PlacementStatus) -> String {\n    match status {\n        PlacementStatus::Correct => \"ok\".to_string(),\n        PlacementStatus::ShouldMove { .. } => \"move\".to_string(),\n        PlacementStatus::Orphaned { .. } => \"orphaned\".to_string(),\n        PlacementStatus::LayerViolation { .. } => \"layer violation\".to_string(),\n    }\n}\n\nfn placement_status_notes(status: &PlacementStatus) -> String {\n    match status {\n        PlacementStatus::Correct => String::new(),\n        PlacementStatus::ShouldMove { reason, impact } => {\n            format!(\"{} (impact {:.2})\", reason, impact)\n        }\n        PlacementStatus::Orphaned { suggested_module } => {\n            format!(\"suggest module {}\", suggested_module)\n        }\n        PlacementStatus::LayerViolation {\n            current_layer,\n            required_layer,\n        } => format!(\"{} -> {}\", current_layer, required_layer),\n    }\n}\n\n#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd)]\npub enum Priority {\n    Critical,\n    High,\n    Medium,\n    Low,\n}\n\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum ActionKind {\n    Cluster,\n    Structural,\n    Cohesion,\n    Ordering,\n}\n\n#[derive(Clone)]\npub struct PlanItem {\n    pub kind: ActionKind,\n    pub priority: Priority,\n    pub description: String,\n    pub command: String,\n    pub current_layer: Option<String>,\n    pub required_layer: Option<String>,\n    pub is_utility: bool,\n    pub impact_weight: usize,\n    pub benefit: usize,\n    pub cost: usize,\n    pub callers: usize,\n    pub caller_files: Vec<PathBuf>,\n    pub current_file: Option<PathBuf>,\n    pub target_file: Option<PathBuf>,\n    pub outgoing_files: Vec<PathBuf>,\n    pub name: Option<String>,\n    pub cluster_cohesion: f64,\n    pub member_count: usize,\n}\n\n#[derive(Clone)]\npub struct ClusterMember {\n    pub file: PathBuf,\n    pub name: String,\n}\n\n#[derive(Clone)]\npub struct ClusterPlan {\n    pub target: PathBuf,\n    pub cohesion: f64,\n    pub members: Vec<ClusterMember>,\n}\n\nfn collect_rename_items(ordering: &FileOrderingResult, label: &str) -> Vec<PlanItem> {\n    let mut layer_violation_files = BTreeSet::new();\n    for violation in &ordering.layer_violations {\n        layer_violation_files.insert(violation.to.clone());\n    }\n\n    ordering\n        .ordered_files\n        .iter()\n        .filter(|entry| entry.needs_rename)\n        .map(|entry| {\n            let from = entry.current_path.clone();\n            let to = entry\n                .current_path\n                .parent()\n                .map(|p| p.join(&entry.suggested_name))\n                .unwrap_or_else(|| PathBuf::from(&entry.suggested_name));\n            let priority = if layer_violation_files.contains(&entry.current_path) {\n                Priority::Critical\n            } else {\n                Priority::Medium\n            };\n            PlanItem {\n                kind: ActionKind::Ordering,\n                priority,\n                description: format!(\n                    \"[{}] `{}` -> `{}`\",\n                    label,\n                    compress_path(from.to_string_lossy().as_ref()),\n                    compress_path(to.to_string_lossy().as_ref())\n                ),\n                command: format!(\n                    \"git mv \\\"{}\\\" \\\"{}\\\"\",\n                    from.to_string_lossy(),\n                    to.to_string_lossy()\n                ),\n                current_layer: None,\n                required_layer: None,\n                is_utility: false,\n                impact_weight: 0,\n                benefit: 0,\n                cost: 1,\n                callers: 0,\n                caller_files: Vec::new(),\n                current_file: Some(from.clone()),\n                target_file: Some(to.clone()),\n                outgoing_files: Vec::new(),\n                name: None,\n                cluster_cohesion: 0.0,\n                member_count: 0,\n            }\n        })\n        .collect()\n}\n\nfn collect_utility_candidates(placements: &[FunctionPlacement]) -> Vec<String> {\n    let mut candidates = BTreeSet::new();\n    for placement in placements {\n        let external_files = placement.call_analysis.calls_from_other_files.len();\n        if external_files >= 3 {\n            candidates.insert(format!(\n                \"`{}` called by {} files (suggest `utilities`)\",\n                placement.name, external_files\n            ));\n        }\n    }\n    candidates.into_iter().collect()\n}\n\nfn directory_moves_to_plan(label: &str, moves: Vec<DirectoryMove>) -> Vec<PlanItem> {\n    moves\n        .into_iter()\n        .map(|item| PlanItem {\n            kind: ActionKind::Ordering,\n            priority: Priority::Medium,\n            description: format!(\n                \"[{}] dir `{}` -> `{}`\",\n                label,\n                compress_path(item.from.to_string_lossy().as_ref()),\n                compress_path(item.to.to_string_lossy().as_ref())\n            ),\n            command: format!(\n                \"git mv \\\"{}\\\" \\\"{}\\\"\",\n                item.from.to_string_lossy(),\n                item.to.to_string_lossy()\n            ),\n            current_layer: None,\n            required_layer: None,\n            is_utility: false,\n            impact_weight: 0,\n            benefit: 0,\n            cost: 1,\n            callers: 0,\n            caller_files: Vec::new(),\n            current_file: Some(item.from.clone()),\n            target_file: Some(item.to.clone()),\n            outgoing_files: Vec::new(),\n            name: None,\n            cluster_cohesion: 0.0,\n            member_count: 0,\n        })\n        .collect()\n}\n\nfn write_priority_section(content: &mut String, title: &str, items: &[PlanItem]) {\n    content.push_str(&format!(\"## {}\\n\\n\", title));\n    let (action, note) = match title {\n        \"Phase 1: Correctness Blockers\" => (\n            \"fix these first; they block correctness or builds.\",\n            \"empty means no critical blockers detected.\",\n        ),\n        \"Phase 2: Cluster Extraction\" => (\n            \"create the listed cluster files and move the grouped functions.\",\n            \"use the batches below to keep changes small.\",\n        ),\n        \"Phase 3: Structural Constraints\" => (\n            \"resolve the layer violations by moving functions to target modules.\",\n            \"follow batch order to avoid cascading dependency churn.\",\n        ),\n        \"Phase 4: Cohesion Improvements\" => (\n            \"optional: improve cohesion by moving functions to better-fit modules.\",\n            \"safe to defer unless you are actively refactoring.\",\n        ),\n        \"Phase 5: Ordering & Renames\" => (\n            \"optional: rename files to match ordering conventions.\",\n            \"update module paths and imports after renames.\",\n        ),\n        _ => (\"review items\", \"no additional guidance available.\"),\n    };\n    content.push_str(&format!(\"Action: {}\\n\", action));\n    content.push_str(&format!(\"Note: {}\\n\\n\", note));\n    if items.is_empty() {\n        content.push_str(\"- None.\\n\\n\");\n        return;\n    }\n\n    let mut commands = Vec::new();\n    for item in items {\n        content.push_str(&format!(\"- {}\\n\", item.description));\n        if !item.command.is_empty() {\n            commands.push(item.command.clone());\n        }\n    }\n    content.push('\\n');\n\n    if !commands.is_empty() {\n        content.push_str(\"```bash\\n\");\n        for cmd in commands {\n            content.push_str(&format!(\"{}\\n\", cmd));\n        }\n        content.push_str(\"```\\n\\n\");\n    }\n}\n\nfn write_structural_tips(content: &mut String, items: &[PlanItem]) {\n    if items.is_empty() {\n        return;\n    }\n    content.push_str(\"### Phase 3 Tips\\n\\n\");\n    content.push_str(\"Action: apply these guidelines while executing Phase 3 batches.\\n\");\n    content.push_str(\"Note: these are advisory, not checklist items.\\n\\n\");\n    content.push_str(\"- Move lowest-layer helpers first; higher layers should depend on stable primitives.\\n\");\n    content.push_str(\"- Keep moves small: move one function + update imports + rerun tests.\\n\");\n    content.push_str(\"- If a target module is missing, create it before moving functions.\\n\");\n    content.push_str(\"- Prefer consolidating shared utilities into their destination layer once.\\n\");\n    content.push_str(\"- Avoid touching `_old/` unless explicitly refactoring archives.\\n\\n\");\n}\n\nfn write_cluster_tips(content: &mut String, plans: &[ClusterPlan]) {\n    if plans.is_empty() {\n        return;\n    }\n    content.push_str(\"### Phase 2 Tips\\n\\n\");\n    content.push_str(\"Action: apply these guidelines while executing Phase 2 batches.\\n\");\n    content.push_str(\"Note: these are advisory, not checklist items.\\n\\n\");\n    content.push_str(\"- Extract clusters as a unit; avoid splitting a cluster across files.\\n\");\n    content.push_str(\"- Prefer creating new files before moving functions to keep diffs small.\\n\");\n    content.push_str(\"- After each batch, update imports and run tests to lock in behavior.\\n\\n\");\n}\n\nfn sort_plan_items(items: &mut Vec<PlanItem>) {\n    items.sort_by(|a, b| {\n        a.priority\n            .cmp(&b.priority)\n            .then_with(|| a.description.cmp(&b.description))\n    });\n}\n\nfn sort_cluster_items(items: &mut Vec<PlanItem>) {\n    items.sort_by(|a, b| {\n        b.cluster_cohesion\n            .partial_cmp(&a.cluster_cohesion)\n            .unwrap_or(Ordering::Equal)\n            .then_with(|| b.member_count.cmp(&a.member_count))\n            .then_with(|| a.description.cmp(&b.description))\n    });\n}\n\nfn cluster_priority(cohesion: f64) -> Priority {\n    if cohesion >= 0.8 {\n        Priority::Critical\n    } else if cohesion >= 0.6 {\n        Priority::High\n    } else if cohesion >= 0.4 {\n        Priority::Medium\n    } else {\n        Priority::Low\n    }\n}\n\nfn collect_cluster_items(plans: &[ClusterPlan]) -> Vec<PlanItem> {\n    plans\n        .iter()\n        .map(|plan| PlanItem {\n            kind: ActionKind::Cluster,\n            priority: cluster_priority(plan.cohesion),\n            description: format!(\n                \"Create cluster file `{}` with {} functions (cohesion {:.2})\",\n                compress_path(plan.target.to_string_lossy().as_ref()),\n                plan.members.len(),\n                plan.cohesion\n            ),\n            command: format!(\"touch \\\"{}\\\"\", plan.target.to_string_lossy()),\n            current_layer: None,\n            required_layer: None,\n            is_utility: false,\n            impact_weight: 0,\n            benefit: 0,\n            cost: 1,\n            callers: 0,\n            caller_files: Vec::new(),\n            current_file: None,\n            target_file: Some(plan.target.clone()),\n            outgoing_files: Vec::new(),\n            name: None,\n            cluster_cohesion: plan.cohesion,\n            member_count: plan.members.len(),\n        })\n        .collect()\n}\n\nfn collect_refactor_actions(\n    result: &AnalysisResult,\n    rust_ordering: &FileOrderingResult,\n    julia_ordering: &FileOrderingResult,\n    placements: &[FunctionPlacement],\n    clusters: &[FunctionCluster],\n    directory: &DirectoryAnalysis,\n    root_path: &Path,\n) -> Vec<crate::correction_plan_types::RefactorAction> {\n    let mut actions = Vec::new();\n\n    let mut renames = collect_rename_items(rust_ordering, \"Rust\")\n        .into_iter()\n        .chain(collect_rename_items(julia_ordering, \"Julia\"))\n        .collect::<Vec<_>>();\n    renames.extend(directory_moves_to_plan(\n        \"Rust\",\n        collect_directory_moves(rust_ordering, root_path),\n    ));\n    renames.extend(directory_moves_to_plan(\n        \"Julia\",\n        collect_directory_moves(julia_ordering, root_path),\n    ));\n\n    let cluster_plans = collect_cluster_plans(clusters, root_path);\n    let cluster_items = collect_cluster_items(&cluster_plans);\n\n    let mut utility_names = BTreeSet::new();\n    for placement in placements {\n        if placement.call_analysis.calls_from_other_files.len() >= 3 {\n            utility_names.insert(placement.name.clone());\n        }\n    }\n    let moves = collect_move_items(placements, &utility_names, directory, root_path);\n\n    for item in renames {\n        if let (Some(from), Some(to)) = (item.current_file, item.target_file) {\n            if !from.exists() {\n                continue;\n            }\n            actions.push(crate::correction_plan_types::RefactorAction::RenameFile { from, to });\n        }\n    }\n    for item in cluster_items {\n        if let Some(path) = item.target_file {\n            actions.push(crate::correction_plan_types::RefactorAction::CreateFile { path });\n        }\n    }\n    for item in moves {\n        if let (Some(name), Some(from), Some(to)) =\n            (item.name.clone(), item.current_file, item.target_file)\n        {\n            actions.push(crate::correction_plan_types::RefactorAction::MoveFunction {\n                function: name,\n                from,\n                to,\n                required_layer: item.required_layer.clone(),\n            });\n        }\n    }\n\n    actions.extend(collect_visibility_actions(result));\n    actions\n}\n\nfn collect_visibility_actions(\n    result: &AnalysisResult,\n) -> Vec<crate::correction_plan_types::RefactorAction> {\n    use crate::types::{ElementType, Language, Visibility};\n    use std::collections::HashMap;\n    use std::path::PathBuf;\n\n    let mut actions = Vec::new();\n    let mut element_files: HashMap<String, PathBuf> = HashMap::new();\n    for element in &result.elements {\n        if element.element_type == ElementType::Function && element.language == Language::Rust {\n            element_files.insert(element.name.clone(), PathBuf::from(&element.file_path));\n        }\n    }\n\n    for element in &result.elements {\n        if element.element_type != ElementType::Function || element.language != Language::Rust {\n            continue;\n        }\n        if matches!(element.visibility, Visibility::Private) {\n            continue;\n        }\n        if element.name == \"main\" || element.name.starts_with(\"test_\") {\n            continue;\n        }\n        let file_path = PathBuf::from(&element.file_path);\n        if is_test_file(&file_path) {\n            continue;\n        }\n        let callers = caller_files(&element.name, &result.call_graph, &element_files);\n        if callers.is_empty() {\n            actions.push(crate::correction_plan_types::RefactorAction::AdjustVisibility {\n                symbol: element.name.clone(),\n                file: file_path.clone(),\n                from: element.visibility.clone(),\n                to: element.visibility.clone(),\n                reason: \"review: public symbol with zero callers (possible external API)\"\n                    .to_string(),\n            });\n            continue;\n        }\n        let mut external = false;\n        for caller in &callers {\n            if *caller != file_path {\n                external = true;\n                break;\n            }\n        }\n        if external {\n            continue;\n        }\n\n        let target_visibility = match element.visibility {\n            Visibility::Public => Visibility::Crate,\n            Visibility::Crate => Visibility::Private,\n            Visibility::Private => continue,\n        };\n        if target_visibility == element.visibility {\n            continue;\n        }\n        actions.push(crate::correction_plan_types::RefactorAction::AdjustVisibility {\n            symbol: element.name.clone(),\n            file: file_path.clone(),\n            from: element.visibility.clone(),\n            to: target_visibility,\n            reason: \"only used within file\".to_string(),\n        });\n    }\n\n    actions\n}\n\nfn caller_files(\n    function: &str,\n    call_graph: &std::collections::HashMap<String, CallGraphNode>,\n    element_files: &std::collections::HashMap<String, std::path::PathBuf>,\n) -> std::collections::HashSet<std::path::PathBuf> {\n    let mut files = std::collections::HashSet::new();\n    if let Some(node) = call_graph.get(function) {\n        for caller in &node.called_by {\n            if let Some(file) = element_files.get(caller) {\n                files.insert(file.clone());\n            }\n        }\n    }\n    files\n}\n\nfn is_test_file(path: &std::path::Path) -> bool {\n    if path.components().any(|c| c.as_os_str() == \"tests\") {\n        return true;\n    }\n    path.file_name()\n        .and_then(|n| n.to_str())\n        .map(|name| name.contains(\"_test\") || name.starts_with(\"test_\"))\n        .unwrap_or(false)\n}\n\n\n\nfn build_correction_metrics(\n    placements: &[FunctionPlacement],\n    _directory: &DirectoryAnalysis,\n) -> crate::quality_delta_calculator::Metrics {\n    let cohesion = compute_directory_cohesion(placements);\n    let violations = placements\n        .iter()\n        .filter(|p| matches!(p.placement_status, PlacementStatus::LayerViolation { .. }))\n        .count();\n    crate::quality_delta_calculator::Metrics {\n        cohesion,\n        violations,\n        complexity: 0.0,\n    }\n}\n\nfn load_cargo_warnings(output_dir: &str) -> Option<String> {\n    let path = Path::new(output_dir).join(\"cargo_warnings.txt\");\n    if !path.exists() {\n        return None;\n    }\n    fs::read_to_string(path).ok()\n}\n\nfn parse_dead_code_warnings(warnings: &str) -> HashMap<String, HashSet<PathBuf>> {\n    let mut dead_code = HashMap::new();\n    let mut lines = warnings.lines().peekable();\n    while let Some(line) = lines.next() {\n        let trimmed = line.trim();\n        if !trimmed.starts_with(\"warning:\") {\n            continue;\n        }\n        let Some(name_start) = trimmed.find(\"function `\") else {\n            continue;\n        };\n        let rest = &trimmed[name_start + \"function `\".len()..];\n        let Some(name_end) = rest.find('`') else {\n            continue;\n        };\n        let name = &rest[..name_end];\n        if !trimmed.contains(\"is never used\") {\n            continue;\n        }\n\n        let mut warn_path: Option<PathBuf> = None;\n        if let Some(next) = lines.peek() {\n            let next_trimmed = next.trim();\n            if let Some(path_start) = next_trimmed.find(\"--> \") {\n                let path_part = &next_trimmed[path_start + 4..];\n                if let Some(path_end) = path_part.find(':') {\n                    warn_path = Some(PathBuf::from(&path_part[..path_end]));\n                }\n            }\n        }\n\n        dead_code\n            .entry(name.to_string())\n            .or_insert_with(HashSet::new)\n            .extend(warn_path);\n    }\n    dead_code\n}\n\nfn parse_use_symbols(line: &str) -> Vec<String> {\n    let mut symbols = Vec::new();\n    let Some(use_idx) = line.find(\"use \") else {\n        return symbols;\n    };\n    let mut clause = line[use_idx + 4..].trim();\n    if let Some(end_idx) = clause.find(';') {\n        clause = clause[..end_idx].trim();\n    }\n    clause = clause.strip_prefix(\"crate::\").unwrap_or(clause);\n    clause = clause.strip_prefix(\"self::\").unwrap_or(clause);\n\n    if let Some(brace_start) = clause.find('{') {\n        let brace_end = clause.rfind('}').unwrap_or(clause.len());\n        let inner = &clause[brace_start + 1..brace_end];\n        for item in inner.split(',') {\n            let item = item.trim();\n            if item.is_empty() || item == \"*\" || item == \"self\" || item == \"super\" {\n                continue;\n            }\n            let item = item.split(\" as \").next().unwrap_or(item).trim();\n            let last = item.rsplit(\"::\").next().unwrap_or(item);\n            if !last.is_empty() {\n                symbols.push(last.to_string());\n            }\n        }\n    } else {\n        let last = clause.rsplit(\"::\").next().unwrap_or(clause).trim();\n        if !last.is_empty() && last != \"*\" && last != \"self\" && last != \"super\" {\n            symbols.push(last.to_string());\n        }\n    }\n\n    symbols\n}\n\nfn scan_crate_paths(line: &str) -> Vec<String> {\n    let mut symbols = Vec::new();\n    let mut idx = 0;\n    while let Some(found) = line[idx..].find(\"crate::\") {\n        let start = idx + found + \"crate::\".len();\n        let mut end = start;\n        for ch in line[start..].chars() {\n            if ch.is_ascii_alphanumeric() || ch == '_' || ch == ':' {\n                end += ch.len_utf8();\n            } else {\n                break;\n            }\n        }\n        if end > start {\n            let path = &line[start..end];\n            if let Some(last) = path.rsplit(\"::\").next() {\n                if !last.is_empty() {\n                    symbols.push(last.to_string());\n                }\n            }\n        }\n        idx = end;\n    }\n    symbols\n}\n\nfn collect_symbol_references(root_path: &Path) -> HashMap<String, HashSet<PathBuf>> {\n    let mut references: HashMap<String, HashSet<PathBuf>> = HashMap::new();\n    let src_dir = root_path.join(\"src\");\n    for entry in WalkDir::new(&src_dir).into_iter().filter_map(|e| e.ok()) {\n        let path = entry.path();\n        if !path.is_file() || path.extension().and_then(|e| e.to_str()) != Some(\"rs\") {\n            continue;\n        }\n        let Ok(contents) = fs::read_to_string(path) else {\n            continue;\n        };\n        for line in contents.lines() {\n            if line.contains(\"use crate::\") {\n                for symbol in parse_use_symbols(line) {\n                    references\n                        .entry(symbol)\n                        .or_insert_with(HashSet::new)\n                        .insert(path.to_path_buf());\n                }\n            }\n            if line.contains(\"crate::\") {\n                for symbol in scan_crate_paths(line) {\n                    references\n                        .entry(symbol)\n                        .or_insert_with(HashSet::new)\n                        .insert(path.to_path_buf());\n                }\n            }\n        }\n    }\n    references\n}\n\nfn is_public_function(file_path: &Path, name: &str) -> Option<bool> {\n    let Ok(contents) = fs::read_to_string(file_path) else {\n        return None;\n    };\n    let needle = format!(\"fn {}\", name);\n    for line in contents.lines() {\n        if let Some(pos) = line.find(&needle) {\n            let prefix = line[..pos].trim_start();\n            return Some(prefix.starts_with(\"pub\"));\n        }\n    }\n    None\n}\n\nfn path_matches(entry_path: &Path, candidate: &Path) -> bool {\n    entry_path == candidate || entry_path.ends_with(candidate) || candidate.ends_with(entry_path)\n}\n\nfn is_entrypoint_main(entry: &FunctionPlacement) -> bool {\n    entry.name == \"main\"\n        && entry\n            .current_file\n            .ends_with(Path::new(\"src/190_main.rs\"))\n}\n\nfn referenced_elsewhere(\n    entry: &FunctionPlacement,\n    references: &HashMap<String, HashSet<PathBuf>>,\n) -> bool {\n    let Some(files) = references.get(&entry.name) else {\n        return false;\n    };\n    files\n        .iter()\n        .any(|path| !path_matches(&entry.current_file, path))\n}\n\nfn is_dead_code_candidate(\n    entry: &FunctionPlacement,\n    dead_code: &HashMap<String, HashSet<PathBuf>>,\n) -> bool {\n    let Some(paths) = dead_code.get(&entry.name) else {\n        return false;\n    };\n    if paths.is_empty() {\n        return true;\n    }\n    paths.iter().any(|path| path_matches(&entry.current_file, path))\n}\n\nfn filter_orphaned<'a>(\n    placements: &'a [FunctionPlacement],\n    root_path: &Path,\n    output_dir: &str,\n) -> (Vec<&'a FunctionPlacement>, Vec<&'a FunctionPlacement>) {\n    let references = collect_symbol_references(root_path);\n    let dead_code = load_cargo_warnings(output_dir)\n        .as_deref()\n        .map(parse_dead_code_warnings)\n        .unwrap_or_default();\n\n    let mut orphaned = Vec::new();\n    let mut delete_candidates = Vec::new();\n    for entry in placements\n        .iter()\n        .filter(|p| matches!(p.placement_status, PlacementStatus::Orphaned { .. }))\n    {\n        if is_entrypoint_main(entry) {\n            continue;\n        }\n        if let Some(true) = is_public_function(&entry.current_file, &entry.name) {\n            if referenced_elsewhere(entry, &references) {\n                continue;\n            }\n        }\n        let is_delete_candidate = is_dead_code_candidate(entry, &dead_code);\n        if is_delete_candidate {\n            delete_candidates.push(entry);\n        }\n        orphaned.push(entry);\n    }\n    (orphaned, delete_candidates)\n}\n\n#[derive(Clone, Debug)]\npub struct ReportConfig {\n    pub file_line_warning: usize,\n    pub dir_file_warning: usize,\n    pub naming_score_warning: f64,\n    pub baseline_path: String,\n}\n\nimpl ReportConfig {\n    fn defaults() -> Self {\n        Self {\n            file_line_warning: 800,\n            dir_file_warning: 30,\n            naming_score_warning: 70.0,\n            baseline_path: \"metrics_baseline.txt\".to_string(),\n        }\n    }\n}\n\nfn load_report_config(output_dir: &str) -> ReportConfig {\n    let path = Path::new(output_dir).join(\"analyzer_config.toml\");\n    let mut config = ReportConfig::defaults();\n    let Ok(contents) = fs::read_to_string(path) else {\n        return config;\n    };\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') {\n            continue;\n        }\n        let Some((key, value)) = trimmed.split_once('=') else {\n            continue;\n        };\n        let key = key.trim();\n        let value = value.trim().trim_matches('\"');\n        match key {\n            \"file_line_warning\" => {\n                if let Ok(parsed) = value.parse::<usize>() {\n                    config.file_line_warning = parsed;\n                }\n            }\n            \"dir_file_warning\" => {\n                if let Ok(parsed) = value.parse::<usize>() {\n                    config.dir_file_warning = parsed;\n                }\n            }\n            \"baseline_path\" => {\n                if !value.is_empty() {\n                    config.baseline_path = value.to_string();\n                }\n            }\n            \"naming_score_warning\" => {\n                if let Ok(parsed) = value.parse::<f64>() {\n                    config.naming_score_warning = parsed;\n                }\n            }\n            _ => {}\n        }\n    }\n    config\n}\n\nfn collect_size_warnings(\n    directory: &DirectoryAnalysis,\n    config: &ReportConfig,\n    warnings: &mut Vec<String>,\n) {\n    if directory.files.len() >= config.dir_file_warning {\n        warnings.push(format!(\n            \"Directory `{}` has {} files; consider splitting into submodules.\",\n            compress_path(directory.path.to_string_lossy().as_ref()),\n            directory.files.len()\n        ));\n    }\n\n    for file in &directory.files {\n        if let Ok(contents) = fs::read_to_string(file) {\n            let lines = contents.lines().count();\n            if lines >= config.file_line_warning {\n                warnings.push(format!(\n                    \"File `{}` has {} lines; consider extracting helpers.\",\n                    compress_path(file.to_string_lossy().as_ref()),\n                    lines\n                ));\n            }\n        }\n    }\n\n    for child in &directory.subdirectories {\n        collect_size_warnings(child, config, warnings);\n    }\n}\n\nfn load_baseline_metrics(config: &ReportConfig, output_dir: &str) -> Option<HashMap<String, f64>> {\n    let path = Path::new(output_dir).join(&config.baseline_path);\n    let Ok(contents) = fs::read_to_string(path) else {\n        return None;\n    };\n    let mut metrics = HashMap::new();\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') {\n            continue;\n        }\n        let Some((key, value)) = trimmed.split_once('=') else {\n            continue;\n        };\n        let key = key.trim().to_string();\n        let value = value.trim();\n        if let Ok(parsed) = value.parse::<f64>() {\n            metrics.insert(key, parsed);\n        }\n    }\n    Some(metrics)\n}\n\nfn baseline_deltas(\n    baseline: &HashMap<String, f64>,\n    dir_cohesion: f64,\n    ordering_correctness: f64,\n    avg_cohesion: f64,\n    renames_len: usize,\n    relocations: usize,\n) -> Vec<String> {\n    let mut deltas = Vec::new();\n    if let Some(prev) = baseline.get(\"directory_cohesion\") {\n        deltas.push(format!(\n            \"directory_cohesion: {:.2} -> {:.2} (delta {:+.2})\",\n            prev,\n            dir_cohesion,\n            dir_cohesion - prev\n        ));\n    }\n    if let Some(prev) = baseline.get(\"ordering_correctness\") {\n        let current = ordering_correctness * 100.0;\n        deltas.push(format!(\n            \"ordering_correctness: {:.1}% -> {:.1}% (delta {:+.1}%)\",\n            prev,\n            current,\n            current - prev\n        ));\n    }\n    if let Some(prev) = baseline.get(\"avg_function_cohesion\") {\n        deltas.push(format!(\n            \"avg_function_cohesion: {:.2} -> {:.2} (delta {:+.2})\",\n            prev,\n            avg_cohesion,\n            avg_cohesion - prev\n        ));\n    }\n    if let Some(prev) = baseline.get(\"rename_ops_needed\") {\n        let current = renames_len as f64;\n        deltas.push(format!(\n            \"rename_ops_needed: {:.0} -> {} (delta {:+.0})\",\n            prev,\n            renames_len,\n            current - prev\n        ));\n    }\n    if let Some(prev) = baseline.get(\"function_relocations\") {\n        let current = relocations as f64;\n        deltas.push(format!(\n            \"function_relocations: {:.0} -> {} (delta {:+.0})\",\n            prev,\n            relocations,\n            current - prev\n        ));\n    }\n    deltas\n}\n\nfn write_baseline_metrics(\n    config: &ReportConfig,\n    output_dir: &str,\n    dir_cohesion: f64,\n    ordering_correctness: f64,\n    avg_cohesion: f64,\n    renames_len: usize,\n    relocations: usize,\n) {\n    let path = Path::new(output_dir).join(&config.baseline_path);\n    if path.exists() {\n        return;\n    }\n    let content = format!(\n        \"directory_cohesion={:.2}\\nordering_correctness={:.1}\\navg_function_cohesion={:.2}\\nrename_ops_needed={}\\nfunction_relocations={}\\n\",\n        dir_cohesion,\n        ordering_correctness * 100.0,\n        avg_cohesion,\n        renames_len,\n        relocations\n    );\n    let _ = fs::write(path, content);\n}\n\nfn collect_directories<'a>(node: &'a DirectoryAnalysis, acc: &mut Vec<&'a DirectoryAnalysis>) {\n    acc.push(node);\n    for child in &node.subdirectories {\n        collect_directories(child, acc);\n    }\n}\n\nfn slugify_path(path: &Path) -> String {\n    let mut slug = String::new();\n    for component in path.components() {\n        if !slug.is_empty() {\n            slug.push_str(\"__\");\n        }\n        slug.push_str(&component.as_os_str().to_string_lossy().replace('/', \"_\"));\n    }\n    if slug.is_empty() {\n        \"root\".to_string()\n    } else {\n        slug\n    }\n}\n\nfn render_mermaid_graph(graph: &petgraph::graph::DiGraph<PathBuf, ()>) -> String {\n    let mut output = String::from(\"```mermaid\\ngraph TD\\n\");\n    let mut node_ids: HashMap<usize, String> = HashMap::new();\n    let mut idx = 0usize;\n    for node in graph.node_indices() {\n        let node_name = graph[node]\n            .file_name()\n            .and_then(|n| n.to_str())\n            .unwrap_or(\"file\");\n        let safe_id = format!(\"F{}\", idx);\n        idx += 1;\n        node_ids.insert(node.index(), safe_id.clone());\n        output.push_str(&format!(\"    {}[\\\"{}\\\"]\\n\", safe_id, node_name));\n    }\n    for edge in graph.edge_indices() {\n        if let Some((src, dst)) = graph.edge_endpoints(edge) {\n            if let (Some(from), Some(to)) = (node_ids.get(&src.index()), node_ids.get(&dst.index()))\n            {\n                output.push_str(&format!(\"    {} --> {}\\n\", from, to));\n            }\n        }\n    }\n    output.push_str(\"```\\n\");\n    output\n}\n\nfn compute_ordering_correctness(\n    rust_ordering: &FileOrderingResult,\n    julia_ordering: &FileOrderingResult,\n) -> f64 {\n    let mut total = 0usize;\n    let mut correct = 0usize;\n    for ordering in [rust_ordering, julia_ordering] {\n        total += ordering.ordered_files.len();\n        correct += ordering.ordered_files.len().saturating_sub(ordering.violations.len());\n    }\n    if total == 0 {\n        1.0\n    } else {\n        correct as f64 / total as f64\n    }\n}\n\nfn compute_directory_cohesion(placements: &[FunctionPlacement]) -> f64 {\n    let mut intra = 0usize;\n    let mut inter = 0usize;\n    for placement in placements {\n        let current_dir = placement.current_file.parent().map(|p| p.to_path_buf());\n        intra += placement.call_analysis.intra_file_calls;\n        for (file, count) in &placement.call_analysis.inter_file_calls {\n            let same_dir = current_dir\n                .as_ref()\n                .and_then(|dir| file.parent().map(|p| p == dir))\n                .unwrap_or(false);\n            if same_dir {\n                intra += count;\n            } else {\n                inter += count;\n            }\n        }\n    }\n    let total = intra + inter;\n    if total == 0 {\n        1.0\n    } else {\n        intra as f64 / total as f64\n    }\n}\n\npub struct ReportGenerator {\n    output_dir: String,\n}\n\nimpl ReportGenerator {\n    pub fn new(output_dir: String) -> Self {\n        Self { output_dir }\n    }\n\n    pub fn generate_all(\n        &self,\n        result: &AnalysisResult,\n        cf_analyzer: &ControlFlowAnalyzer,\n        rust_layers: &LayerGraph,\n        julia_layers: &LayerGraph,\n        rust_ordering: &FileOrderingResult,\n        julia_ordering: &FileOrderingResult,\n        function_placements: &[FunctionPlacement],\n        function_clusters: &[FunctionCluster],\n        directory_structure: &DirectoryAnalysis,\n        root_path: &Path,\n        correction_intelligence: bool,\n        correction_json: Option<PathBuf>,\n        verification_policy_json: Option<PathBuf>,\n        correction_path_slice: bool,\n        correction_path_slice_dir: Option<PathBuf>,\n        correction_visibility_slice: bool,\n        correction_visibility_slice_dir: Option<PathBuf>,\n        correction_cluster_slice: Option<usize>,\n        correction_cluster_slice_dir: Option<PathBuf>,\n        correction_cluster_plan: Option<PathBuf>,\n    ) -> Result<()> {\n        fs::create_dir_all(&self.output_dir)?;\n        self.cleanup_legacy_reports()?;\n        let correction_root = Path::new(&self.output_dir).join(\"97_correction_intelligence\");\n\n        println!(\"  Report: structure\");\n        self.generate_structure_report(result)?;\n        println!(\"  Report: call_graph\");\n        self.generate_call_graph_report(cf_analyzer)?;\n        println!(\"  Report: cfg\");\n        self.generate_cfg_report(cf_analyzer)?;\n        println!(\"  Report: module_dependencies\");\n        self.generate_module_dependencies(result)?;\n        println!(\"  Report: module_map_mismatch\");\n        self.generate_module_map_mismatch(root_path)?;\n        println!(\"  Report: test_topology\");\n        self.generate_test_topology(root_path)?;\n        println!(\"  Report: warning_hygiene\");\n        self.generate_warning_hygiene(root_path)?;\n        println!(\"  Report: function_analysis\");\n        self.generate_function_analysis(result)?;\n        println!(\"  Report: layer_dependencies\");\n        self.generate_layer_dependency_report(rust_layers, julia_layers, root_path)?;\n        println!(\"  Report: file_ordering\");\n        self.generate_file_ordering_report(rust_ordering, julia_ordering, root_path)?;\n        println!(\"  Report: cohesion_analysis\");\n        self.generate_cohesion_report(function_placements, function_clusters, root_path)?;\n        println!(\"  Report: refactoring_plan\");\n        let correction_report = if correction_intelligence {\n            let actions = collect_refactor_actions(\n                result,\n                rust_ordering,\n                julia_ordering,\n                function_placements,\n                function_clusters,\n                directory_structure,\n                root_path,\n            );\n            let metrics = build_correction_metrics(function_placements, directory_structure);\n            let state = crate::correction_intelligence_report::build_state(root_path, result, metrics);\n            let report = crate::correction_intelligence_report::generate_intelligence_report(&actions, &state);\n            let output_dir = correction_root.clone();\n            crate::correction_intelligence_report::write_intelligence_outputs_at(\n                &report,\n                &output_dir,\n                correction_json.as_deref(),\n                verification_policy_json.as_deref(),\n            )?;\n            if correction_path_slice {\n                println!(\"  Report: correction_intelligence_path_coherence\");\n                let path_report =\n                    crate::correction_intelligence_report::filter_path_coherence_report(&report);\n                let slice_dir = correction_path_slice_dir.unwrap_or_else(|| {\n                    output_dir.join(\"slice_path_coherence\")\n                });\n                crate::correction_intelligence_report::write_intelligence_outputs_at(\n                    &path_report,\n                    &slice_dir,\n                    None,\n                    None,\n                )?;\n            }\n            if correction_visibility_slice {\n                println!(\"  Report: correction_intelligence_visibility\");\n                let visibility_report =\n                    crate::correction_intelligence_report::filter_visibility_report(&report);\n                let slice_dir = correction_visibility_slice_dir.unwrap_or_else(|| {\n                    output_dir.join(\"slice_visibility\")\n                });\n                crate::correction_intelligence_report::write_intelligence_outputs_at(\n                    &visibility_report,\n                    &slice_dir,\n                    None,\n                    None,\n                )?;\n            }\n            Some(report)\n        } else {\n            None\n        };\n        if let Some(batch_index) = correction_cluster_slice {\n            println!(\"  Report: correction_intelligence_cluster_slice\");\n            let default_plan = root_path.join(\"docs/00_refactoring_plan/04_phase2_clusters.md\");\n            let fallback_plan =\n                root_path.join(\"../mmsb-executor/docs/00_refactoring_plan/04_phase2_clusters.md\");\n            let plan_path = correction_cluster_plan.unwrap_or_else(|| {\n                if default_plan.exists() {\n                    default_plan\n                } else {\n                    fallback_plan\n                }\n            });\n            let slice_dir = correction_cluster_slice_dir.unwrap_or_else(|| {\n                correction_root.join(format!(\"slice_cluster_b{}\", batch_index))\n            });\n            let report = crate::correction_intelligence_report::generate_phase2_cluster_slice(\n                &plan_path,\n                batch_index,\n                root_path,\n            )?;\n            crate::correction_intelligence_report::write_intelligence_outputs_at(\n                &report,\n                &slice_dir,\n                None,\n                None,\n            )?;\n        }\n        self.generate_refactoring_plan(\n            rust_ordering,\n            julia_ordering,\n            function_placements,\n            function_clusters,\n            directory_structure,\n            root_path,\n            correction_report.as_ref(),\n        )?;\n        println!(\"  Report: file_organization\");\n        self.generate_file_organization_report(\n            directory_structure,\n            rust_ordering,\n            julia_ordering,\n            root_path,\n        )?;\n\n        Ok(())\n    }\n\n    fn cleanup_legacy_reports(&self) -> Result<()> {\n        let legacy_files = [\n            \"structure.md\",\n            \"call_graph.md\",\n            \"cfg.md\",\n            \"module_dependencies.md\",\n            \"function_analysis.md\",\n            \"layer_dependencies.md\",\n            \"file_ordering.md\",\n            \"cohesion_analysis.md\",\n            \"refactoring_plan.md\",\n            \"file_organization.md\",\n        ];\n        for file in legacy_files {\n            let path = Path::new(&self.output_dir).join(file);\n            if path.exists() {\n                fs::remove_file(path)?;\n            }\n        }\n        let report_dirs = [\n            \"structure\",\n            \"call_graph\",\n            \"cfg\",\n            \"module_dependencies\",\n            \"function_analysis\",\n            \"layer_dependencies\",\n            \"file_ordering\",\n            \"cohesion_analysis\",\n            \"refactoring_plan\",\n            \"file_organization\",\n            \"10_structure\",\n            \"20_call_graph\",\n            \"30_cfg\",\n            \"40_module_dependencies\",\n            \"41_module_map_mismatch\",\n            \"42_test_topology\",\n            \"43_warning_hygiene\",\n            \"50_function_analysis\",\n            \"60_layer_dependencies\",\n            \"70_file_ordering\",\n            \"80_cohesion_analysis\",\n            \"90_file_organization\",\n        ];\n        for dir in report_dirs {\n            let path = Path::new(&self.output_dir).join(dir);\n            if !path.exists() {\n                continue;\n            }\n            for entry in fs::read_dir(&path)? {\n                let entry = entry?;\n                let entry_path = entry.path();\n                if entry_path.is_dir() {\n                    if dir == \"30_cfg\" && entry_path.file_name().map_or(false, |n| n == \"dots\") {\n                        continue;\n                    }\n                    fs::remove_dir_all(entry_path)?;\n                } else {\n                    fs::remove_file(entry_path)?;\n                }\n            }\n        }\n        Ok(())\n    }\n\n    fn prepare_report_dir(&self, name: &str) -> Result<PathBuf> {\n        let dir = Path::new(&self.output_dir).join(name);\n        fs::create_dir_all(&dir)?;\n        Ok(dir)\n    }\n\n    fn generate_structure_report(&self, result: &AnalysisResult) -> Result<()> {\n        let dir = self.prepare_report_dir(\"10_structure\")?;\n        let generated_at = chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\");\n\n        let mut files: BTreeMap<String, Vec<&CodeElement>> = BTreeMap::new();\n        for elem in &result.elements {\n            files\n                .entry(elem.file_path.clone())\n                .or_insert_with(Vec::new)\n                .push(elem);\n        }\n\n        let mut grouped: BTreeMap<String, Vec<(String, Vec<&CodeElement>)>> = BTreeMap::new();\n        for (file_path, elements) in files {\n            let compressed = compress_path(&file_path);\n            let key = prefix_key_from_path(&compressed);\n            grouped\n                .entry(key)\n                .or_insert_with(Vec::new)\n                .push((compressed, elements));\n        }\n\n        let mut grouped: Vec<_> = grouped.into_iter().collect();\n        grouped.sort_by(|a, b| group_key_cmp(&a.0, &b.0));\n\n        let mut index = String::from(\"# MMSB Code Structure Overview\\n\\n\");\n        index.push_str(&format!(\"Generated: {}\\n\\n\", generated_at));\n        index.push_str(\n            \"Each numbered file groups source files by MMSB prefix so a simple `ls 10_structure/` \\\nshows the traversal order.\\n\\n\",\n        );\n\n        if grouped.is_empty() {\n            index.push_str(\"No code elements were recorded.\\n\");\n        } else {\n            index.push_str(\"## Group Files\\n\\n\");\n            for (idx, (group_key, _)) in grouped.iter().enumerate() {\n                let slug = slugify_key(group_key);\n                let file_name = format!(\"{:03}-{}.md\", idx * 10, slug);\n                index.push_str(&format!(\"- `{}`  `{}`\\n\", group_key, file_name));\n            }\n        }\n\n        for (idx, (group_key, mut entries)) in grouped.into_iter().enumerate() {\n            entries.sort_by(|a, b| a.0.cmp(&b.0));\n            let slug = slugify_key(&group_key);\n            let file_name = format!(\"{:03}-{}.md\", idx * 10, slug);\n            let mut content = format!(\"# Structure Group: {}\\n\\n\", group_key);\n\n            for (file_path, mut elements) in entries {\n                content.push_str(&format!(\"## File: {}\\n\\n\", file_path));\n\n                let layers: BTreeSet<String> = elements.iter().map(|e| e.layer.clone()).collect();\n                let layer_summary = if layers.is_empty() {\n                    \"root\".to_string()\n                } else {\n                    layers.iter().cloned().collect::<Vec<_>>().join(\", \")\n                };\n\n                let mut language_counts: BTreeMap<String, usize> = BTreeMap::new();\n                let mut type_counts: BTreeMap<String, usize> = BTreeMap::new();\n                for elem in &elements {\n                    *language_counts\n                        .entry(language_label(&elem.language).to_string())\n                        .or_insert(0) += 1;\n                    *type_counts\n                        .entry(format!(\"{:?}\", elem.element_type))\n                        .or_insert(0) += 1;\n                }\n\n                let lang_summary = if language_counts.is_empty() {\n                    \"n/a\".to_string()\n                } else {\n                    language_counts\n                        .iter()\n                        .map(|(lang, count)| format!(\"{} ({})\", lang, count))\n                        .collect::<Vec<_>>()\n                        .join(\", \")\n                };\n\n                let type_summary = if type_counts.is_empty() {\n                    \"n/a\".to_string()\n                } else {\n                    type_counts\n                        .iter()\n                        .map(|(ty, count)| format!(\"{} ({})\", ty, count))\n                        .collect::<Vec<_>>()\n                        .join(\", \")\n                };\n\n                content.push_str(&format!(\"- Layer(s): {}\\n\", layer_summary));\n                content.push_str(&format!(\"- Language coverage: {}\\n\", lang_summary));\n                content.push_str(&format!(\"- Element types: {}\\n\", type_summary));\n                content.push_str(&format!(\"- Total elements: {}\\n\\n\", elements.len()));\n\n                content.push_str(\"### Elements\\n\\n\");\n                elements.sort_by(|a, b| {\n                    a.line_number\n                        .cmp(&b.line_number)\n                        .then_with(|| a.name.cmp(&b.name))\n                });\n                for elem in elements {\n                    content.push_str(&self.format_element_entry(elem));\n                }\n                content.push('\\n');\n            }\n\n            fs::write(dir.join(file_name), content)?;\n        }\n\n        // Summary statistics\n        index.push_str(\"\\n## Summary Statistics\\n\\n\");\n        index.push_str(&format!(\"- Total elements: {}\\n\", result.elements.len()));\n        index.push_str(&format!(\n            \"- Rust elements: {}\\n\",\n            result\n                .elements\n                .iter()\n                .filter(|e| matches!(e.language, Language::Rust))\n                .count()\n        ));\n        index.push_str(&format!(\n            \"- Julia elements: {}\\n\",\n            result\n                .elements\n                .iter()\n                .filter(|e| matches!(e.language, Language::Julia))\n                .count()\n        ));\n\n        let mut type_counts: HashMap<String, usize> = HashMap::new();\n        for elem in &result.elements {\n            let key = format!(\"{:?}_{:?}\", elem.language, elem.element_type);\n            *type_counts.entry(key).or_insert(0) += 1;\n        }\n\n        index.push_str(\"\\n### Elements by Type\\n\\n\");\n        let mut sorted_types: Vec<_> = type_counts.iter().collect();\n        sorted_types.sort_by_key(|(k, _)| k.as_str());\n        for (type_name, count) in sorted_types {\n            index.push_str(&format!(\"- {}: {}\\n\", type_name, count));\n        }\n\n        fs::write(dir.join(\"index.md\"), index)?;\n        Ok(())\n    }\n\n    fn format_element_entry(&self, elem: &CodeElement) -> String {\n        let mut entry = format!(\n            \"- [{} | {:?}] `{}` (line {}, {})\\n\",\n            language_label(&elem.language),\n            elem.element_type,\n            elem.name,\n            elem.line_number,\n            visibility_label(&elem.visibility),\n        );\n\n        if !elem.signature.is_empty()\n            && matches!(\n                elem.element_type,\n                ElementType::Function | ElementType::Struct\n            )\n        {\n            entry.push_str(&format!(\n                \"  - Signature: `{}`\\n\",\n                short_signature(&elem.signature)\n            ));\n        }\n\n        if !elem.generic_params.is_empty() {\n            entry.push_str(&format!(\n                \"  - Generics: {}\\n\",\n                elem.generic_params.join(\", \")\n            ));\n        }\n\n        if matches!(elem.element_type, ElementType::Function) && !elem.calls.is_empty() {\n            entry.push_str(&format!(\"  - Calls: {}\\n\", elem.calls.join(\", \")));\n        }\n\n        entry\n    }\n\n    fn generate_call_graph_report(&self, cf_analyzer: &ControlFlowAnalyzer) -> Result<()> {\n        let dir = self.prepare_report_dir(\"20_call_graph\")?;\n        let path = dir.join(\"index.md\");\n        let mut content = String::from(\"# Call Graph Analysis\\n\\n\");\n        content.push_str(\"This document shows the **interprocedural call graph** - which functions call which other functions.\\n\\n\");\n        content.push_str(\"> **Note:** This is NOT a control flow graph (CFG). CFG shows intraprocedural control flow (branches, loops) within individual functions.\\n\\n\");\n\n        let stats = cf_analyzer.get_statistics();\n\n        content.push_str(\"## Call Graph Statistics\\n\\n\");\n        content.push_str(&format!(\"- Total functions: {}\\n\", stats.total_functions));\n        content.push_str(&format!(\"- Total function calls: {}\\n\", stats.total_calls));\n        content.push_str(&format!(\"- Maximum call depth: {}\\n\", stats.max_depth));\n        content.push_str(&format!(\n            \"- Leaf functions (no outgoing calls): {}\\n\\n\",\n            stats.leaf_functions\n        ));\n\n        content.push_str(\"## Call Graph Visualization\\n\\n\");\n        content.push_str(&cf_analyzer.generate_mermaid());\n\n        fs::write(path, content)?;\n        Ok(())\n    }\n\n    fn generate_cfg_report(&self, cf_analyzer: &ControlFlowAnalyzer) -> Result<()> {\n        let dir = self.prepare_report_dir(\"30_cfg\")?;\n        let mut index = String::from(\"# Control Flow Graphs (CFG)\\n\\n\");\n        index.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        if cf_analyzer.cfgs().is_empty() {\n            index.push_str(\"No control flow graphs were captured.\\n\");\n            fs::write(dir.join(\"index.md\"), index)?;\n            return Ok(());\n        }\n\n        let mut grouped: BTreeMap<String, Vec<(String, &FunctionCfg)>> = BTreeMap::new();\n        for cfg in cf_analyzer.cfgs() {\n            let compressed = compress_path(&cfg.file_path);\n            let key = prefix_key_from_path(&compressed);\n            grouped\n                .entry(key)\n                .or_insert_with(Vec::new)\n                .push((compressed, cfg));\n        }\n\n        let mut grouped: Vec<_> = grouped.into_iter().collect();\n        grouped.sort_by(|a, b| group_key_cmp(&a.0, &b.0));\n\n        index.push_str(&format!(\"- Total CFGs: {}\\n\", cf_analyzer.cfgs().len()));\n        index.push_str(\n            \"- Files are grouped by MMSB directory prefix; numeric prefixes match lexical ordering.\\n\\n\",\n        );\n\n        index.push_str(\"## Group Files\\n\\n\");\n        for (idx, (group_key, _)) in grouped.iter().enumerate() {\n            let file_name = format!(\"{:03}-{}.md\", idx * 10, slugify_key(group_key));\n            index.push_str(&format!(\"- `{}`  `{}`\\n\", group_key, file_name));\n        }\n\n        for (idx, (group_key, mut entries)) in grouped.into_iter().enumerate() {\n            entries.sort_by(|a, b| a.1.function.cmp(&b.1.function));\n            let slug = slugify_key(&group_key);\n            let file_name = format!(\"{:03}-{}.md\", idx * 10, slug);\n            let mut content = format!(\"# CFG Group: {}\\n\\n\", group_key);\n\n            for (compressed, cfg) in entries {\n                content.push_str(&format!(\"## Function: `{}`\\n\\n\", cfg.function));\n                content.push_str(&format!(\n                    \"- File: {}\\n- Branches: {}\\n- Loops: {}\\n- Nodes: {}\\n- Edges: {}\\n\\n\",\n                    compressed,\n                    cfg.branch_count,\n                    cfg.loop_count,\n                    cfg.nodes.len(),\n                    cfg.edges.len(),\n                ));\n                if let Some(dot_rel) = self.dot_path_for(&compressed) {\n                    content.push_str(&format!(\"- DOT call graph: `{}`\\n\\n\", dot_rel));\n                }\n\n                content.push_str(\"```mermaid\\nflowchart TD\\n\");\n                let mut id_map = HashMap::new();\n                let prefix = sanitize_mermaid_id(&cfg.function);\n                for node in &cfg.nodes {\n                    let raw_id = format!(\"{}_{}\", prefix, node.id);\n                    let safe_id = sanitize_mermaid_id(&raw_id);\n                    id_map.insert(node.id, safe_id.clone());\n                    content.push_str(&format!(\n                        \"    {}[\\\"{}\\\"]\\n\",\n                        safe_id,\n                        sanitize_mermaid_label(&node.label)\n                    ));\n                }\n                for edge in &cfg.edges {\n                    if let (Some(src), Some(dst)) = (id_map.get(&edge.from), id_map.get(&edge.to)) {\n                        content.push_str(&format!(\"    {} --> {}\\n\", src, dst));\n                    }\n                }\n                content.push_str(\"```\\n\\n\");\n            }\n\n            fs::write(dir.join(file_name), content)?;\n        }\n\n        fs::write(dir.join(\"index.md\"), index)?;\n        Ok(())\n    }\n\n    fn generate_layer_dependency_report(\n        &self,\n        rust_layers: &LayerGraph,\n        julia_layers: &LayerGraph,\n        root_path: &Path,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"60_layer_dependencies\")?;\n        let path = dir.join(\"index.md\");\n        let mut content = String::from(\"# Layer Dependency Report\\n\\n\");\n        content.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        self.write_layer_section(&mut content, \"Rust\", rust_layers, root_path);\n        self.write_layer_section(&mut content, \"Julia\", julia_layers, root_path);\n\n        fs::write(path, content)?;\n        Ok(())\n    }\n\n    fn generate_file_ordering_report(\n        &self,\n        rust_ordering: &FileOrderingResult,\n        julia_ordering: &FileOrderingResult,\n        root_path: &Path,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"70_file_ordering\")?;\n        let path = dir.join(\"index.md\");\n        let mut content = String::from(\"# File Ordering Report\\n\\n\");\n        content.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        self.write_ordering_section(&mut content, \"Rust\", rust_ordering, root_path);\n        self.write_ordering_section(&mut content, \"Julia\", julia_ordering, root_path);\n\n        fs::write(path, content)?;\n        Ok(())\n    }\n\n    fn write_ordering_section(\n        &self,\n        content: &mut String,\n        label: &str,\n        ordering: &FileOrderingResult,\n        root_path: &Path,\n    ) {\n        content.push_str(&format!(\"## {} File Ordering\\n\\n\", label));\n        if ordering.ordered_files.is_empty() {\n            content.push_str(\"No files analyzed.\\n\\n\");\n            return;\n        }\n\n        let rename_count = ordering\n            .ordered_files\n            .iter()\n            .filter(|entry| entry.needs_rename)\n            .count();\n        content.push_str(\"### Metrics\\n\\n\");\n        content.push_str(&format!(\n            \"- Total files: {}\\n- Rename suggestions: {}\\n- Ordering violations: {}\\n- Layer violations: {}\\n- Directories: {}\\n\\n\",\n            ordering.ordered_files.len(),\n            rename_count,\n            ordering.violations.len(),\n            ordering.layer_violations.len(),\n            ordering.ordered_directories.len()\n        ));\n\n        if !ordering.cycles.is_empty() {\n            content.push_str(\"### Cycles Detected\\n\");\n            for cycle in &ordering.cycles {\n                let listing = cycle\n                    .iter()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .collect::<Vec<_>>()\n                    .join(\", \");\n                content.push_str(&format!(\"- {}\\n\", listing));\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Canonical Order\\n\\n\");\n        content.push_str(\"| Order | Current | Suggested | Rename |\\n\");\n        content.push_str(\"| --- | --- | --- | --- |\\n\");\n        for entry in &ordering.ordered_files {\n            let current = display_path(&entry.current_path, root_path);\n            let rename = if entry.needs_rename { \"yes\" } else { \"no\" };\n            content.push_str(&format!(\n                \"| {} | `{}` | `{}` | {} |\\n\",\n                entry.canonical_order, current, entry.suggested_name, rename\n            ));\n        }\n        content.push('\\n');\n\n        content.push_str(\"### Ordering Violations\\n\");\n        if ordering.violations.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for violation in &ordering.violations {\n                let file = display_path(&violation.file, root_path);\n                content.push_str(&format!(\n                    \"- `{}`: alphabetical position {}, required position {}\\n\",\n                    file, violation.current_position, violation.required_position\n                ));\n                if !violation.blocking_dependencies.is_empty() {\n                    for dep in &violation.blocking_dependencies {\n                        let dep_path = display_path(dep, root_path);\n                        content.push_str(&format!(\"  - depends on `{}`\\n\", dep_path));\n                    }\n                }\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Layer Violations\\n\");\n        if ordering.layer_violations.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for violation in &ordering.layer_violations {\n                let from = display_path(&violation.from, root_path);\n                let to = display_path(&violation.to, root_path);\n                content.push_str(&format!(\n                    \"- `{}` ({}) depends on `{}` ({})\\n\",\n                    to, violation.to_layer, from, violation.from_layer\n                ));\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Directory Order\\n\");\n        if ordering.ordered_directories.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for dir in &ordering.ordered_directories {\n                let path = display_path(dir, root_path);\n                content.push_str(&format!(\"- `{}`\\n\", path));\n            }\n            content.push('\\n');\n        }\n    }\n\n    fn generate_cohesion_report(\n        &self,\n        placements: &[FunctionPlacement],\n        clusters: &[FunctionCluster],\n        root_path: &Path,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"80_cohesion_analysis\")?;\n        let path = dir.join(\"index.md\");\n        let mut content = String::from(\"# Function Cohesion Analysis\\n\\n\");\n        content.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        if placements.is_empty() {\n            content.push_str(\"No function placement data recorded.\\n\");\n            fs::write(path, content)?;\n            return Ok(());\n        }\n\n        let mut by_file: BTreeMap<String, Vec<&FunctionPlacement>> = BTreeMap::new();\n        let avg_cohesion = if placements.is_empty() {\n            0.0\n        } else {\n            placements\n                .iter()\n                .map(|p| p.cohesion_score)\n                .sum::<f64>()\n                / placements.len() as f64\n        };\n        let move_count = placements\n            .iter()\n            .filter(|p| matches!(p.placement_status, PlacementStatus::ShouldMove { .. }))\n            .count();\n        let (orphaned, delete_candidates) =\n            filter_orphaned(placements, root_path, &self.output_dir);\n        let orphaned_count = orphaned.len();\n        let layer_violation_count = placements\n            .iter()\n            .filter(|p| matches!(p.placement_status, PlacementStatus::LayerViolation { .. }))\n            .count();\n        content.push_str(\"## Metrics\\n\\n\");\n        content.push_str(&format!(\n            \"- Avg cohesion: {:.2}\\n- Move suggestions: {}\\n- Orphaned functions: {}\\n- Layer violations: {}\\n\\n\",\n            avg_cohesion, move_count, orphaned_count, layer_violation_count\n        ));\n        for placement in placements {\n            by_file\n                .entry(placement.current_file.to_string_lossy().to_string())\n                .or_default()\n                .push(placement);\n        }\n\n        for (file, mut entries) in by_file {\n            entries.sort_by(|a, b| {\n                a.cohesion_score\n                    .partial_cmp(&b.cohesion_score)\n                    .unwrap_or(Ordering::Equal)\n            });\n            let compressed = compress_path(&file);\n            content.push_str(&format!(\"## File: {}\\n\\n\", compressed));\n            content.push_str(\"| Function | Signature | Cohesion | Calls | Type refs | Status | Suggestion |\\n\");\n            content.push_str(\"| --- | --- | --- | --- | --- | --- | --- |\\n\");\n            for entry in entries {\n                let status = placement_status_label(&entry.placement_status);\n                let mut suggestion = entry\n                    .suggested_file\n                    .as_ref()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .unwrap_or_else(|| \"-\".to_string());\n                let notes = placement_status_notes(&entry.placement_status);\n                if !notes.is_empty() {\n                    suggestion = format!(\"{} ({})\", suggestion, notes);\n                }\n                let call_summary = format!(\n                    \"intra {}, inter {}\",\n                    entry.call_analysis.intra_file_calls,\n                    entry.call_analysis.inter_file_calls.len()\n                );\n                let type_summary = format!(\n                    \"same {}, other {}\",\n                    entry.call_analysis.same_file_type_refs,\n                    entry.call_analysis.other_file_type_refs\n                );\n                content.push_str(&format!(\n                    \"| `{}` | `{}` | {:.2} | {} | {} | {} | {} |\\n\",\n                    entry.name,\n                    entry.signature.replace('|', \"\\\\|\"),\n                    entry.cohesion_score,\n                    call_summary,\n                    type_summary,\n                    status,\n                    suggestion\n                ));\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"## Orphaned Functions (Review Only)\\n\\n\");\n        content.push_str(\"Action: review each item for expected usage. Delete only if it also appears under \\\"Delete Candidates (Orphaned + Dead Code)\\\".\\n\");\n        content.push_str(\"Note: excludes public symbols referenced by other modules and entry points. Delete candidates require dead_code warnings.\\n\\n\");\n        if orphaned.is_empty() {\n            content.push_str(\"- None detected.\\n\");\n        } else {\n            for entry in orphaned {\n                let file = compress_path(entry.current_file.to_string_lossy().as_ref());\n                content.push_str(&format!(\"- `{}` in `{}`\\n\", entry.name, file));\n            }\n        }\n        content.push('\\n');\n        content.push_str(\"## Delete Candidates (Orphaned + Dead Code)\\n\\n\");\n        if delete_candidates.is_empty() {\n            content.push_str(\"- None detected.\\n\");\n        } else {\n            for entry in delete_candidates {\n                let file = compress_path(entry.current_file.to_string_lossy().as_ref());\n                content.push_str(&format!(\"- `{}` in `{}`\\n\", entry.name, file));\n            }\n        }\n        content.push('\\n');\n\n        let utility_candidates = collect_utility_candidates(placements);\n        content.push_str(\"## Utility Module Candidates\\n\\n\");\n        if utility_candidates.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for candidate in utility_candidates {\n                content.push_str(&format!(\"- {}\\n\", candidate));\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"## Function Clusters\\n\\n\");\n        if clusters.is_empty() {\n            content.push_str(\"- None detected.\\n\");\n        } else {\n            for cluster in clusters {\n                let suggested = cluster\n                    .suggested_file\n                    .as_ref()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .unwrap_or_else(|| \"-\".to_string());\n                let members = cluster\n                    .members\n                    .iter()\n                    .map(|m| compress_path(m))\n                    .collect::<Vec<_>>()\n                    .join(\", \");\n                content.push_str(&format!(\n                    \"- cohesion {:.2}, suggested `{}`\\n  - {}\\n\",\n                    cluster.cohesion, suggested, members\n                ));\n            }\n        }\n        content.push('\\n');\n\n        fs::write(path, content)?;\n        Ok(())\n    }\n\n    fn generate_refactoring_plan(\n        &self,\n        rust_ordering: &FileOrderingResult,\n        julia_ordering: &FileOrderingResult,\n        placements: &[FunctionPlacement],\n        clusters: &[FunctionCluster],\n        directory: &DirectoryAnalysis,\n        root_path: &Path,\n        correction_report: Option<&crate::correction_intelligence_report::CorrectionIntelligenceReport>,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"00_refactoring_plan\")?;\n        let generated_at = chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\").to_string();\n\n        let mut renames = collect_rename_items(rust_ordering, \"Rust\")\n            .into_iter()\n            .chain(collect_rename_items(julia_ordering, \"Julia\"))\n            .collect::<Vec<_>>();\n        renames.extend(directory_moves_to_plan(\n            \"Rust\",\n            collect_directory_moves(rust_ordering, root_path),\n        ));\n        renames.extend(directory_moves_to_plan(\n            \"Julia\",\n            collect_directory_moves(julia_ordering, root_path),\n        ));\n        let cluster_plans = collect_cluster_plans(clusters, root_path);\n        let cluster_items = collect_cluster_items(&cluster_plans);\n        let mut utility_names = BTreeSet::new();\n        for placement in placements {\n            if placement.call_analysis.calls_from_other_files.len() >= 3 {\n                utility_names.insert(placement.name.clone());\n            }\n        }\n        let mut moves = collect_move_items(placements, &utility_names, directory, root_path);\n\n        // MECHANICAL CONSTRAINT ENFORCEMENT\n        // Filter moves by invariant constraints to prevent unsafe refactorings\n        if let Ok(constraints_json) = std::fs::read_to_string(\n            std::path::Path::new(&self.output_dir).join(\"96_constraints/refactor_constraints.json\")\n        ) {\n            use crate::refactor_constraints::RefactorConstraint;\n            if let Ok(constraints) = serde_json::from_str::<Vec<RefactorConstraint>>(&constraints_json) {\n                let mut blocked_count = 0;\n\n                moves.retain(|m| {\n                    // Check if this move violates any constraint\n                    use crate::action_validator::check_move_allowed;\n\n                    // Skip items without name or current/target file paths\n                    let name = match &m.name {\n                        Some(n) => n.clone(),\n                        None => return true, // Keep if no name to check\n                    };\n\n                    let from = match &m.current_file {\n                        Some(f) => f.clone(),\n                        None => return true,\n                    };\n\n                    let to = match &m.target_file {\n                        Some(t) => t.clone(),\n                        None => return true,\n                    };\n\n                    match check_move_allowed(&name, &from, &to, &constraints) {\n                        Ok(_) => true,  // Allowed\n                        Err(reason) => {\n                            // Log rejection (only in verbose mode to avoid clutter)\n                            if std::env::var(\"VERBOSE\").is_ok() {\n                                eprintln!(\"  BLOCKED: {} - {}\", name, reason);\n                            }\n                            blocked_count += 1;\n                            false  // Filtered out\n                        }\n                    }\n                });\n\n                if blocked_count > 0 {\n                    println!(\" Constraint enforcement: {} moves allowed, {} blocked by invariants\",\n                             moves.len(), blocked_count);\n                }\n            }\n        }\n\n        let (orphaned, delete_candidates) =\n            filter_orphaned(placements, root_path, &self.output_dir);\n\n        let mut all_items = Vec::new();\n        all_items.extend(cluster_items.iter().cloned());\n        all_items.extend(renames.iter().cloned());\n        all_items.extend(moves.iter().cloned());\n\n        let mut correctness: Vec<PlanItem> = Vec::new();\n        let mut clusters_phase = Vec::new();\n        let mut structural = Vec::new();\n        let mut cohesion = Vec::new();\n        let mut ordering = Vec::new();\n\n        for item in all_items {\n            match item.kind {\n                ActionKind::Cluster => clusters_phase.push(item),\n                ActionKind::Structural => structural.push(item),\n                ActionKind::Cohesion => cohesion.push(item),\n                ActionKind::Ordering => ordering.push(item),\n            }\n        }\n\n        sort_plan_items(&mut correctness);\n        sort_cluster_items(&mut clusters_phase);\n        sort_structural_items(&mut structural);\n        sort_plan_items(&mut cohesion);\n        sort_plan_items(&mut ordering);\n\n        let config = load_report_config(&self.output_dir);\n        let dir_cohesion = compute_directory_cohesion(placements);\n        let avg_cohesion = if placements.is_empty() {\n            0.0\n        } else {\n            placements\n                .iter()\n                .map(|p| p.cohesion_score)\n                .sum::<f64>()\n                / placements.len() as f64\n        };\n        let ordering_correctness = compute_ordering_correctness(rust_ordering, julia_ordering);\n        let relocations = placements\n            .iter()\n            .filter(|p| matches!(p.placement_status, PlacementStatus::ShouldMove { .. }\n                | PlacementStatus::LayerViolation { .. }))\n            .count();\n\n        write_baseline_metrics(\n            &config,\n            &self.output_dir,\n            dir_cohesion,\n            ordering_correctness,\n            avg_cohesion,\n            renames.len(),\n            relocations,\n        );\n\n        let mut summary = String::from(\"# Refactoring Plan\\n\\n\");\n        summary.push_str(&format!(\"Generated: {}\\n\\n\", generated_at));\n        summary.push_str(\"## Summary\\n\\n\");\n        summary.push_str(\"Action: use this as the quick status snapshot for planning work.\\n\");\n        summary.push_str(\"Note: counts are derived from current analysis output.\\n\\n\");\n        summary.push_str(&format!(\n            \"- File/dir renames: {}\\n- Function moves: {}\\n- Orphaned functions: {}\\n- Clusters: {}\\n\\n\",\n            renames.len(),\n            moves.len(),\n            orphaned.len(),\n            clusters.len()\n        ));\n\n        let mut metrics = String::new();\n        metrics.push_str(\"## Metrics\\n\\n\");\n        metrics.push_str(\"Action: monitor trends and regressions across runs.\\n\");\n        metrics.push_str(\"Note: compare against baseline metrics when available.\\n\\n\");\n        metrics.push_str(&format!(\n            \"- Directory cohesion: {:.2}\\n- Ordering correctness: {:.1}%\\n- Avg function cohesion: {:.2}\\n- Rename ops needed: {}\\n- Function relocations suggested: {}\\n\\n\",\n            dir_cohesion,\n            ordering_correctness * 100.0,\n            avg_cohesion,\n            renames.len(),\n            relocations\n        ));\n\n        let mut baseline_section = String::new();\n        if let Some(baseline) = load_baseline_metrics(&config, &self.output_dir) {\n            let mut regression_warnings = Vec::new();\n            let epsilon = 0.005;\n            if let Some(prev) = baseline.get(\"directory_cohesion\") {\n                if dir_cohesion + epsilon < *prev {\n                    regression_warnings.push(format!(\n                        \"Directory cohesion dropped from {:.2} to {:.2}.\",\n                        prev, dir_cohesion\n                    ));\n                }\n            }\n            if let Some(prev) = baseline.get(\"ordering_correctness\") {\n                let current = ordering_correctness * 100.0;\n                if current + epsilon < *prev {\n                    regression_warnings.push(format!(\n                        \"Ordering correctness dropped from {:.1}% to {:.1}%.\",\n                        prev, current\n                    ));\n                }\n            }\n            if let Some(prev) = baseline.get(\"avg_function_cohesion\") {\n                if avg_cohesion + epsilon < *prev {\n                    regression_warnings.push(format!(\n                        \"Avg function cohesion dropped from {:.2} to {:.2}.\",\n                        prev, avg_cohesion\n                    ));\n                }\n            }\n            if let Some(prev) = baseline.get(\"rename_ops_needed\") {\n                if (renames.len() as f64) > *prev + epsilon {\n                    regression_warnings.push(format!(\n                        \"Rename ops needed increased from {:.0} to {}.\",\n                        prev,\n                        renames.len()\n                    ));\n                }\n            }\n            if let Some(prev) = baseline.get(\"function_relocations\") {\n                if (relocations as f64) > *prev + epsilon {\n                    regression_warnings.push(format!(\n                        \"Function relocations suggested increased from {:.0} to {}.\",\n                        prev,\n                        relocations\n                    ));\n                }\n            }\n\n            let deltas = baseline_deltas(\n                &baseline,\n                dir_cohesion,\n                ordering_correctness,\n                avg_cohesion,\n                renames.len(),\n                relocations,\n            );\n            if !deltas.is_empty() {\n                println!(\"Baseline deltas:\");\n                for line in &deltas {\n                    println!(\"  {}\", line);\n                }\n            }\n\n            baseline_section.push_str(\"## Baseline Regression Warnings\\n\\n\");\n            baseline_section\n                .push_str(\"Action: investigate any regressions before proceeding with refactors.\\n\");\n            baseline_section.push_str(\"Note: derived from the last saved baseline metrics.\\n\\n\");\n            if regression_warnings.is_empty() {\n                baseline_section.push_str(\"- None.\\n\\n\");\n            } else {\n                for warning in regression_warnings {\n                    baseline_section.push_str(&format!(\"- {}\\n\", warning));\n                }\n                baseline_section.push('\\n');\n            }\n        } else {\n            baseline_section.push_str(\"## Baseline Regression Warnings\\n\\n\");\n            baseline_section\n                .push_str(\"Action: save a baseline to enable regression tracking.\\n\");\n            baseline_section\n                .push_str(\"Note: baseline metrics file not found for this output directory.\\n\\n\");\n            baseline_section.push_str(\"- None.\\n\\n\");\n        }\n\n        let mut phase1 = String::new();\n        write_priority_section(&mut phase1, \"Phase 1: Correctness Blockers\", &correctness);\n\n        let mut phase2 = String::new();\n        write_priority_section(&mut phase2, \"Phase 2: Cluster Extraction\", &clusters_phase);\n        write_cluster_tips(&mut phase2, &cluster_plans);\n        write_cluster_batches(&mut phase2, &cluster_plans, root_path);\n\n        let mut phase3 = String::new();\n        write_priority_section(&mut phase3, \"Phase 3: Structural Constraints\", &structural);\n        write_structural_tips(&mut phase3, &structural);\n        write_structural_batches(&mut phase3, &structural);\n\n        let mut phase4 = String::new();\n        write_priority_section(&mut phase4, \"Phase 4: Cohesion Improvements\", &cohesion);\n\n        let mut phase5 = String::new();\n        write_priority_section(&mut phase5, \"Phase 5: Ordering & Renames\", &ordering);\n\n        let mut orphaned_section = String::new();\n        orphaned_section.push_str(\"## Orphaned Functions (Review Only)\\n\\n\");\n        orphaned_section.push_str(\"Action: review each item for expected usage. Delete only if it also appears under \\\"Delete Candidates (Orphaned + Dead Code)\\\".\\n\");\n        orphaned_section.push_str(\"Note: excludes public symbols referenced by other modules and entry points. Delete candidates require dead_code warnings.\\n\\n\");\n        if orphaned.is_empty() {\n            orphaned_section.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for entry in &orphaned {\n                let file = compress_path(entry.current_file.to_string_lossy().as_ref());\n                orphaned_section.push_str(&format!(\"- `{}` in `{}`\\n\", entry.name, file));\n            }\n            orphaned_section.push('\\n');\n        }\n\n        let mut delete_section = String::new();\n        delete_section.push_str(\"## Delete Candidates (Orphaned + Dead Code)\\n\\n\");\n        delete_section.push_str(\"Action: consider removal after confirming behavior and running tests.\\n\");\n        delete_section.push_str(\"Note: derived from orphaned list plus compiler dead_code warnings.\\n\\n\");\n        if delete_candidates.is_empty() {\n            delete_section.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for entry in &delete_candidates {\n                let file = compress_path(entry.current_file.to_string_lossy().as_ref());\n                delete_section.push_str(&format!(\"- `{}` in `{}`\\n\", entry.name, file));\n            }\n            delete_section.push('\\n');\n        }\n\n        let mut cluster_suggestions = String::new();\n        cluster_suggestions.push_str(\"## Suggested New Files (Clusters)\\n\\n\");\n        cluster_suggestions.push_str(\"Action: consider creating these files to improve cohesion.\\n\");\n        cluster_suggestions.push_str(\"Note: suggestions are heuristic and should be validated.\\n\\n\");\n        if clusters.is_empty() {\n            cluster_suggestions.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for cluster in clusters {\n                let suggested = cluster\n                    .suggested_file\n                    .as_ref()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .unwrap_or_else(|| \"new module\".to_string());\n                let members = cluster\n                    .members\n                    .iter()\n                    .map(|m| compress_path(m))\n                    .collect::<Vec<_>>()\n                    .join(\", \");\n                cluster_suggestions.push_str(&format!(\n                    \"- cohesion {:.2}, suggested `{}`\\n  - {}\\n\",\n                    cluster.cohesion, suggested, members\n                ));\n            }\n            cluster_suggestions.push('\\n');\n        }\n\n        let utility_candidates = collect_utility_candidates(placements);\n        let mut utility_section = String::new();\n        utility_section.push_str(\"## Utility Module Candidates\\n\\n\");\n        utility_section.push_str(\"Action: consider consolidating these into a shared utilities module.\\n\");\n        utility_section.push_str(\"Note: candidates are based on cross-file usage frequency.\\n\\n\");\n        if utility_candidates.is_empty() {\n            utility_section.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for candidate in utility_candidates {\n                utility_section.push_str(&format!(\"- {}\\n\", candidate));\n            }\n            utility_section.push('\\n');\n        }\n\n        let mut naming_warnings = Vec::new();\n        let _ = collect_naming_warnings(directory, &config, &mut naming_warnings);\n        let mut naming_section = String::new();\n        naming_section.push_str(\"## Naming Warnings\\n\\n\");\n        naming_section.push_str(\"Action: rename files if the suggested name improves ordering clarity.\\n\");\n        naming_section.push_str(\"Note: `_old` paths are excluded from naming warnings.\\n\\n\");\n        if naming_warnings.is_empty() {\n            naming_section.push_str(\"- None.\\n\\n\");\n        } else {\n            for warning in naming_warnings {\n                naming_section.push_str(&format!(\"- {}\\n\", warning));\n            }\n            naming_section.push('\\n');\n        }\n\n        let mut size_warnings = Vec::new();\n        collect_size_warnings(directory, &config, &mut size_warnings);\n        let mut size_section = String::new();\n        size_section.push_str(\"## Size Warnings\\n\\n\");\n        size_section.push_str(\"Action: consider extracting helpers to reduce file size.\\n\");\n        size_section.push_str(\"Note: thresholds come from report configuration.\\n\\n\");\n        if size_warnings.is_empty() {\n            size_section.push_str(\"- None.\\n\\n\");\n        } else {\n            for warning in size_warnings {\n                size_section.push_str(&format!(\"- {}\\n\", warning));\n            }\n            size_section.push('\\n');\n        }\n\n        let mut cargo_section = String::new();\n        if let Some(warnings) = load_cargo_warnings(&self.output_dir) {\n            cargo_section.push_str(\"## Cargo Warnings\\n\\n\");\n            cargo_section.push_str(\"Action: address compiler warnings before major refactors.\\n\");\n            cargo_section.push_str(\"Note: captured from cargo check/test outputs.\\n\\n\");\n            if warnings.trim().is_empty() {\n                cargo_section.push_str(\"- None.\\n\\n\");\n            } else {\n                cargo_section.push_str(\"```text\\n\");\n                cargo_section.push_str(warnings.trim());\n                cargo_section.push_str(\"\\n```\\n\\n\");\n            }\n        } else {\n            cargo_section.push_str(\"## Cargo Warnings\\n\\n\");\n            cargo_section.push_str(\"Action: address compiler warnings before major refactors.\\n\");\n            cargo_section.push_str(\"Note: no cargo warnings captured in this run.\\n\\n\");\n            cargo_section.push_str(\"- None.\\n\\n\");\n        }\n\n        let mut correction_section = String::new();\n        if let Some(report) = correction_report {\n            correction_section.push_str(\"## Correction Intelligence\\n\\n\");\n            correction_section.push_str(\"Action: review correction plans and verification policies before execution.\\n\");\n            correction_section.push_str(\"Note: generated for mmsb-executor ingestion; analyzer does not mutate code.\\n\\n\");\n            correction_section.push_str(&format!(\n                \"- Actions analyzed: {}\\n- Trivial: {}\\n- Moderate: {}\\n- Complex: {}\\n- Avg confidence: {:.1}%\\n\\n\",\n                report.actions_analyzed,\n                report.summary.trivial_count,\n                report.summary.moderate_count,\n                report.summary.complex_count,\n                report.summary.average_confidence * 100.0\n            ));\n            correction_section.push_str(\n                \"- JSON: `97_correction_intelligence/correction_intelligence.json`\\n\",\n            );\n            correction_section.push_str(\n                \"- Verification policy: `97_correction_intelligence/verification_policy.json`\\n\\n\",\n            );\n        }\n\n        let mut files = Vec::new();\n        files.push((\"00_summary.md\", summary));\n        files.push((\"01_metrics.md\", metrics));\n        files.push((\"02_baseline_regressions.md\", baseline_section));\n        files.push((\"03_phase1_correctness.md\", phase1));\n        files.push((\"04_phase2_clusters.md\", phase2));\n        files.push((\"05_phase3_structural.md\", phase3));\n        files.push((\"06_phase4_cohesion.md\", phase4));\n        files.push((\"07_phase5_ordering_renames.md\", phase5));\n        files.push((\"08_orphaned_functions.md\", orphaned_section));\n        files.push((\"09_delete_candidates.md\", delete_section));\n        files.push((\"10_suggested_new_files.md\", cluster_suggestions));\n        files.push((\"11_utility_module_candidates.md\", utility_section));\n        files.push((\"12_naming_warnings.md\", naming_section));\n        files.push((\"13_size_warnings.md\", size_section));\n        files.push((\"14_cargo_warnings.md\", cargo_section));\n        if correction_report.is_some() {\n            files.push((\"15_correction_intelligence.md\", correction_section));\n        }\n\n        let mut index = String::from(\"# Refactoring Plan Index\\n\\n\");\n        index.push_str(&format!(\"Generated: {}\\n\\n\", generated_at));\n        for (name, _) in &files {\n            index.push_str(&format!(\"- `{}`\\n\", name));\n        }\n        fs::write(dir.join(\"index.md\"), index)?;\n        for (name, content) in files {\n            fs::write(dir.join(name), content)?;\n        }\n        Ok(())\n    }\n\n    fn generate_file_organization_report(\n        &self,\n        directory: &DirectoryAnalysis,\n        _rust_ordering: &FileOrderingResult,\n        _julia_ordering: &FileOrderingResult,\n        root_path: &Path,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"90_file_organization\")?;\n        let mut index = String::from(\"# File Organization Report\\n\\n\");\n        index.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        let mut entries = Vec::new();\n        collect_directories(directory, &mut entries);\n        for entry in &entries {\n            if entry.files.is_empty() {\n                continue;\n            }\n            let file_map = build_directory_entry_map(&entry.files)?;\n            let relative = entry\n                .path\n                .strip_prefix(root_path)\n                .unwrap_or(&entry.path)\n                .to_path_buf();\n            let slug = slugify_path(&relative);\n            let file_name = format!(\"{}.md\", slug);\n            index.push_str(&format!(\n                \"- `{}`  `{}`\\n\",\n                compress_path(entry.path.to_string_lossy().as_ref()),\n                file_name\n            ));\n\n            let mut content = format!(\n                \"# Directory: {}\\n\\n\",\n                compress_path(entry.path.to_string_lossy().as_ref())\n            );\n            content.push_str(&format!(\"- Layer: `{}`\\n\\n\", entry.layer));\n            content.push_str(\"## Files\\n\\n\");\n            content.push_str(\"| File | Suggested | Rename |\\n\");\n            content.push_str(\"| --- | --- | --- |\\n\");\n            let mut files = entry.files.clone();\n            files.sort();\n            for file in files {\n                let entry_info = file_map.get(&file);\n                let suggested = entry_info\n                    .map(|info| info.suggested_name.as_str())\n                    .unwrap_or(\"-\");\n                let rename = entry_info\n                    .map(|info| if info.needs_rename { \"yes\" } else { \"no\" })\n                    .unwrap_or(\"no\");\n                content.push_str(&format!(\n                    \"| `{}` | `{}` | {} |\\n\",\n                    compress_path(file.to_string_lossy().as_ref()),\n                    suggested,\n                    rename\n                ));\n            }\n            content.push('\\n');\n\n            content.push_str(\"## Dependency Graph\\n\\n\");\n            if entry.files.is_empty() {\n                content.push_str(\"No source files.\\n\\n\");\n            } else {\n                let graph = build_file_dependency_graph(&entry.files)?;\n                content.push_str(&render_mermaid_graph(&graph));\n                content.push('\\n');\n            }\n\n            fs::write(dir.join(file_name), content)?;\n        }\n\n        fs::write(dir.join(\"index.md\"), index)?;\n        Ok(())\n    }\n\n    fn write_layer_section(\n        &self,\n        content: &mut String,\n        label: &str,\n        graph: &LayerGraph,\n        root_path: &Path,\n    ) {\n        content.push_str(&format!(\"## {} Layer Graph\\n\\n\", label));\n\n        if graph.ordered_layers.is_empty() {\n            content.push_str(\"No layers discovered.\\n\\n\");\n            return;\n        }\n\n        content.push_str(\"### Layer Order\\n\");\n        for (idx, layer) in graph.ordered_layers.iter().enumerate() {\n            let cycle_tag = if graph.cycles.contains(layer) {\n                \" (cycle)\"\n            } else {\n                \"\"\n            };\n            content.push_str(&format!(\"{}. `{}`{}\\n\", idx + 1, layer, cycle_tag));\n        }\n        content.push('\\n');\n\n        if !graph.cycles.is_empty() {\n            content.push_str(\"### Cycles Detected\\n\");\n            for cycle in &graph.cycles {\n                content.push_str(&format!(\"- `{}`\\n\", cycle));\n            }\n            content.push('\\n');\n        }\n\n        let violations: Vec<_> = graph.edges.iter().filter(|e| e.violation).collect();\n        content.push_str(\"### Layer Violations\\n\");\n        if violations.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for edge in violations {\n                content.push_str(&format!(\n                    \"- `{}` depends on `{}` ({} references)\\n\",\n                    edge.to,\n                    edge.from,\n                    edge.references.len()\n                ));\n                for reference in &edge.references {\n                    let compressed = display_path(&reference.file, root_path);\n                    content.push_str(&format!(\"  - {} :: {}\\n\", compressed, reference.reference));\n                }\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Dependency Edges\\n\");\n        if graph.edges.is_empty() {\n            content.push_str(\"- No cross-layer dependencies recorded.\\n\\n\");\n        } else {\n            for edge in &graph.edges {\n                content.push_str(&format!(\n                    \"- `{}`  `{}` ({} references{})\\n\",\n                    edge.from,\n                    edge.to,\n                    edge.references.len(),\n                    if edge.violation { \", VIOLATION\" } else { \"\" }\n                ));\n                for reference in &edge.references {\n                    let compressed = display_path(&reference.file, root_path);\n                    content.push_str(&format!(\"  - {} :: {}\\n\", compressed, reference.reference));\n                }\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Unresolved References\\n\");\n        if graph.unresolved.is_empty() {\n            content.push_str(\"- None.\\n\\n\");\n        } else {\n            for unresolved in &graph.unresolved {\n                let compressed = display_path(&unresolved.file, root_path);\n                content.push_str(&format!(\"- {}  `{}`\\n\", compressed, unresolved.reference));\n            }\n            content.push('\\n');\n        }\n    }\n\n    fn generate_module_dependencies(&self, result: &AnalysisResult) -> Result<()> {\n        let dir = self.prepare_report_dir(\"40_module_dependencies\")?;\n        let index_path = dir.join(\"index.md\");\n        let mut index = String::from(\"# Module Dependencies\\n\\n\");\n\n        if result.modules.is_empty() {\n            index.push_str(\"No module metadata captured yet.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        }\n\n        let mut modules_by_file: BTreeMap<String, ModuleAggregate> = BTreeMap::new();\n        for module in &result.modules {\n            let layer = self.extract_layer_from_path(&module.file_path);\n            let entry = modules_by_file\n                .entry(module.file_path.clone())\n                .or_insert_with(|| ModuleAggregate::new(module.name.clone(), layer.clone()));\n\n            if entry.name == \"unknown\" && !module.name.is_empty() {\n                entry.name = module.name.clone();\n            }\n\n            entry.layer = layer;\n            for import in &module.imports {\n                entry.imports.insert(normalize_use_stmt(import));\n            }\n            for export in &module.exports {\n                entry.exports.insert(normalize_use_stmt(export));\n            }\n            for sub in &module.submodules {\n                entry.submodules.insert(sub.clone());\n            }\n        }\n\n        let total_imports: usize = modules_by_file.values().map(|m| m.imports.len()).sum();\n        let total_exports: usize = modules_by_file.values().map(|m| m.exports.len()).sum();\n        let total_submodules: usize = modules_by_file.values().map(|m| m.submodules.len()).sum();\n\n        let mut modules: Vec<_> = modules_by_file.into_iter().collect();\n        modules.sort_by(|a, b| a.0.cmp(&b.0));\n\n        index.push_str(&format!(\"- Module files analyzed: {}\\n\", modules.len()));\n        index.push_str(&format!(\"- Unique imports captured: {}\\n\", total_imports));\n        index.push_str(&format!(\"- Unique exports captured: {}\\n\", total_exports));\n        index.push_str(&format!(\n            \"- Submodule declarations captured: {}\\n\\n\",\n            total_submodules\n        ));\n        index.push_str(\"## Per-file Summary\\n\\n\");\n        for (file_path, module) in &modules {\n            let compressed = compress_path(file_path);\n            index.push_str(&format!(\n                \"- `{}`  module `{}` (layer {}, {} imports / {} exports / {} submodules)\\n\",\n                compressed,\n                module.name,\n                module.layer,\n                module.imports.len(),\n                module.exports.len(),\n                module.submodules.len()\n            ));\n        }\n        index.push_str(\n            \"\\n## Detailed Files\\n\\n- `010-imports.md`  expanded import lists\\n- `020-exports.md`  export statements\\n- `030-submodules.md`  nested module declarations\\n- `040-violations.md`  placeholder for future per-module violations\\n\",\n        );\n        fs::write(&index_path, index)?;\n\n        let mut imports_doc = String::from(\"# Module Imports\\n\\n\");\n        let mut has_imports = false;\n        for (file_path, module) in &modules {\n            if module.imports.is_empty() {\n                continue;\n            }\n            has_imports = true;\n            let compressed = compress_path(file_path);\n            imports_doc.push_str(&format!(\"## {} ({})\\n\\n\", compressed, module.layer));\n            imports_doc.push_str(&format!(\"Module `{}`\\n\\n\", module.name));\n            for import in &module.imports {\n                imports_doc.push_str(&format!(\"- `{}`\\n\", import));\n            }\n            imports_doc.push('\\n');\n        }\n        if !has_imports {\n            imports_doc.push_str(\"No imports captured across modules.\\n\");\n        }\n        fs::write(dir.join(\"010-imports.md\"), imports_doc)?;\n\n        let mut exports_doc = String::from(\"# Module Exports\\n\\n\");\n        let mut has_exports = false;\n        for (file_path, module) in &modules {\n            if module.exports.is_empty() {\n                continue;\n            }\n            has_exports = true;\n            let compressed = compress_path(file_path);\n            exports_doc.push_str(&format!(\"## {} ({})\\n\\n\", compressed, module.layer));\n            exports_doc.push_str(&format!(\"Module `{}`\\n\\n\", module.name));\n            for export in &module.exports {\n                exports_doc.push_str(&format!(\"- `{}`\\n\", export));\n            }\n            exports_doc.push('\\n');\n        }\n        if !has_exports {\n            exports_doc.push_str(\"No exports captured across modules.\\n\");\n        }\n        fs::write(dir.join(\"020-exports.md\"), exports_doc)?;\n\n        let mut subs_doc = String::from(\"# Submodules\\n\\n\");\n        let mut has_submodules = false;\n        for (file_path, module) in &modules {\n            if module.submodules.is_empty() {\n                continue;\n            }\n            has_submodules = true;\n            let compressed = compress_path(file_path);\n            subs_doc.push_str(&format!(\"## {} ({})\\n\\n\", compressed, module.layer));\n            subs_doc.push_str(&format!(\"Module `{}`\\n\\n\", module.name));\n            for sub in &module.submodules {\n                subs_doc.push_str(&format!(\"- `{}`\\n\", sub));\n            }\n            subs_doc.push('\\n');\n        }\n        if !has_submodules {\n            subs_doc.push_str(\"No nested modules recorded.\\n\");\n        }\n        fs::write(dir.join(\"030-submodules.md\"), subs_doc)?;\n\n        let mut violations_doc = String::from(\"# Module Violations\\n\\n\");\n        violations_doc.push_str(\n            \"Per-module import/export violations are not computed yet.\\n\\\nRefer to `60_layer_dependencies/index.md` for cross-layer problems.\\n\",\n        );\n        fs::write(dir.join(\"040-violations.md\"), violations_doc)?;\n\n        Ok(())\n    }\n\n    fn generate_module_map_mismatch(&self, root_path: &Path) -> Result<()> {\n        let dir = self.prepare_report_dir(\"41_module_map_mismatch\")?;\n        let index_path = dir.join(\"index.md\");\n        let src_root = crate::layer_utilities::resolve_source_root(root_path);\n        let rust_files = crate::cluster_010::gather_rust_files(root_path)\n            .into_iter()\n            .filter(|path| path.starts_with(&src_root))\n            .collect::<Vec<_>>();\n\n        let mut missing_modules = Vec::new();\n        let mut ambiguous_modules = Vec::new();\n        let mut outside_root = Vec::new();\n        let mut mod_decl_count = 0usize;\n\n        for file in &rust_files {\n            let Ok(content) = fs::read_to_string(file) else {\n                continue;\n            };\n            let parent_dir = file.parent().unwrap_or(&src_root);\n            let mut pending_path: Option<String> = None;\n\n            for (idx, line) in content.lines().enumerate() {\n                let trimmed = line.trim();\n                if let Some(path_attr) = extract_path_attr(trimmed) {\n                    pending_path = Some(path_attr);\n                    continue;\n                }\n\n                if trimmed.starts_with(\"#[\") || trimmed.is_empty() || trimmed.starts_with(\"//\") {\n                    continue;\n                }\n\n                if let Some(module) = parse_mod_decl(trimmed) {\n                    mod_decl_count += 1;\n                    let line_no = idx + 1;\n                    let path_attr = pending_path.take();\n\n                    if let Some(attr) = path_attr {\n                        let resolved = resolve_path_attr(parent_dir, &attr);\n                        if !resolved.starts_with(&src_root) {\n                            outside_root.push(ModuleIssue {\n                                parent_file: file.clone(),\n                                module: module.clone(),\n                                line: line_no,\n                                details: vec![resolved],\n                                note: format!(\"path attribute `{}` resolves outside src root\", attr),\n                                kind: ModuleIssueKind::PathOutsideRoot,\n                            });\n                            continue;\n                        }\n                        if !resolved.is_file() {\n                            missing_modules.push(ModuleIssue {\n                                parent_file: file.clone(),\n                                module,\n                                line: line_no,\n                                details: vec![resolved],\n                                note: format!(\"path attribute `{}` missing\", attr),\n                                kind: ModuleIssueKind::MissingPathAttr,\n                            });\n                        }\n                        continue;\n                    }\n\n                    let direct = parent_dir.join(format!(\"{}.rs\", module));\n                    let nested = parent_dir.join(&module).join(\"mod.rs\");\n                    let direct_exists = direct.is_file();\n                    let nested_exists = nested.is_file();\n\n                    if direct_exists && nested_exists {\n                        ambiguous_modules.push(ModuleIssue {\n                            parent_file: file.clone(),\n                            module,\n                            line: line_no,\n                            details: vec![direct, nested],\n                            note: \"both module paths exist\".to_string(),\n                            kind: ModuleIssueKind::AmbiguousModulePaths,\n                        });\n                    } else if !direct_exists && !nested_exists {\n                        missing_modules.push(ModuleIssue {\n                            parent_file: file.clone(),\n                            module,\n                            line: line_no,\n                            details: vec![direct, nested],\n                            note: \"no module file found\".to_string(),\n                            kind: ModuleIssueKind::MissingModuleFile,\n                        });\n                    }\n                } else {\n                    pending_path = None;\n                }\n            }\n        }\n\n        missing_modules.sort_by(|a, b| (a.parent_file.cmp(&b.parent_file)).then(a.module.cmp(&b.module)));\n        ambiguous_modules.sort_by(|a, b| (a.parent_file.cmp(&b.parent_file)).then(a.module.cmp(&b.module)));\n        outside_root.sort_by(|a, b| (a.parent_file.cmp(&b.parent_file)).then(a.module.cmp(&b.module)));\n\n        let mut index = String::from(\"# Module Map Mismatch\\n\\n\");\n        index.push_str(\"Action: Review only. Detection-only report.\\n\\n\");\n        index.push_str(&format!(\n            \"- Rust files scanned: {}\\n\",\n            rust_files.len()\n        ));\n        index.push_str(&format!(\n            \"- mod declarations scanned: {}\\n\",\n            mod_decl_count\n        ));\n        index.push_str(&format!(\n            \"- Missing module files: {}\\n\",\n            missing_modules.len()\n        ));\n        index.push_str(&format!(\n            \"- Ambiguous module paths: {}\\n\",\n            ambiguous_modules.len()\n        ));\n        index.push_str(&format!(\n            \"- #[path] outside src root: {}\\n\\n\",\n            outside_root.len()\n        ));\n\n        if missing_modules.is_empty() && ambiguous_modules.is_empty() && outside_root.is_empty() {\n            index.push_str(\"No module map mismatches detected.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        }\n\n        if !missing_modules.is_empty() {\n            index.push_str(\"## Missing Module Files\\n\\n\");\n            for issue in &missing_modules {\n                let parent = compress_path(issue.parent_file.to_string_lossy().as_ref());\n                index.push_str(&format!(\n                    \"- `{}`:{} `mod {}`  {} ({})\\n\",\n                    parent,\n                    issue.line,\n                    issue.module,\n                    format_paths(&issue.details),\n                    issue.note\n                ));\n                index.push_str(&format!(\"  Plan: {}\\n\", issue_plan_summary(issue)));\n            }\n            index.push('\\n');\n        }\n\n        if !ambiguous_modules.is_empty() {\n            index.push_str(\"## Ambiguous Module Paths\\n\\n\");\n            for issue in &ambiguous_modules {\n                let parent = compress_path(issue.parent_file.to_string_lossy().as_ref());\n                index.push_str(&format!(\n                    \"- `{}`:{} `mod {}`  {} ({})\\n\",\n                    parent,\n                    issue.line,\n                    issue.module,\n                    format_paths(&issue.details),\n                    issue.note\n                ));\n                index.push_str(&format!(\"  Plan: {}\\n\", issue_plan_summary(issue)));\n            }\n            index.push('\\n');\n        }\n\n        if !outside_root.is_empty() {\n            index.push_str(\"## #[path] Outside Source Root\\n\\n\");\n            for issue in &outside_root {\n                let parent = compress_path(issue.parent_file.to_string_lossy().as_ref());\n                index.push_str(&format!(\n                    \"- `{}`:{} `mod {}`  {} ({})\\n\",\n                    parent,\n                    issue.line,\n                    issue.module,\n                    format_paths(&issue.details),\n                    issue.note\n                ));\n                index.push_str(&format!(\"  Plan: {}\\n\", issue_plan_summary(issue)));\n            }\n            index.push('\\n');\n        }\n\n        fs::write(index_path, index)?;\n        Ok(())\n    }\n\n    fn generate_test_topology(&self, root_path: &Path) -> Result<()> {\n        let dir = self.prepare_report_dir(\"42_test_topology\")?;\n        let index_path = dir.join(\"index.md\");\n        let src_root = crate::layer_utilities::resolve_source_root(root_path);\n\n        let rust_files = crate::cluster_010::gather_rust_files(root_path)\n            .into_iter()\n            .filter(|path| path.starts_with(&src_root))\n            .collect::<Vec<_>>();\n        let test_files = gather_test_files(root_path);\n\n        let mut issues = Vec::new();\n\n        for file in &rust_files {\n            let Ok(content) = fs::read_to_string(file) else {\n                continue;\n            };\n            let mut pending_attrs: Vec<String> = Vec::new();\n            let mut file_has_submodules = false;\n            let mut file_has_cfg_tests = false;\n\n            for (idx, line) in content.lines().enumerate() {\n                let trimmed = line.trim();\n                if trimmed.is_empty() || trimmed.starts_with(\"//\") {\n                    continue;\n                }\n                if trimmed.starts_with(\"#[\") {\n                    pending_attrs.push(trimmed.to_string());\n                    continue;\n                }\n\n                if let Some(mod_name) = parse_mod_decl(trimmed) {\n                    if mod_name != \"tests\" {\n                        file_has_submodules = true;\n                    }\n                }\n\n                if is_mod_tests_decl(trimmed) {\n                    let line_no = idx + 1;\n                    if !has_cfg_test_attr(&pending_attrs) {\n                        issues.push(TestTopologyIssue {\n                            file: file.clone(),\n                            line: line_no,\n                            kind: TestIssueKind::TestsWithoutCfg,\n                            note: \"mod tests without #[cfg(test)]\".to_string(),\n                        });\n                    } else {\n                        file_has_cfg_tests = true;\n                    }\n                }\n\n                pending_attrs.clear();\n            }\n\n            if file_has_cfg_tests && file_has_submodules {\n                issues.push(TestTopologyIssue {\n                    file: file.clone(),\n                    line: 0,\n                    kind: TestIssueKind::CfgTestsInNonLeaf,\n                    note: \"cfg(test) block in module with submodules\".to_string(),\n                });\n            }\n        }\n\n        for file in &test_files {\n            let Ok(content) = fs::read_to_string(file) else {\n                continue;\n            };\n            for (idx, line) in content.lines().enumerate() {\n                let trimmed = line.trim();\n                if trimmed.starts_with(\"use crate::\") {\n                    issues.push(TestTopologyIssue {\n                        file: file.clone(),\n                        line: idx + 1,\n                        kind: TestIssueKind::IntegrationUsesCratePath,\n                        note: \"integration test uses crate:: path (check crate name)\".to_string(),\n                    });\n                }\n                if trimmed.starts_with(\"use super::\") {\n                    issues.push(TestTopologyIssue {\n                        file: file.clone(),\n                        line: idx + 1,\n                        kind: TestIssueKind::IntegrationUsesSuper,\n                        note: \"integration test uses super:: (invalid module path)\".to_string(),\n                    });\n                }\n            }\n        }\n\n        issues.sort_by(|a, b| {\n            a.file\n                .cmp(&b.file)\n                .then(a.line.cmp(&b.line))\n                .then(a.kind.cmp(&b.kind))\n        });\n\n        let mut index = String::from(\"# Test Topology\\n\\n\");\n        index.push_str(\"Action: Review only. Detection-only report.\\n\\n\");\n        index.push_str(&format!(\n            \"- Rust source files scanned: {}\\n\",\n            rust_files.len()\n        ));\n        index.push_str(&format!(\n            \"- Integration test files scanned: {}\\n\",\n            test_files.len()\n        ));\n        index.push_str(&format!(\"- Issues detected: {}\\n\\n\", issues.len()));\n\n        if issues.is_empty() {\n            index.push_str(\"No test topology issues detected.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        }\n\n        let mut grouped: BTreeMap<TestIssueKind, Vec<&TestTopologyIssue>> = BTreeMap::new();\n        for issue in &issues {\n            grouped.entry(issue.kind).or_default().push(issue);\n        }\n\n        for (kind, entries) in grouped {\n            index.push_str(&format!(\"## {}\\n\\n\", kind.label()));\n            for issue in entries {\n                let file = compress_path(issue.file.to_string_lossy().as_ref());\n                if issue.line == 0 {\n                    index.push_str(&format!(\n                        \"- `{}`  {} (review_only)\\n\",\n                        file, issue.note\n                    ));\n                } else {\n                    index.push_str(&format!(\n                        \"- `{}`:{}  {} (review_only)\\n\",\n                        file, issue.line, issue.note\n                    ));\n                }\n            }\n            index.push('\\n');\n        }\n\n        fs::write(index_path, index)?;\n        Ok(())\n    }\n\n    fn generate_warning_hygiene(&self, root_path: &Path) -> Result<()> {\n        let dir = self.prepare_report_dir(\"43_warning_hygiene\")?;\n        let index_path = dir.join(\"index.md\");\n        let output_dir = Path::new(&self.output_dir);\n        let candidates = [\n            output_dir.join(\"cargo_warnings.txt\"),\n            root_path.join(\"cargo_warnings.txt\"),\n        ];\n        let warnings_path = candidates.iter().find(|p| p.exists());\n\n        let mut index = String::from(\"# Warning Hygiene\\n\\n\");\n        index.push_str(\"Action: Review only. Detection-only report.\\n\\n\");\n\n        let Some(path) = warnings_path else {\n            index.push_str(\"No cargo_warnings.txt found.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        };\n\n        let content = fs::read_to_string(path).unwrap_or_default();\n        let warnings = parse_cargo_warnings(&content);\n\n        index.push_str(&format!(\"- Source: `{}`\\n\", compress_path(path.to_string_lossy().as_ref())));\n        index.push_str(&format!(\"- Warnings parsed: {}\\n\\n\", warnings.len()));\n\n        if warnings.is_empty() {\n            index.push_str(\"No warnings detected.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        }\n\n        let mut by_message: BTreeMap<String, usize> = BTreeMap::new();\n        for warning in &warnings {\n            *by_message.entry(warning.message.clone()).or_insert(0) += 1;\n        }\n\n        index.push_str(\"## Warning Types\\n\\n\");\n        for (message, count) in &by_message {\n            index.push_str(&format!(\"- {} ({} occurrences)\\n\", message, count));\n        }\n        index.push('\\n');\n\n        index.push_str(\"## Warning Details\\n\\n\");\n        for warning in &warnings {\n            let location = if let Some(loc) = warning.location.as_ref() {\n                format!(\"{}:{}\", compress_path(loc.file.to_string_lossy().as_ref()), loc.line)\n            } else {\n                \"unknown\".to_string()\n            };\n            index.push_str(&format!(\n                \"- `{}`  {}\\n\",\n                location, warning.message\n            ));\n        }\n        index.push('\\n');\n\n        fs::write(index_path, index)?;\n        Ok(())\n    }\n\n    fn generate_function_analysis(&self, result: &AnalysisResult) -> Result<()> {\n        let dir = self.prepare_report_dir(\"50_function_analysis\")?;\n        let mut index = String::from(\"# Function Analysis\\n\\n\");\n\n        let functions: Vec<_> = result\n            .elements\n            .iter()\n            .filter(|e| matches!(e.element_type, ElementType::Function))\n            .collect();\n\n        index.push_str(&format!(\"## Total Functions: {}\\n\\n\", functions.len()));\n        index.push_str(\n            \"Functions are bucketed alphabetically so `ls 50_function_analysis/` advertises the range.\\n\\n\",\n        );\n\n        if functions.is_empty() {\n            fs::write(dir.join(\"index.md\"), index)?;\n            return Ok(());\n        }\n\n        let bucket_labels = [\"A-F\", \"G-M\", \"N-S\", \"T-Z\", \"Other\"];\n        let mut buckets: HashMap<&'static str, Vec<&CodeElement>> = HashMap::new();\n        for label in bucket_labels {\n            buckets.insert(label, Vec::new());\n        }\n\n        for func in &functions {\n            let label = function_bucket_label(&func.name);\n            buckets.entry(label).or_insert_with(Vec::new).push(func);\n        }\n\n        index.push_str(\"## Bucket Files\\n\\n\");\n        for (idx, label) in bucket_labels.iter().enumerate() {\n            let file_name = format!(\"{:03}-functions_{}.md\", (idx + 1) * 10, label);\n            let count = buckets.get(label).map(|v| v.len()).unwrap_or(0);\n            index.push_str(&format!(\n                \"- `{}`  `{}` ({} functions)\\n\",\n                label, file_name, count\n            ));\n        }\n        fs::write(dir.join(\"index.md\"), index)?;\n\n        for (idx, label) in bucket_labels.iter().enumerate() {\n            let mut funcs = buckets.remove(label).unwrap_or_default();\n            funcs.sort_by_key(|f| (&f.layer, &f.name));\n            let file_name = format!(\"{:03}-functions_{}.md\", (idx + 1) * 10, label);\n            let mut content = format!(\"# Functions {}\\n\\n\", label);\n\n            if funcs.is_empty() {\n                content.push_str(\"No functions fell into this range.\\n\");\n                fs::write(dir.join(file_name), content)?;\n                continue;\n            }\n\n            let mut layer_map: BTreeMap<String, Vec<&CodeElement>> = BTreeMap::new();\n            for func in funcs {\n                layer_map\n                    .entry(func.layer.clone())\n                    .or_insert_with(Vec::new)\n                    .push(func);\n            }\n\n            for (layer, entries) in layer_map {\n                content.push_str(&format!(\"## Layer: {}\\n\\n\", layer));\n\n                let mut rust_funcs: Vec<_> = entries\n                    .iter()\n                    .filter(|f| matches!(f.language, Language::Rust))\n                    .collect();\n                let mut julia_funcs: Vec<_> = entries\n                    .iter()\n                    .filter(|f| matches!(f.language, Language::Julia))\n                    .collect();\n\n                rust_funcs.sort_by_key(|f| &f.name);\n                julia_funcs.sort_by_key(|f| &f.name);\n\n                if !rust_funcs.is_empty() {\n                    content.push_str(\"### Rust Functions\\n\\n\");\n                    for func in rust_funcs {\n                        content.push_str(&format!(\"#### `{}`\\n\\n\", func.name));\n                        let compressed = compress_path(&func.file_path);\n                        content.push_str(&format!(\n                            \"- **File:** {}:{}\\n\",\n                            compressed, func.line_number\n                        ));\n                        content.push_str(&format!(\"- **Visibility:** {:?}\\n\", func.visibility));\n\n                        if !func.generic_params.is_empty() {\n                            content.push_str(&format!(\n                                \"- **Generics:** {}\\n\",\n                                func.generic_params.join(\", \")\n                            ));\n                        }\n\n                        if !func.calls.is_empty() {\n                            content.push_str(\"- **Calls:**\\n\");\n                            for call in &func.calls {\n                                content.push_str(&format!(\"  - `{}`\\n\", call));\n                            }\n                        }\n                        content.push_str(\"\\n\");\n                    }\n                }\n\n                if !julia_funcs.is_empty() {\n                    content.push_str(\"### Julia Functions\\n\\n\");\n                    for func in julia_funcs {\n                        content.push_str(&format!(\"#### `{}`\\n\\n\", func.name));\n                        let compressed = compress_path(&func.file_path);\n                        content.push_str(&format!(\n                            \"- **File:** {}:{}\\n\",\n                            compressed, func.line_number\n                        ));\n                        content.push_str(&format!(\"- **Signature:** `{}`\\n\", func.signature));\n\n                        if !func.calls.is_empty() {\n                            content.push_str(\"- **Calls:**\\n\");\n                            for call in &func.calls {\n                                content.push_str(&format!(\"  - `{}`\\n\", call));\n                            }\n                        }\n                        content.push_str(\"\\n\");\n                    }\n                }\n            }\n\n            fs::write(dir.join(file_name), content)?;\n        }\n\n        Ok(())\n    }\n\n    fn extract_layer_from_path(&self, path: &str) -> String {\n        for component in path.split('/') {\n            if component\n                .chars()\n                .next()\n                .map_or(false, |c| c.is_ascii_digit())\n            {\n                if let Some(pos) = component.find('_') {\n                    if component[..pos].chars().all(|c| c.is_ascii_digit()) {\n                        return component.to_string();\n                    }\n                }\n            }\n        }\n        \"root\".to_string()\n    }\n\n    fn dot_path_for(&self, compressed_path: &str) -> Option<String> {\n        let slug = slugify_file_path(compressed_path);\n        let rel = format!(\"30_cfg/dots/{}/call_graph.dot\", slug);\n        let absolute = Path::new(&self.output_dir).join(&rel);\n        if absolute.exists() {\n            Some(rel)\n        } else {\n            None\n        }\n    }\n}\n\nfn prefix_key_from_path(path: &str) -> String {\n    let relative = path.strip_prefix(\"MMSB/\").unwrap_or(path);\n    if relative.is_empty() {\n        return \"root\".to_string();\n    }\n    let parts: Vec<&str> = relative.split('/').collect();\n    if parts.len() == 1 {\n        return \"root\".to_string();\n    }\n    if parts[0] == \"src\" && parts.len() >= 2 {\n        return format!(\"{}/{}\", parts[0], parts[1]);\n    }\n    parts[0].to_string()\n}\n\nfn slugify_key(input: &str) -> String {\n    input\n        .chars()\n        .map(|c| match c {\n            '/' => '-',\n            ' ' => '_',\n            _ if c.is_ascii_alphanumeric() || c == '-' => c.to_ascii_lowercase(),\n            _ => '_',\n        })\n        .collect()\n}\n\nfn group_key_cmp(a: &str, b: &str) -> Ordering {\n    match (a == \"root\", b == \"root\") {\n        (true, true) => Ordering::Equal,\n        (true, false) => Ordering::Less,\n        (false, true) => Ordering::Greater,\n        _ => a.cmp(b),\n    }\n}\n\nfn function_bucket_label(name: &str) -> &'static str {\n    let first = name\n        .chars()\n        .find(|c| c.is_ascii_alphabetic())\n        .map(|c| c.to_ascii_uppercase())\n        .unwrap_or('#');\n\n    match first {\n        'A'..='F' => \"A-F\",\n        'G'..='M' => \"G-M\",\n        'N'..='S' => \"N-S\",\n        'T'..='Z' => \"T-Z\",\n        _ => \"Other\",\n    }\n}\n\nfn slugify_file_path(path: &str) -> String {\n    path.trim_start_matches(\"MMSB/\")\n        .replace('/', \"-\")\n        .replace('.', \"_\")\n        .to_lowercase()\n}\n\nfn language_label(language: &Language) -> &'static str {\n    match language {\n        Language::Rust => \"Rust\",\n        Language::Julia => \"Julia\",\n    }\n}\n\nfn visibility_label(vis: &Visibility) -> &'static str {\n    match vis {\n        Visibility::Public => \"pub\",\n        Visibility::Crate => \"pub(crate)\",\n        Visibility::Private => \"priv\",\n    }\n}\n\nfn short_signature(input: &str) -> String {\n    let collapsed = input.split_whitespace().collect::<Vec<_>>().join(\" \");\n    if collapsed.len() > 120 {\n        let mut truncated = collapsed.chars().take(117).collect::<String>();\n        truncated.push_str(\"...\");\n        truncated\n    } else {\n        collapsed\n    }\n}\n\nstruct ModuleAggregate {\n    name: String,\n    layer: String,\n    imports: BTreeSet<String>,\n    exports: BTreeSet<String>,\n    submodules: BTreeSet<String>,\n}\n\nimpl ModuleAggregate {\n    fn new(name: String, layer: String) -> Self {\n        Self {\n            name: if name.is_empty() {\n                \"unknown\".to_string()\n            } else {\n                name\n            },\n            layer,\n            imports: BTreeSet::new(),\n            exports: BTreeSet::new(),\n            submodules: BTreeSet::new(),\n        }\n    }\n}\n\n#[derive(Clone)]\nstruct ModuleIssue {\n    parent_file: PathBuf,\n    module: String,\n    line: usize,\n    details: Vec<PathBuf>,\n    note: String,\n    kind: ModuleIssueKind,\n}\n\n#[derive(Clone, Copy)]\nenum ModuleIssueKind {\n    MissingModuleFile,\n    MissingPathAttr,\n    AmbiguousModulePaths,\n    PathOutsideRoot,\n}\n\nfn extract_path_attr(line: &str) -> Option<String> {\n    if !line.trim_start().starts_with(\"#[path\") {\n        return None;\n    }\n    let start = line.find('\"')?;\n    let rest = &line[start + 1..];\n    let end = rest.find('\"')?;\n    Some(rest[..end].to_string())\n}\n\nfn parse_mod_decl(line: &str) -> Option<String> {\n    let mut rest = line.trim_start();\n    if rest.starts_with(\"pub \") {\n        rest = rest.trim_start_matches(\"pub \").trim_start();\n    } else if rest.starts_with(\"pub(\") {\n        let end = rest.find(')')?;\n        rest = rest[end + 1..].trim_start();\n    }\n    if !rest.starts_with(\"mod \") {\n        return None;\n    }\n    rest = rest.trim_start_matches(\"mod \").trim_start();\n    let name: String = rest\n        .chars()\n        .take_while(|c| c.is_alphanumeric() || *c == '_')\n        .collect();\n    if name.is_empty() {\n        return None;\n    }\n    let semicolon = rest.find(';');\n    let brace = rest.find('{');\n    if brace.is_some() && (semicolon.is_none() || brace.unwrap() < semicolon.unwrap()) {\n        return None;\n    }\n    if semicolon.is_none() {\n        return None;\n    }\n    Some(name)\n}\n\nfn resolve_path_attr(parent_dir: &Path, attr: &str) -> PathBuf {\n    let candidate = PathBuf::from(attr);\n    if candidate.is_absolute() {\n        candidate\n    } else {\n        parent_dir.join(candidate)\n    }\n}\n\nfn format_paths(paths: &[PathBuf]) -> String {\n    let mut items = paths\n        .iter()\n        .map(|p| compress_path(p.to_string_lossy().as_ref()))\n        .collect::<Vec<_>>();\n    items.sort();\n    items.join(\", \")\n}\n\nfn issue_plan_summary(issue: &ModuleIssue) -> String {\n    match issue.kind {\n        ModuleIssueKind::MissingModuleFile => {\n            \"review_only. options: keep_as_is | add_mod_declaration | add_module_file\".to_string()\n        }\n        ModuleIssueKind::MissingPathAttr => {\n            \"review_only. options: keep_as_is | update_path_attr | remove_mod_decl\".to_string()\n        }\n        ModuleIssueKind::AmbiguousModulePaths => {\n            \"review_only. options: keep_as_is | choose_flat_file | choose_nested_mod\".to_string()\n        }\n        ModuleIssueKind::PathOutsideRoot => {\n            \"review_only. options: keep_as_is | relocate_module | update_path_attr\".to_string()\n        }\n    }\n}\n\n#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\nenum TestIssueKind {\n    TestsWithoutCfg,\n    CfgTestsInNonLeaf,\n    IntegrationUsesCratePath,\n    IntegrationUsesSuper,\n}\n\nimpl TestIssueKind {\n    fn label(self) -> &'static str {\n        match self {\n            TestIssueKind::TestsWithoutCfg => \"Inline tests missing #[cfg(test)]\",\n            TestIssueKind::CfgTestsInNonLeaf => \"cfg(test) in non-leaf module\",\n            TestIssueKind::IntegrationUsesCratePath => \"Integration tests using crate::\",\n            TestIssueKind::IntegrationUsesSuper => \"Integration tests using super::\",\n        }\n    }\n}\n\nstruct TestTopologyIssue {\n    file: PathBuf,\n    line: usize,\n    kind: TestIssueKind,\n    note: String,\n}\n\nfn has_cfg_test_attr(attrs: &[String]) -> bool {\n    attrs.iter().any(|attr| attr.contains(\"cfg(test)\"))\n}\n\nfn is_mod_tests_decl(line: &str) -> bool {\n    let trimmed = line.trim_start();\n    if trimmed.starts_with(\"mod tests\") {\n        return trimmed.contains(';') || trimmed.contains('{');\n    }\n    if trimmed.starts_with(\"pub mod tests\") {\n        return trimmed.contains(';') || trimmed.contains('{');\n    }\n    false\n}\n\nfn gather_test_files(root_path: &Path) -> Vec<PathBuf> {\n    let tests_dir = root_path.join(\"tests\");\n    if !tests_dir.is_dir() {\n        return Vec::new();\n    }\n    WalkDir::new(&tests_dir)\n        .into_iter()\n        .filter_map(|entry| entry.ok())\n        .filter(|entry| entry.path().extension().map_or(false, |ext| ext == \"rs\"))\n        .map(|entry| entry.into_path())\n        .collect()\n}\n\nstruct WarningLocation {\n    file: PathBuf,\n    line: usize,\n}\n\nstruct WarningEntry {\n    message: String,\n    location: Option<WarningLocation>,\n}\n\nfn parse_cargo_warnings(content: &str) -> Vec<WarningEntry> {\n    let mut warnings = Vec::new();\n    let mut pending_message: Option<String> = None;\n\n    for line in content.lines() {\n        let trimmed = line.trim_start();\n        if let Some(msg) = trimmed.strip_prefix(\"warning:\") {\n            let message = msg.trim().to_string();\n            pending_message = Some(message);\n            continue;\n        }\n\n        if let Some(rest) = trimmed.strip_prefix(\"-->\") {\n            if let Some(message) = pending_message.take() {\n                if let Some(location) = parse_location(rest.trim()) {\n                    warnings.push(WarningEntry {\n                        message,\n                        location: Some(location),\n                    });\n                } else {\n                    warnings.push(WarningEntry {\n                        message,\n                        location: None,\n                    });\n                }\n            }\n            continue;\n        }\n\n        if trimmed.is_empty() && pending_message.is_some() {\n            let message = pending_message.take().unwrap_or_default();\n            warnings.push(WarningEntry {\n                message,\n                location: None,\n            });\n        }\n    }\n\n    if let Some(message) = pending_message.take() {\n        warnings.push(WarningEntry {\n            message,\n            location: None,\n        });\n    }\n\n    warnings\n}\n\nfn parse_location(raw: &str) -> Option<WarningLocation> {\n    let parts: Vec<&str> = raw.split(':').collect();\n    if parts.len() < 3 {\n        return None;\n    }\n    let file = parts[0].trim();\n    let line = parts[1].trim().parse::<usize>().ok()?;\n    Some(WarningLocation {\n        file: PathBuf::from(file),\n        line,\n    })\n}\n\nfn normalize_use_stmt(stmt: &str) -> String {\n    let collapsed = stmt.replace('\\n', \" \");\n    let mut cleaned = collapsed.split_whitespace().collect::<Vec<_>>().join(\" \");\n    if let Some(idx) = cleaned.find(';') {\n        cleaned.truncate(idx);\n    }\n    cleaned = cleaned.trim().to_string();\n    if cleaned.starts_with(\"pub\") {\n        if let Some(pos) = cleaned.find(' ') {\n            cleaned = cleaned[pos + 1..].trim().to_string();\n        }\n    }\n    if let Some(stripped) = cleaned.strip_prefix(\"use \") {\n        cleaned = stripped.trim().to_string();\n    }\n    cleaned\n}\n\nfn sanitize_mermaid_id(input: &str) -> String {\n    input\n        .chars()\n        .map(|c| if c.is_ascii_alphanumeric() { c } else { '_' })\n        .collect()\n}\n\nfn sanitize_mermaid_label(label: &str) -> String {\n    label.replace('\"', \"'\").replace('`', \"'\")\n}\n\npub fn compress_path(path: &str) -> String {\n    // Find MMSB in the path and return everything from there\n    if let Some(idx) = path.find(\"/MMSB/\") {\n        return format!(\"MMSB{}\", &path[idx + 5..]);\n    }\n    // If already starts with MMSB/, return as-is\n    if path.starts_with(\"MMSB/\") {\n        return path.to_string();\n    }\n    // Fallback: try to find src/ or other common markers\n    if let Some(idx) = path.rfind(\"/src/\") {\n        return format!(\"MMSB/src{}\", &path[idx + 4..]);\n    }\n    // Last resort: return original\n    path.to_string()\n}\n\npub fn collect_directory_files(directory: &DirectoryAnalysis, out: &mut Vec<PathBuf>) {\n    out.extend(directory.files.iter().cloned());\n    for sub in &directory.subdirectories {\n        collect_directory_files(sub, out);\n    }\n}\n\npub fn path_common_prefix_len(a: &Path, b: &Path) -> isize {\n    let mut count = 0isize;\n    for (a_comp, b_comp) in a.components().zip(b.components()) {\n        if a_comp == b_comp {\n            count += 1;\n        } else {\n            break;\n        }\n    }\n    count\n}\n\npub fn compute_move_metrics(\n    placement: &FunctionPlacement,\n) -> (usize, usize, usize, usize, Vec<PathBuf>, Vec<PathBuf>) {\n    let incoming_calls = placement\n        .call_analysis\n        .calls_from_other_files\n        .iter()\n        .map(|(_, count)| *count)\n        .sum::<usize>();\n    let callers = placement.call_analysis.calls_from_other_files.len();\n    let mut touched = BTreeSet::new();\n    touched.insert(placement.current_file.clone());\n    let mut outgoing_files = Vec::new();\n    for (path, _) in &placement.call_analysis.inter_file_calls {\n        touched.insert(path.clone());\n        outgoing_files.push(path.clone());\n    }\n    let mut caller_files = Vec::new();\n    for (path, _) in &placement.call_analysis.calls_from_other_files {\n        touched.insert(path.clone());\n        caller_files.push(path.clone());\n    }\n    let cost = touched.len().max(1);\n    let benefit = 1 + callers;\n    (incoming_calls, benefit, cost, callers, caller_files, outgoing_files)\n}\n\npub fn generate_canonical_name(path: &Path, number: usize) -> String {\n    let stem = path\n        .file_stem()\n        .and_then(|s| s.to_str())\n        .unwrap_or(\"unknown\");\n    let ext = path\n        .extension()\n        .and_then(|s| s.to_str())\n        .unwrap_or(\"\");\n    let clean_stem = strip_numeric_prefix(stem);\n    if ext.is_empty() {\n        format!(\"{:03}_{}\", number, clean_stem)\n    } else {\n        format!(\"{:03}_{}.{}\", number, clean_stem, ext)\n    }\n}\n\npub fn collect_directory_moves(\n    ordering: &crate::types::FileOrderingResult,\n    root_path: &Path,\n) -> Vec<crate::file_ordering::DirectoryMove> {\n    let mut moves = Vec::new();\n    let mut by_parent: BTreeMap<PathBuf, Vec<PathBuf>> = BTreeMap::new();\n    let src_dir = root_path.join(\"src\");\n\n    for dir in &ordering.ordered_directories {\n        if dir == root_path {\n            continue;\n        }\n        if dir == &src_dir {\n            continue;\n        }\n        if let Some(parent) = dir.parent() {\n            by_parent\n                .entry(parent.to_path_buf())\n                .or_default()\n                .push(dir.clone());\n        }\n    }\n\n    for (parent, mut dirs) in by_parent {\n        dirs.sort_by(|a, b| crate::cluster_008::compare_dir_layers(a, b));\n        for (idx, dir) in dirs.iter().enumerate() {\n            let Some(name) = dir.file_name().and_then(|n| n.to_str()) else {\n                continue;\n            };\n            let clean = strip_numeric_prefix(name);\n            let suggested = format!(\"{:03}_{}\", idx * 10, clean);\n            if name == suggested {\n                continue;\n            }\n            let to = parent.join(&suggested);\n            moves.push(crate::file_ordering::DirectoryMove {\n                from: dir.clone(),\n                to,\n            });\n        }\n    }\n\n    moves\n}\n\npub fn write_structural_batches(content: &mut String, items: &[PlanItem]) {\n    if items.is_empty() {\n        return;\n    }\n\n    let mut ordered_targets = Vec::new();\n    let mut batches: HashMap<PathBuf, Vec<&PlanItem>> = HashMap::new();\n    for item in items {\n        let Some(target) = &item.target_file else {\n            continue;\n        };\n        let entry = batches.entry(target.clone()).or_default();\n        if entry.is_empty() {\n            ordered_targets.push(target.clone());\n        }\n        entry.push(item);\n    }\n\n    content.push_str(\"### Phase 3 Batches\\n\\n\");\n    content.push_str(\"Action: execute batches in order and verify after each batch.\\n\");\n    content.push_str(\"Note: each batch targets one destination module.\\n\\n\");\n    for (idx, target) in ordered_targets.iter().enumerate() {\n        let empty: Vec<&PlanItem> = Vec::new();\n        let items = batches.get(target).unwrap_or(&empty);\n        content.push_str(&format!(\n            \"#### Batch {}: target `{}`\\n\\n\",\n            idx + 1,\n            compress_path(target.to_string_lossy().as_ref())\n        ));\n        content.push_str(\"Action: move the listed functions into the target module.\\n\");\n        content.push_str(\"Note: use the rg commands to locate definitions and callers.\\n\\n\");\n        let mut commands: Vec<String> = Vec::new();\n        if !target.exists() {\n            let target_label = compress_path(target.to_string_lossy().as_ref());\n            content.push_str(&format!(\n                \"- Create target file: `{}`\\n\",\n                target_label\n            ));\n            commands.push(format!(\"touch \\\"{}\\\"\", target.to_string_lossy()));\n        }\n        for item in items {\n            let name = item.name.as_deref().unwrap_or(\"function\");\n            let current = item\n                .current_file\n                .as_ref()\n                .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                .unwrap_or_else(|| \"-\".to_string());\n            let ratio = if item.cost == 0 {\n                0.0\n            } else {\n                item.benefit as f64 / item.cost as f64\n            };\n            let caller_hint = if item.callers == 0 {\n                \"no external callers\".to_string()\n            } else {\n                format!(\"update {} caller files\", item.callers)\n            };\n            content.push_str(&format!(\n                \"- Move `{}` from `{}` (impact {}, benefit/cost {:.2}, touches {} files; {})\\n\",\n                name,\n                current,\n                item.impact_weight,\n                ratio,\n                item.cost,\n                caller_hint\n            ));\n            if let Some(current_file) = &item.current_file {\n                commands.push(format!(\n                    \"rg -n \\\"{}\\\" \\\"{}\\\"\",\n                    name,\n                    current_file.to_string_lossy()\n                ));\n            }\n            let mut callers = item.caller_files.clone();\n            callers.sort();\n            callers.dedup();\n            if !callers.is_empty() {\n                content.push_str(\"- Update imports in:\\n\");\n                for caller in callers {\n                    content.push_str(&format!(\n                        \"  - `{}`\\n\",\n                        compress_path(caller.to_string_lossy().as_ref())\n                    ));\n                    commands.push(format!(\n                        \"rg -n \\\"{}\\\" \\\"{}\\\"\",\n                        name,\n                        caller.to_string_lossy()\n                    ));\n                }\n            }\n        }\n        content.push_str(\"- Verification gate: `cargo test`\\n\");\n        if !commands.is_empty() {\n            content.push_str(\"\\n```bash\\n\");\n            for command in commands {\n                content.push_str(&format!(\"{}\\n\", command));\n            }\n            content.push_str(\"```\\n\");\n        }\n        content.push('\\n');\n    }\n}\n\npub fn write_cluster_batches(content: &mut String, plans: &[ClusterPlan], root_path: &Path) {\n    if plans.is_empty() {\n        return;\n    }\n    content.push_str(\"### Phase 2 Batches\\n\\n\");\n    content.push_str(\"Action: execute batches in order and verify after each batch.\\n\");\n    content.push_str(\"Note: each batch creates or fills a cluster file.\\n\\n\");\n    for (idx, plan) in plans.iter().enumerate() {\n        content.push_str(&format!(\n            \"#### Batch {}: target `{}`\\n\\n\",\n            idx + 1,\n            compress_path(plan.target.to_string_lossy().as_ref())\n        ));\n        content.push_str(\"Action: move the listed functions into the target module.\\n\");\n        content.push_str(\"Note: use the rg commands to locate definitions and callers.\\n\\n\");\n        let mut commands = Vec::new();\n        if !plan.target.exists() {\n            content.push_str(&format!(\n                \"- Create target file: `{}`\\n\",\n                compress_path(plan.target.to_string_lossy().as_ref())\n            ));\n            commands.push(format!(\"touch \\\"{}\\\"\", plan.target.to_string_lossy()));\n        }\n        content.push_str(&format!(\n            \"- Cluster cohesion {:.2}, {} functions\\n\",\n            plan.cohesion,\n            plan.members.len()\n        ));\n        for member in &plan.members {\n            let file = compress_path(member.file.to_string_lossy().as_ref());\n            content.push_str(&format!(\"- Move `{}` from `{}`\\n\", member.name, file));\n            commands.push(format!(\n                \"rg -n \\\"{}\\\" \\\"{}\\\"\",\n                member.name,\n                member.file.to_string_lossy()\n            ));\n            commands.push(format!(\n                \"rg -n \\\"{}\\\" \\\"{}\\\"\",\n                member.name,\n                root_path.to_string_lossy()\n            ));\n        }\n        content.push_str(\"- Verification gate: `cargo test`\\n\");\n        if !commands.is_empty() {\n            content.push_str(\"\\n```bash\\n\");\n            for command in commands {\n                content.push_str(&format!(\"{}\\n\", command));\n            }\n            content.push_str(\"```\\n\");\n        }\n        content.push('\\n');\n    }\n}\n\npub fn resolve_required_layer_path(\n    required_layer: &str,\n    current_file: &Path,\n    directory: &DirectoryAnalysis,\n    root_path: &Path,\n) -> PathBuf {\n    let mut files = Vec::new();\n    collect_directory_files(directory, &mut files);\n    let candidates = files\n        .into_iter()\n        .filter(|path| {\n            path.file_name()\n                .and_then(|name| name.to_str())\n                .map(|name| name == required_layer)\n                .unwrap_or(false)\n        })\n        .collect::<Vec<_>>();\n    if candidates.is_empty() {\n        return current_file\n            .parent()\n            .unwrap_or(root_path)\n            .join(required_layer);\n    }\n\n    let current_dir = current_file.parent().unwrap_or(root_path);\n    let mut best = None;\n    let mut best_score = -1isize;\n    for candidate in candidates {\n        let candidate_dir = candidate.parent().unwrap_or(root_path);\n        let score = path_common_prefix_len(current_dir, candidate_dir);\n        let length = candidate.components().count() as isize;\n        let combined = score * 1000 - length;\n        if combined > best_score {\n            best_score = combined;\n            best = Some(candidate);\n        }\n    }\n    best.unwrap_or_else(|| {\n        current_file\n            .parent()\n            .unwrap_or(root_path)\n            .join(required_layer)\n    })\n}\n",
          "updated_content": "//! Markdown report generation\n\nuse crate::cluster_008::collect_cluster_plans;\nuse crate::layer_core::{sort_structural_items};\nuse crate::control_flow::ControlFlowAnalyzer;\nuse crate::dependency::{LayerGraph, build_directory_entry_map, build_file_dependency_graph, collect_naming_warnings};\nuse crate::file_ordering::DirectoryMove;\nuse crate::types::{\n    AnalysisResult,\n    CallGraphNode,\n    CodeElement,\n    DirectoryAnalysis,\n    ElementType,\n    FileOrderingResult,\n    FunctionCfg,\n    FunctionCluster,\n    FunctionPlacement,\n    Language,\n    PlacementStatus,\n    Visibility,\n};\nuse std::cmp::Ordering;\nuse std::collections::{BTreeMap, BTreeSet, HashMap, HashSet};\nuse std::fs;\nuse std::path::{Path, PathBuf};\nuse walkdir::WalkDir;\nuse crate::cluster_006::strip_numeric_prefix;\n\ntype Result<T> = anyhow::Result<T>;\nfn display_path(path: &Path, root_path: &Path) -> String {\n    let relative = path.strip_prefix(root_path).unwrap_or(path);\n    relative.to_string_lossy().to_string()\n}\n\nfn placement_status_label(status: &PlacementStatus) -> String {\n    match status {\n        PlacementStatus::Correct => \"ok\".to_string(),\n        PlacementStatus::ShouldMove { .. } => \"move\".to_string(),\n        PlacementStatus::Orphaned { .. } => \"orphaned\".to_string(),\n        PlacementStatus::LayerViolation { .. } => \"layer violation\".to_string(),\n    }\n}\n\nfn placement_status_notes(status: &PlacementStatus) -> String {\n    match status {\n        PlacementStatus::Correct => String::new(),\n        PlacementStatus::ShouldMove { reason, impact } => {\n            format!(\"{} (impact {:.2})\", reason, impact)\n        }\n        PlacementStatus::Orphaned { suggested_module } => {\n            format!(\"suggest module {}\", suggested_module)\n        }\n        PlacementStatus::LayerViolation {\n            current_layer,\n            required_layer,\n        } => format!(\"{} -> {}\", current_layer, required_layer),\n    }\n}\n\n#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd)]\npub enum Priority {\n    Critical,\n    High,\n    Medium,\n    Low,\n}\n\n#[derive(Clone, Copy, Debug, Eq, PartialEq)]\npub enum ActionKind {\n    Cluster,\n    Structural,\n    Cohesion,\n    Ordering,\n}\n\n#[derive(Clone)]\npub struct PlanItem {\n    pub kind: ActionKind,\n    pub priority: Priority,\n    pub description: String,\n    pub command: String,\n    pub current_layer: Option<String>,\n    pub required_layer: Option<String>,\n    pub is_utility: bool,\n    pub impact_weight: usize,\n    pub benefit: usize,\n    pub cost: usize,\n    pub callers: usize,\n    pub caller_files: Vec<PathBuf>,\n    pub current_file: Option<PathBuf>,\n    pub target_file: Option<PathBuf>,\n    pub outgoing_files: Vec<PathBuf>,\n    pub name: Option<String>,\n    pub cluster_cohesion: f64,\n    pub member_count: usize,\n}\n\n#[derive(Clone)]\npub struct ClusterMember {\n    pub file: PathBuf,\n    pub name: String,\n}\n\n#[derive(Clone)]\npub struct ClusterPlan {\n    pub target: PathBuf,\n    pub cohesion: f64,\n    pub members: Vec<ClusterMember>,\n}\n\nfn collect_rename_items(ordering: &FileOrderingResult, label: &str) -> Vec<PlanItem> {\n    let mut layer_violation_files = BTreeSet::new();\n    for violation in &ordering.layer_violations {\n        layer_violation_files.insert(violation.to.clone());\n    }\n\n    ordering\n        .ordered_files\n        .iter()\n        .filter(|entry| entry.needs_rename)\n        .map(|entry| {\n            let from = entry.current_path.clone();\n            let to = entry\n                .current_path\n                .parent()\n                .map(|p| p.join(&entry.suggested_name))\n                .unwrap_or_else(|| PathBuf::from(&entry.suggested_name));\n            let priority = if layer_violation_files.contains(&entry.current_path) {\n                Priority::Critical\n            } else {\n                Priority::Medium\n            };\n            PlanItem {\n                kind: ActionKind::Ordering,\n                priority,\n                description: format!(\n                    \"[{}] `{}` -> `{}`\",\n                    label,\n                    compress_path(from.to_string_lossy().as_ref()),\n                    compress_path(to.to_string_lossy().as_ref())\n                ),\n                command: format!(\n                    \"git mv \\\"{}\\\" \\\"{}\\\"\",\n                    from.to_string_lossy(),\n                    to.to_string_lossy()\n                ),\n                current_layer: None,\n                required_layer: None,\n                is_utility: false,\n                impact_weight: 0,\n                benefit: 0,\n                cost: 1,\n                callers: 0,\n                caller_files: Vec::new(),\n                current_file: Some(from.clone()),\n                target_file: Some(to.clone()),\n                outgoing_files: Vec::new(),\n                name: None,\n                cluster_cohesion: 0.0,\n                member_count: 0,\n            }\n        })\n        .collect()\n}\n\nfn collect_utility_candidates(placements: &[FunctionPlacement]) -> Vec<String> {\n    let mut candidates = BTreeSet::new();\n    for placement in placements {\n        let external_files = placement.call_analysis.calls_from_other_files.len();\n        if external_files >= 3 {\n            candidates.insert(format!(\n                \"`{}` called by {} files (suggest `utilities`)\",\n                placement.name, external_files\n            ));\n        }\n    }\n    candidates.into_iter().collect()\n}\n\nfn directory_moves_to_plan(label: &str, moves: Vec<DirectoryMove>) -> Vec<PlanItem> {\n    moves\n        .into_iter()\n        .map(|item| PlanItem {\n            kind: ActionKind::Ordering,\n            priority: Priority::Medium,\n            description: format!(\n                \"[{}] dir `{}` -> `{}`\",\n                label,\n                compress_path(item.from.to_string_lossy().as_ref()),\n                compress_path(item.to.to_string_lossy().as_ref())\n            ),\n            command: format!(\n                \"git mv \\\"{}\\\" \\\"{}\\\"\",\n                item.from.to_string_lossy(),\n                item.to.to_string_lossy()\n            ),\n            current_layer: None,\n            required_layer: None,\n            is_utility: false,\n            impact_weight: 0,\n            benefit: 0,\n            cost: 1,\n            callers: 0,\n            caller_files: Vec::new(),\n            current_file: Some(item.from.clone()),\n            target_file: Some(item.to.clone()),\n            outgoing_files: Vec::new(),\n            name: None,\n            cluster_cohesion: 0.0,\n            member_count: 0,\n        })\n        .collect()\n}\n\nfn write_priority_section(content: &mut String, title: &str, items: &[PlanItem]) {\n    content.push_str(&format!(\"## {}\\n\\n\", title));\n    let (action, note) = match title {\n        \"Phase 1: Correctness Blockers\" => (\n            \"fix these first; they block correctness or builds.\",\n            \"empty means no critical blockers detected.\",\n        ),\n        \"Phase 2: Cluster Extraction\" => (\n            \"create the listed cluster files and move the grouped functions.\",\n            \"use the batches below to keep changes small.\",\n        ),\n        \"Phase 3: Structural Constraints\" => (\n            \"resolve the layer violations by moving functions to target modules.\",\n            \"follow batch order to avoid cascading dependency churn.\",\n        ),\n        \"Phase 4: Cohesion Improvements\" => (\n            \"optional: improve cohesion by moving functions to better-fit modules.\",\n            \"safe to defer unless you are actively refactoring.\",\n        ),\n        \"Phase 5: Ordering & Renames\" => (\n            \"optional: rename files to match ordering conventions.\",\n            \"update module paths and imports after renames.\",\n        ),\n        _ => (\"review items\", \"no additional guidance available.\"),\n    };\n    content.push_str(&format!(\"Action: {}\\n\", action));\n    content.push_str(&format!(\"Note: {}\\n\\n\", note));\n    if items.is_empty() {\n        content.push_str(\"- None.\\n\\n\");\n        return;\n    }\n\n    let mut commands = Vec::new();\n    for item in items {\n        content.push_str(&format!(\"- {}\\n\", item.description));\n        if !item.command.is_empty() {\n            commands.push(item.command.clone());\n        }\n    }\n    content.push('\\n');\n\n    if !commands.is_empty() {\n        content.push_str(\"```bash\\n\");\n        for cmd in commands {\n            content.push_str(&format!(\"{}\\n\", cmd));\n        }\n        content.push_str(\"```\\n\\n\");\n    }\n}\n\nfn write_structural_tips(content: &mut String, items: &[PlanItem]) {\n    if items.is_empty() {\n        return;\n    }\n    content.push_str(\"### Phase 3 Tips\\n\\n\");\n    content.push_str(\"Action: apply these guidelines while executing Phase 3 batches.\\n\");\n    content.push_str(\"Note: these are advisory, not checklist items.\\n\\n\");\n    content.push_str(\"- Move lowest-layer helpers first; higher layers should depend on stable primitives.\\n\");\n    content.push_str(\"- Keep moves small: move one function + update imports + rerun tests.\\n\");\n    content.push_str(\"- If a target module is missing, create it before moving functions.\\n\");\n    content.push_str(\"- Prefer consolidating shared utilities into their destination layer once.\\n\");\n    content.push_str(\"- Avoid touching `_old/` unless explicitly refactoring archives.\\n\\n\");\n}\n\nfn write_cluster_tips(content: &mut String, plans: &[ClusterPlan]) {\n    if plans.is_empty() {\n        return;\n    }\n    content.push_str(\"### Phase 2 Tips\\n\\n\");\n    content.push_str(\"Action: apply these guidelines while executing Phase 2 batches.\\n\");\n    content.push_str(\"Note: these are advisory, not checklist items.\\n\\n\");\n    content.push_str(\"- Extract clusters as a unit; avoid splitting a cluster across files.\\n\");\n    content.push_str(\"- Prefer creating new files before moving functions to keep diffs small.\\n\");\n    content.push_str(\"- After each batch, update imports and run tests to lock in behavior.\\n\\n\");\n}\n\nfn sort_plan_items(items: &mut Vec<PlanItem>) {\n    items.sort_by(|a, b| {\n        a.priority\n            .cmp(&b.priority)\n            .then_with(|| a.description.cmp(&b.description))\n    });\n}\n\nfn sort_cluster_items(items: &mut Vec<PlanItem>) {\n    items.sort_by(|a, b| {\n        b.cluster_cohesion\n            .partial_cmp(&a.cluster_cohesion)\n            .unwrap_or(Ordering::Equal)\n            .then_with(|| b.member_count.cmp(&a.member_count))\n            .then_with(|| a.description.cmp(&b.description))\n    });\n}\n\nfn cluster_priority(cohesion: f64) -> Priority {\n    if cohesion >= 0.8 {\n        Priority::Critical\n    } else if cohesion >= 0.6 {\n        Priority::High\n    } else if cohesion >= 0.4 {\n        Priority::Medium\n    } else {\n        Priority::Low\n    }\n}\n\nfn collect_cluster_items(plans: &[ClusterPlan]) -> Vec<PlanItem> {\n    plans\n        .iter()\n        .map(|plan| PlanItem {\n            kind: ActionKind::Cluster,\n            priority: cluster_priority(plan.cohesion),\n            description: format!(\n                \"Create cluster file `{}` with {} functions (cohesion {:.2})\",\n                compress_path(plan.target.to_string_lossy().as_ref()),\n                plan.members.len(),\n                plan.cohesion\n            ),\n            command: format!(\"touch \\\"{}\\\"\", plan.target.to_string_lossy()),\n            current_layer: None,\n            required_layer: None,\n            is_utility: false,\n            impact_weight: 0,\n            benefit: 0,\n            cost: 1,\n            callers: 0,\n            caller_files: Vec::new(),\n            current_file: None,\n            target_file: Some(plan.target.clone()),\n            outgoing_files: Vec::new(),\n            name: None,\n            cluster_cohesion: plan.cohesion,\n            member_count: plan.members.len(),\n        })\n        .collect()\n}\n\nfn collect_refactor_actions(\n    result: &AnalysisResult,\n    rust_ordering: &FileOrderingResult,\n    julia_ordering: &FileOrderingResult,\n    placements: &[FunctionPlacement],\n    clusters: &[FunctionCluster],\n    directory: &DirectoryAnalysis,\n    root_path: &Path,\n) -> Vec<crate::correction_plan_types::RefactorAction> {\n    let mut actions = Vec::new();\n\n    let mut renames = collect_rename_items(rust_ordering, \"Rust\")\n        .into_iter()\n        .chain(collect_rename_items(julia_ordering, \"Julia\"))\n        .collect::<Vec<_>>();\n    renames.extend(directory_moves_to_plan(\n        \"Rust\",\n        collect_directory_moves(rust_ordering, root_path),\n    ));\n    renames.extend(directory_moves_to_plan(\n        \"Julia\",\n        collect_directory_moves(julia_ordering, root_path),\n    ));\n\n    let cluster_plans = collect_cluster_plans(clusters, root_path);\n    let cluster_items = collect_cluster_items(&cluster_plans);\n\n    let mut utility_names = BTreeSet::new();\n    for placement in placements {\n        if placement.call_analysis.calls_from_other_files.len() >= 3 {\n            utility_names.insert(placement.name.clone());\n        }\n    }\n    let moves = collect_move_items(placements, &utility_names, directory, root_path);\n\n    for item in renames {\n        if let (Some(from), Some(to)) = (item.current_file, item.target_file) {\n            if !from.exists() {\n                continue;\n            }\n            actions.push(crate::correction_plan_types::RefactorAction::RenameFile { from, to });\n        }\n    }\n    for item in cluster_items {\n        if let Some(path) = item.target_file {\n            actions.push(crate::correction_plan_types::RefactorAction::CreateFile { path });\n        }\n    }\n    for item in moves {\n        if let (Some(name), Some(from), Some(to)) =\n            (item.name.clone(), item.current_file, item.target_file)\n        {\n            actions.push(crate::correction_plan_types::RefactorAction::MoveFunction {\n                function: name,\n                from,\n                to,\n                required_layer: item.required_layer.clone(),\n            });\n        }\n    }\n\n    actions.extend(collect_visibility_actions(result));\n    actions\n}\n\nfn collect_visibility_actions(\n    result: &AnalysisResult,\n) -> Vec<crate::correction_plan_types::RefactorAction> {\n    use crate::types::{ElementType, Language, Visibility};\n    use std::collections::HashMap;\n    use std::path::PathBuf;\n\n    let mut actions = Vec::new();\n    let mut element_files: HashMap<String, PathBuf> = HashMap::new();\n    for element in &result.elements {\n        if element.element_type == ElementType::Function && element.language == Language::Rust {\n            element_files.insert(element.name.clone(), PathBuf::from(&element.file_path));\n        }\n    }\n\n    for element in &result.elements {\n        if element.element_type != ElementType::Function || element.language != Language::Rust {\n            continue;\n        }\n        if matches!(element.visibility, Visibility::Private) {\n            continue;\n        }\n        if element.name == \"main\" || element.name.starts_with(\"test_\") {\n            continue;\n        }\n        let file_path = PathBuf::from(&element.file_path);\n        if is_test_file(&file_path) {\n            continue;\n        }\n        let callers = caller_files(&element.name, &result.call_graph, &element_files);\n        if callers.is_empty() {\n            actions.push(crate::correction_plan_types::RefactorAction::AdjustVisibility {\n                symbol: element.name.clone(),\n                file: file_path.clone(),\n                from: element.visibility.clone(),\n                to: element.visibility.clone(),\n                reason: \"review: public symbol with zero callers (possible external API)\"\n                    .to_string(),\n            });\n            continue;\n        }\n        let mut external = false;\n        for caller in &callers {\n            if *caller != file_path {\n                external = true;\n                break;\n            }\n        }\n        if external {\n            continue;\n        }\n\n        let target_visibility = match element.visibility {\n            Visibility::Public => Visibility::Crate,\n            Visibility::Crate => Visibility::Private,\n            Visibility::Private => continue,\n        };\n        if target_visibility == element.visibility {\n            continue;\n        }\n        actions.push(crate::correction_plan_types::RefactorAction::AdjustVisibility {\n            symbol: element.name.clone(),\n            file: file_path.clone(),\n            from: element.visibility.clone(),\n            to: target_visibility,\n            reason: \"only used within file\".to_string(),\n        });\n    }\n\n    actions\n}\n\nfn caller_files(\n    function: &str,\n    call_graph: &std::collections::HashMap<String, CallGraphNode>,\n    element_files: &std::collections::HashMap<String, std::path::PathBuf>,\n) -> std::collections::HashSet<std::path::PathBuf> {\n    let mut files = std::collections::HashSet::new();\n    if let Some(node) = call_graph.get(function) {\n        for caller in &node.called_by {\n            if let Some(file) = element_files.get(caller) {\n                files.insert(file.clone());\n            }\n        }\n    }\n    files\n}\n\nfn is_test_file(path: &std::path::Path) -> bool {\n    if path.components().any(|c| c.as_os_str() == \"tests\") {\n        return true;\n    }\n    path.file_name()\n        .and_then(|n| n.to_str())\n        .map(|name| name.contains(\"_test\") || name.starts_with(\"test_\"))\n        .unwrap_or(false)\n}\n\n\n\nfn build_correction_metrics(\n    placements: &[FunctionPlacement],\n    _directory: &DirectoryAnalysis,\n) -> crate::quality_delta_calculator::Metrics {\n    let cohesion = compute_directory_cohesion(placements);\n    let violations = placements\n        .iter()\n        .filter(|p| matches!(p.placement_status, PlacementStatus::LayerViolation { .. }))\n        .count();\n    crate::quality_delta_calculator::Metrics {\n        cohesion,\n        violations,\n        complexity: 0.0,\n    }\n}\n\nfn load_cargo_warnings(output_dir: &str) -> Option<String> {\n    let path = Path::new(output_dir).join(\"cargo_warnings.txt\");\n    if !path.exists() {\n        return None;\n    }\n    fs::read_to_string(path).ok()\n}\n\nfn parse_dead_code_warnings(warnings: &str) -> HashMap<String, HashSet<PathBuf>> {\n    let mut dead_code = HashMap::new();\n    let mut lines = warnings.lines().peekable();\n    while let Some(line) = lines.next() {\n        let trimmed = line.trim();\n        if !trimmed.starts_with(\"warning:\") {\n            continue;\n        }\n        let Some(name_start) = trimmed.find(\"function `\") else {\n            continue;\n        };\n        let rest = &trimmed[name_start + \"function `\".len()..];\n        let Some(name_end) = rest.find('`') else {\n            continue;\n        };\n        let name = &rest[..name_end];\n        if !trimmed.contains(\"is never used\") {\n            continue;\n        }\n\n        let mut warn_path: Option<PathBuf> = None;\n        if let Some(next) = lines.peek() {\n            let next_trimmed = next.trim();\n            if let Some(path_start) = next_trimmed.find(\"--> \") {\n                let path_part = &next_trimmed[path_start + 4..];\n                if let Some(path_end) = path_part.find(':') {\n                    warn_path = Some(PathBuf::from(&path_part[..path_end]));\n                }\n            }\n        }\n\n        dead_code\n            .entry(name.to_string())\n            .or_insert_with(HashSet::new)\n            .extend(warn_path);\n    }\n    dead_code\n}\n\nfn parse_use_symbols(line: &str) -> Vec<String> {\n    let mut symbols = Vec::new();\n    let Some(use_idx) = line.find(\"use \") else {\n        return symbols;\n    };\n    let mut clause = line[use_idx + 4..].trim();\n    if let Some(end_idx) = clause.find(';') {\n        clause = clause[..end_idx].trim();\n    }\n    clause = clause.strip_prefix(\"crate::\").unwrap_or(clause);\n    clause = clause.strip_prefix(\"self::\").unwrap_or(clause);\n\n    if let Some(brace_start) = clause.find('{') {\n        let brace_end = clause.rfind('}').unwrap_or(clause.len());\n        let inner = &clause[brace_start + 1..brace_end];\n        for item in inner.split(',') {\n            let item = item.trim();\n            if item.is_empty() || item == \"*\" || item == \"self\" || item == \"super\" {\n                continue;\n            }\n            let item = item.split(\" as \").next().unwrap_or(item).trim();\n            let last = item.rsplit(\"::\").next().unwrap_or(item);\n            if !last.is_empty() {\n                symbols.push(last.to_string());\n            }\n        }\n    } else {\n        let last = clause.rsplit(\"::\").next().unwrap_or(clause).trim();\n        if !last.is_empty() && last != \"*\" && last != \"self\" && last != \"super\" {\n            symbols.push(last.to_string());\n        }\n    }\n\n    symbols\n}\n\nfn scan_crate_paths(line: &str) -> Vec<String> {\n    let mut symbols = Vec::new();\n    let mut idx = 0;\n    while let Some(found) = line[idx..].find(\"crate::\") {\n        let start = idx + found + \"crate::\".len();\n        let mut end = start;\n        for ch in line[start..].chars() {\n            if ch.is_ascii_alphanumeric() || ch == '_' || ch == ':' {\n                end += ch.len_utf8();\n            } else {\n                break;\n            }\n        }\n        if end > start {\n            let path = &line[start..end];\n            if let Some(last) = path.rsplit(\"::\").next() {\n                if !last.is_empty() {\n                    symbols.push(last.to_string());\n                }\n            }\n        }\n        idx = end;\n    }\n    symbols\n}\n\nfn collect_symbol_references(root_path: &Path) -> HashMap<String, HashSet<PathBuf>> {\n    let mut references: HashMap<String, HashSet<PathBuf>> = HashMap::new();\n    let src_dir = root_path.join(\"src\");\n    for entry in WalkDir::new(&src_dir).into_iter().filter_map(|e| e.ok()) {\n        let path = entry.path();\n        if !path.is_file() || path.extension().and_then(|e| e.to_str()) != Some(\"rs\") {\n            continue;\n        }\n        let Ok(contents) = fs::read_to_string(path) else {\n            continue;\n        };\n        for line in contents.lines() {\n            if line.contains(\"use crate::\") {\n                for symbol in parse_use_symbols(line) {\n                    references\n                        .entry(symbol)\n                        .or_insert_with(HashSet::new)\n                        .insert(path.to_path_buf());\n                }\n            }\n            if line.contains(\"crate::\") {\n                for symbol in scan_crate_paths(line) {\n                    references\n                        .entry(symbol)\n                        .or_insert_with(HashSet::new)\n                        .insert(path.to_path_buf());\n                }\n            }\n        }\n    }\n    references\n}\n\nfn is_public_function(file_path: &Path, name: &str) -> Option<bool> {\n    let Ok(contents) = fs::read_to_string(file_path) else {\n        return None;\n    };\n    let needle = format!(\"fn {}\", name);\n    for line in contents.lines() {\n        if let Some(pos) = line.find(&needle) {\n            let prefix = line[..pos].trim_start();\n            return Some(prefix.starts_with(\"pub\"));\n        }\n    }\n    None\n}\n\nfn path_matches(entry_path: &Path, candidate: &Path) -> bool {\n    entry_path == candidate || entry_path.ends_with(candidate) || candidate.ends_with(entry_path)\n}\n\nfn is_entrypoint_main(entry: &FunctionPlacement) -> bool {\n    entry.name == \"main\"\n        && entry\n            .current_file\n            .ends_with(Path::new(\"src/190_main.rs\"))\n}\n\nfn referenced_elsewhere(\n    entry: &FunctionPlacement,\n    references: &HashMap<String, HashSet<PathBuf>>,\n) -> bool {\n    let Some(files) = references.get(&entry.name) else {\n        return false;\n    };\n    files\n        .iter()\n        .any(|path| !path_matches(&entry.current_file, path))\n}\n\nfn is_dead_code_candidate(\n    entry: &FunctionPlacement,\n    dead_code: &HashMap<String, HashSet<PathBuf>>,\n) -> bool {\n    let Some(paths) = dead_code.get(&entry.name) else {\n        return false;\n    };\n    if paths.is_empty() {\n        return true;\n    }\n    paths.iter().any(|path| path_matches(&entry.current_file, path))\n}\n\nfn filter_orphaned<'a>(\n    placements: &'a [FunctionPlacement],\n    root_path: &Path,\n    output_dir: &str,\n) -> (Vec<&'a FunctionPlacement>, Vec<&'a FunctionPlacement>) {\n    let references = collect_symbol_references(root_path);\n    let dead_code = load_cargo_warnings(output_dir)\n        .as_deref()\n        .map(parse_dead_code_warnings)\n        .unwrap_or_default();\n\n    let mut orphaned = Vec::new();\n    let mut delete_candidates = Vec::new();\n    for entry in placements\n        .iter()\n        .filter(|p| matches!(p.placement_status, PlacementStatus::Orphaned { .. }))\n    {\n        if is_entrypoint_main(entry) {\n            continue;\n        }\n        if let Some(true) = is_public_function(&entry.current_file, &entry.name) {\n            if referenced_elsewhere(entry, &references) {\n                continue;\n            }\n        }\n        let is_delete_candidate = is_dead_code_candidate(entry, &dead_code);\n        if is_delete_candidate {\n            delete_candidates.push(entry);\n        }\n        orphaned.push(entry);\n    }\n    (orphaned, delete_candidates)\n}\n\n#[derive(Clone, Debug)]\npub struct ReportConfig {\n    pub file_line_warning: usize,\n    pub dir_file_warning: usize,\n    pub naming_score_warning: f64,\n    pub baseline_path: String,\n}\n\nimpl ReportConfig {\n    fn defaults() -> Self {\n        Self {\n            file_line_warning: 800,\n            dir_file_warning: 30,\n            naming_score_warning: 70.0,\n            baseline_path: \"metrics_baseline.txt\".to_string(),\n        }\n    }\n}\n\nfn load_report_config(output_dir: &str) -> ReportConfig {\n    let path = Path::new(output_dir).join(\"analyzer_config.toml\");\n    let mut config = ReportConfig::defaults();\n    let Ok(contents) = fs::read_to_string(path) else {\n        return config;\n    };\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') {\n            continue;\n        }\n        let Some((key, value)) = trimmed.split_once('=') else {\n            continue;\n        };\n        let key = key.trim();\n        let value = value.trim().trim_matches('\"');\n        match key {\n            \"file_line_warning\" => {\n                if let Ok(parsed) = value.parse::<usize>() {\n                    config.file_line_warning = parsed;\n                }\n            }\n            \"dir_file_warning\" => {\n                if let Ok(parsed) = value.parse::<usize>() {\n                    config.dir_file_warning = parsed;\n                }\n            }\n            \"baseline_path\" => {\n                if !value.is_empty() {\n                    config.baseline_path = value.to_string();\n                }\n            }\n            \"naming_score_warning\" => {\n                if let Ok(parsed) = value.parse::<f64>() {\n                    config.naming_score_warning = parsed;\n                }\n            }\n            _ => {}\n        }\n    }\n    config\n}\n\nfn collect_size_warnings(\n    directory: &DirectoryAnalysis,\n    config: &ReportConfig,\n    warnings: &mut Vec<String>,\n) {\n    if directory.files.len() >= config.dir_file_warning {\n        warnings.push(format!(\n            \"Directory `{}` has {} files; consider splitting into submodules.\",\n            compress_path(directory.path.to_string_lossy().as_ref()),\n            directory.files.len()\n        ));\n    }\n\n    for file in &directory.files {\n        if let Ok(contents) = fs::read_to_string(file) {\n            let lines = contents.lines().count();\n            if lines >= config.file_line_warning {\n                warnings.push(format!(\n                    \"File `{}` has {} lines; consider extracting helpers.\",\n                    compress_path(file.to_string_lossy().as_ref()),\n                    lines\n                ));\n            }\n        }\n    }\n\n    for child in &directory.subdirectories {\n        collect_size_warnings(child, config, warnings);\n    }\n}\n\nfn load_baseline_metrics(config: &ReportConfig, output_dir: &str) -> Option<HashMap<String, f64>> {\n    let path = Path::new(output_dir).join(&config.baseline_path);\n    let Ok(contents) = fs::read_to_string(path) else {\n        return None;\n    };\n    let mut metrics = HashMap::new();\n    for line in contents.lines() {\n        let trimmed = line.trim();\n        if trimmed.is_empty() || trimmed.starts_with('#') {\n            continue;\n        }\n        let Some((key, value)) = trimmed.split_once('=') else {\n            continue;\n        };\n        let key = key.trim().to_string();\n        let value = value.trim();\n        if let Ok(parsed) = value.parse::<f64>() {\n            metrics.insert(key, parsed);\n        }\n    }\n    Some(metrics)\n}\n\nfn baseline_deltas(\n    baseline: &HashMap<String, f64>,\n    dir_cohesion: f64,\n    ordering_correctness: f64,\n    avg_cohesion: f64,\n    renames_len: usize,\n    relocations: usize,\n) -> Vec<String> {\n    let mut deltas = Vec::new();\n    if let Some(prev) = baseline.get(\"directory_cohesion\") {\n        deltas.push(format!(\n            \"directory_cohesion: {:.2} -> {:.2} (delta {:+.2})\",\n            prev,\n            dir_cohesion,\n            dir_cohesion - prev\n        ));\n    }\n    if let Some(prev) = baseline.get(\"ordering_correctness\") {\n        let current = ordering_correctness * 100.0;\n        deltas.push(format!(\n            \"ordering_correctness: {:.1}% -> {:.1}% (delta {:+.1}%)\",\n            prev,\n            current,\n            current - prev\n        ));\n    }\n    if let Some(prev) = baseline.get(\"avg_function_cohesion\") {\n        deltas.push(format!(\n            \"avg_function_cohesion: {:.2} -> {:.2} (delta {:+.2})\",\n            prev,\n            avg_cohesion,\n            avg_cohesion - prev\n        ));\n    }\n    if let Some(prev) = baseline.get(\"rename_ops_needed\") {\n        let current = renames_len as f64;\n        deltas.push(format!(\n            \"rename_ops_needed: {:.0} -> {} (delta {:+.0})\",\n            prev,\n            renames_len,\n            current - prev\n        ));\n    }\n    if let Some(prev) = baseline.get(\"function_relocations\") {\n        let current = relocations as f64;\n        deltas.push(format!(\n            \"function_relocations: {:.0} -> {} (delta {:+.0})\",\n            prev,\n            relocations,\n            current - prev\n        ));\n    }\n    deltas\n}\n\nfn write_baseline_metrics(\n    config: &ReportConfig,\n    output_dir: &str,\n    dir_cohesion: f64,\n    ordering_correctness: f64,\n    avg_cohesion: f64,\n    renames_len: usize,\n    relocations: usize,\n) {\n    let path = Path::new(output_dir).join(&config.baseline_path);\n    if path.exists() {\n        return;\n    }\n    let content = format!(\n        \"directory_cohesion={:.2}\\nordering_correctness={:.1}\\navg_function_cohesion={:.2}\\nrename_ops_needed={}\\nfunction_relocations={}\\n\",\n        dir_cohesion,\n        ordering_correctness * 100.0,\n        avg_cohesion,\n        renames_len,\n        relocations\n    );\n    let _ = fs::write(path, content);\n}\n\nfn collect_directories<'a>(node: &'a DirectoryAnalysis, acc: &mut Vec<&'a DirectoryAnalysis>) {\n    acc.push(node);\n    for child in &node.subdirectories {\n        collect_directories(child, acc);\n    }\n}\n\nfn slugify_path(path: &Path) -> String {\n    let mut slug = String::new();\n    for component in path.components() {\n        if !slug.is_empty() {\n            slug.push_str(\"__\");\n        }\n        slug.push_str(&component.as_os_str().to_string_lossy().replace('/', \"_\"));\n    }\n    if slug.is_empty() {\n        \"root\".to_string()\n    } else {\n        slug\n    }\n}\n\nfn render_mermaid_graph(graph: &petgraph::graph::DiGraph<PathBuf, ()>) -> String {\n    let mut output = String::from(\"```mermaid\\ngraph TD\\n\");\n    let mut node_ids: HashMap<usize, String> = HashMap::new();\n    let mut idx = 0usize;\n    for node in graph.node_indices() {\n        let node_name = graph[node]\n            .file_name()\n            .and_then(|n| n.to_str())\n            .unwrap_or(\"file\");\n        let safe_id = format!(\"F{}\", idx);\n        idx += 1;\n        node_ids.insert(node.index(), safe_id.clone());\n        output.push_str(&format!(\"    {}[\\\"{}\\\"]\\n\", safe_id, node_name));\n    }\n    for edge in graph.edge_indices() {\n        if let Some((src, dst)) = graph.edge_endpoints(edge) {\n            if let (Some(from), Some(to)) = (node_ids.get(&src.index()), node_ids.get(&dst.index()))\n            {\n                output.push_str(&format!(\"    {} --> {}\\n\", from, to));\n            }\n        }\n    }\n    output.push_str(\"```\\n\");\n    output\n}\n\nfn compute_ordering_correctness(\n    rust_ordering: &FileOrderingResult,\n    julia_ordering: &FileOrderingResult,\n) -> f64 {\n    let mut total = 0usize;\n    let mut correct = 0usize;\n    for ordering in [rust_ordering, julia_ordering] {\n        total += ordering.ordered_files.len();\n        correct += ordering.ordered_files.len().saturating_sub(ordering.violations.len());\n    }\n    if total == 0 {\n        1.0\n    } else {\n        correct as f64 / total as f64\n    }\n}\n\nfn compute_directory_cohesion(placements: &[FunctionPlacement]) -> f64 {\n    let mut intra = 0usize;\n    let mut inter = 0usize;\n    for placement in placements {\n        let current_dir = placement.current_file.parent().map(|p| p.to_path_buf());\n        intra += placement.call_analysis.intra_file_calls;\n        for (file, count) in &placement.call_analysis.inter_file_calls {\n            let same_dir = current_dir\n                .as_ref()\n                .and_then(|dir| file.parent().map(|p| p == dir))\n                .unwrap_or(false);\n            if same_dir {\n                intra += count;\n            } else {\n                inter += count;\n            }\n        }\n    }\n    let total = intra + inter;\n    if total == 0 {\n        1.0\n    } else {\n        intra as f64 / total as f64\n    }\n}\n\npub struct ReportGenerator {\n    output_dir: String,\n}\n\nimpl ReportGenerator {\n    pub fn new(output_dir: String) -> Self {\n        Self { output_dir }\n    }\n\n    pub fn generate_all(\n        &self,\n        result: &AnalysisResult,\n        cf_analyzer: &ControlFlowAnalyzer,\n        rust_layers: &LayerGraph,\n        julia_layers: &LayerGraph,\n        rust_ordering: &FileOrderingResult,\n        julia_ordering: &FileOrderingResult,\n        function_placements: &[FunctionPlacement],\n        function_clusters: &[FunctionCluster],\n        directory_structure: &DirectoryAnalysis,\n        root_path: &Path,\n        correction_intelligence: bool,\n        correction_json: Option<PathBuf>,\n        verification_policy_json: Option<PathBuf>,\n        correction_path_slice: bool,\n        correction_path_slice_dir: Option<PathBuf>,\n        correction_visibility_slice: bool,\n        correction_visibility_slice_dir: Option<PathBuf>,\n        correction_cluster_slice: Option<usize>,\n        correction_cluster_slice_dir: Option<PathBuf>,\n        correction_cluster_plan: Option<PathBuf>,\n    ) -> Result<()> {\n        fs::create_dir_all(&self.output_dir)?;\n        self.cleanup_legacy_reports()?;\n        let correction_root = Path::new(&self.output_dir).join(\"97_correction_intelligence\");\n\n        println!(\"  Report: structure\");\n        self.generate_structure_report(result)?;\n        println!(\"  Report: call_graph\");\n        self.generate_call_graph_report(cf_analyzer)?;\n        println!(\"  Report: cfg\");\n        self.generate_cfg_report(cf_analyzer)?;\n        println!(\"  Report: module_dependencies\");\n        self.generate_module_dependencies(result)?;\n        println!(\"  Report: module_map_mismatch\");\n        self.generate_module_map_mismatch(root_path)?;\n        println!(\"  Report: test_topology\");\n        self.generate_test_topology(root_path)?;\n        println!(\"  Report: warning_hygiene\");\n        self.generate_warning_hygiene(root_path)?;\n        println!(\"  Report: function_analysis\");\n        self.generate_function_analysis(result)?;\n        println!(\"  Report: layer_dependencies\");\n        self.generate_layer_dependency_report(rust_layers, julia_layers, root_path)?;\n        println!(\"  Report: file_ordering\");\n        self.generate_file_ordering_report(rust_ordering, julia_ordering, root_path)?;\n        println!(\"  Report: cohesion_analysis\");\n        self.generate_cohesion_report(function_placements, function_clusters, root_path)?;\n        println!(\"  Report: refactoring_plan\");\n        let correction_report = if correction_intelligence {\n            let actions = collect_refactor_actions(\n                result,\n                rust_ordering,\n                julia_ordering,\n                function_placements,\n                function_clusters,\n                directory_structure,\n                root_path,\n            );\n            let metrics = build_correction_metrics(function_placements, directory_structure);\n            let state = crate::correction_intelligence_report::build_state(root_path, result, metrics);\n            let report = crate::correction_intelligence_report::generate_intelligence_report(&actions, &state);\n            let output_dir = correction_root.clone();\n            crate::correction_intelligence_report::write_intelligence_outputs_at(\n                &report,\n                &output_dir,\n                correction_json.as_deref(),\n                verification_policy_json.as_deref(),\n            )?;\n            if correction_path_slice {\n                println!(\"  Report: correction_intelligence_path_coherence\");\n                let path_report =\n                    crate::correction_intelligence_report::filter_path_coherence_report(&report);\n                let slice_dir = correction_path_slice_dir.unwrap_or_else(|| {\n                    output_dir.join(\"slice_path_coherence\")\n                });\n                crate::correction_intelligence_report::write_intelligence_outputs_at(\n                    &path_report,\n                    &slice_dir,\n                    None,\n                    None,\n                )?;\n            }\n            if correction_visibility_slice {\n                println!(\"  Report: correction_intelligence_visibility\");\n                let visibility_report =\n                    crate::correction_intelligence_report::filter_visibility_report(&report);\n                let slice_dir = correction_visibility_slice_dir.unwrap_or_else(|| {\n                    output_dir.join(\"slice_visibility\")\n                });\n                crate::correction_intelligence_report::write_intelligence_outputs_at(\n                    &visibility_report,\n                    &slice_dir,\n                    None,\n                    None,\n                )?;\n            }\n            Some(report)\n        } else {\n            None\n        };\n        if let Some(batch_index) = correction_cluster_slice {\n            println!(\"  Report: correction_intelligence_cluster_slice\");\n            let default_plan = root_path.join(\"docs/00_refactoring_plan/04_phase2_clusters.md\");\n            let fallback_plan =\n                root_path.join(\"../mmsb-executor/docs/00_refactoring_plan/04_phase2_clusters.md\");\n            let plan_path = correction_cluster_plan.unwrap_or_else(|| {\n                if default_plan.exists() {\n                    default_plan\n                } else {\n                    fallback_plan\n                }\n            });\n            let slice_dir = correction_cluster_slice_dir.unwrap_or_else(|| {\n                correction_root.join(format!(\"slice_cluster_b{}\", batch_index))\n            });\n            let report = crate::correction_intelligence_report::generate_phase2_cluster_slice(\n                &plan_path,\n                batch_index,\n                root_path,\n            )?;\n            crate::correction_intelligence_report::write_intelligence_outputs_at(\n                &report,\n                &slice_dir,\n                None,\n                None,\n            )?;\n        }\n        self.generate_refactoring_plan(\n            rust_ordering,\n            julia_ordering,\n            function_placements,\n            function_clusters,\n            directory_structure,\n            root_path,\n            correction_report.as_ref(),\n        )?;\n        println!(\"  Report: file_organization\");\n        self.generate_file_organization_report(\n            directory_structure,\n            rust_ordering,\n            julia_ordering,\n            root_path,\n        )?;\n\n        Ok(())\n    }\n\n    fn cleanup_legacy_reports(&self) -> Result<()> {\n        let legacy_files = [\n            \"structure.md\",\n            \"call_graph.md\",\n            \"cfg.md\",\n            \"module_dependencies.md\",\n            \"function_analysis.md\",\n            \"layer_dependencies.md\",\n            \"file_ordering.md\",\n            \"cohesion_analysis.md\",\n            \"refactoring_plan.md\",\n            \"file_organization.md\",\n        ];\n        for file in legacy_files {\n            let path = Path::new(&self.output_dir).join(file);\n            if path.exists() {\n                fs::remove_file(path)?;\n            }\n        }\n        let report_dirs = [\n            \"structure\",\n            \"call_graph\",\n            \"cfg\",\n            \"module_dependencies\",\n            \"function_analysis\",\n            \"layer_dependencies\",\n            \"file_ordering\",\n            \"cohesion_analysis\",\n            \"refactoring_plan\",\n            \"file_organization\",\n            \"10_structure\",\n            \"20_call_graph\",\n            \"30_cfg\",\n            \"40_module_dependencies\",\n            \"41_module_map_mismatch\",\n            \"42_test_topology\",\n            \"43_warning_hygiene\",\n            \"50_function_analysis\",\n            \"60_layer_dependencies\",\n            \"70_file_ordering\",\n            \"80_cohesion_analysis\",\n            \"90_file_organization\",\n        ];\n        for dir in report_dirs {\n            let path = Path::new(&self.output_dir).join(dir);\n            if !path.exists() {\n                continue;\n            }\n            for entry in fs::read_dir(&path)? {\n                let entry = entry?;\n                let entry_path = entry.path();\n                if entry_path.is_dir() {\n                    if dir == \"30_cfg\" && entry_path.file_name().map_or(false, |n| n == \"dots\") {\n                        continue;\n                    }\n                    fs::remove_dir_all(entry_path)?;\n                } else {\n                    fs::remove_file(entry_path)?;\n                }\n            }\n        }\n        Ok(())\n    }\n\n    fn prepare_report_dir(&self, name: &str) -> Result<PathBuf> {\n        let dir = Path::new(&self.output_dir).join(name);\n        fs::create_dir_all(&dir)?;\n        Ok(dir)\n    }\n\n    fn generate_structure_report(&self, result: &AnalysisResult) -> Result<()> {\n        let dir = self.prepare_report_dir(\"10_structure\")?;\n        let generated_at = chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\");\n\n        let mut files: BTreeMap<String, Vec<&CodeElement>> = BTreeMap::new();\n        for elem in &result.elements {\n            files\n                .entry(elem.file_path.clone())\n                .or_insert_with(Vec::new)\n                .push(elem);\n        }\n\n        let mut grouped: BTreeMap<String, Vec<(String, Vec<&CodeElement>)>> = BTreeMap::new();\n        for (file_path, elements) in files {\n            let compressed = compress_path(&file_path);\n            let key = prefix_key_from_path(&compressed);\n            grouped\n                .entry(key)\n                .or_insert_with(Vec::new)\n                .push((compressed, elements));\n        }\n\n        let mut grouped: Vec<_> = grouped.into_iter().collect();\n        grouped.sort_by(|a, b| group_key_cmp(&a.0, &b.0));\n\n        let mut index = String::from(\"# MMSB Code Structure Overview\\n\\n\");\n        index.push_str(&format!(\"Generated: {}\\n\\n\", generated_at));\n        index.push_str(\n            \"Each numbered file groups source files by MMSB prefix so a simple `ls 10_structure/` \\\nshows the traversal order.\\n\\n\",\n        );\n\n        if grouped.is_empty() {\n            index.push_str(\"No code elements were recorded.\\n\");\n        } else {\n            index.push_str(\"## Group Files\\n\\n\");\n            for (idx, (group_key, _)) in grouped.iter().enumerate() {\n                let slug = slugify_key(group_key);\n                let file_name = format!(\"{:03}-{}.md\", idx * 10, slug);\n                index.push_str(&format!(\"- `{}`  `{}`\\n\", group_key, file_name));\n            }\n        }\n\n        for (idx, (group_key, mut entries)) in grouped.into_iter().enumerate() {\n            entries.sort_by(|a, b| a.0.cmp(&b.0));\n            let slug = slugify_key(&group_key);\n            let file_name = format!(\"{:03}-{}.md\", idx * 10, slug);\n            let mut content = format!(\"# Structure Group: {}\\n\\n\", group_key);\n\n            for (file_path, mut elements) in entries {\n                content.push_str(&format!(\"## File: {}\\n\\n\", file_path));\n\n                let layers: BTreeSet<String> = elements.iter().map(|e| e.layer.clone()).collect();\n                let layer_summary = if layers.is_empty() {\n                    \"root\".to_string()\n                } else {\n                    layers.iter().cloned().collect::<Vec<_>>().join(\", \")\n                };\n\n                let mut language_counts: BTreeMap<String, usize> = BTreeMap::new();\n                let mut type_counts: BTreeMap<String, usize> = BTreeMap::new();\n                for elem in &elements {\n                    *language_counts\n                        .entry(language_label(&elem.language).to_string())\n                        .or_insert(0) += 1;\n                    *type_counts\n                        .entry(format!(\"{:?}\", elem.element_type))\n                        .or_insert(0) += 1;\n                }\n\n                let lang_summary = if language_counts.is_empty() {\n                    \"n/a\".to_string()\n                } else {\n                    language_counts\n                        .iter()\n                        .map(|(lang, count)| format!(\"{} ({})\", lang, count))\n                        .collect::<Vec<_>>()\n                        .join(\", \")\n                };\n\n                let type_summary = if type_counts.is_empty() {\n                    \"n/a\".to_string()\n                } else {\n                    type_counts\n                        .iter()\n                        .map(|(ty, count)| format!(\"{} ({})\", ty, count))\n                        .collect::<Vec<_>>()\n                        .join(\", \")\n                };\n\n                content.push_str(&format!(\"- Layer(s): {}\\n\", layer_summary));\n                content.push_str(&format!(\"- Language coverage: {}\\n\", lang_summary));\n                content.push_str(&format!(\"- Element types: {}\\n\", type_summary));\n                content.push_str(&format!(\"- Total elements: {}\\n\\n\", elements.len()));\n\n                content.push_str(\"### Elements\\n\\n\");\n                elements.sort_by(|a, b| {\n                    a.line_number\n                        .cmp(&b.line_number)\n                        .then_with(|| a.name.cmp(&b.name))\n                });\n                for elem in elements {\n                    content.push_str(&self.format_element_entry(elem));\n                }\n                content.push('\\n');\n            }\n\n            fs::write(dir.join(file_name), content)?;\n        }\n\n        // Summary statistics\n        index.push_str(\"\\n## Summary Statistics\\n\\n\");\n        index.push_str(&format!(\"- Total elements: {}\\n\", result.elements.len()));\n        index.push_str(&format!(\n            \"- Rust elements: {}\\n\",\n            result\n                .elements\n                .iter()\n                .filter(|e| matches!(e.language, Language::Rust))\n                .count()\n        ));\n        index.push_str(&format!(\n            \"- Julia elements: {}\\n\",\n            result\n                .elements\n                .iter()\n                .filter(|e| matches!(e.language, Language::Julia))\n                .count()\n        ));\n\n        let mut type_counts: HashMap<String, usize> = HashMap::new();\n        for elem in &result.elements {\n            let key = format!(\"{:?}_{:?}\", elem.language, elem.element_type);\n            *type_counts.entry(key).or_insert(0) += 1;\n        }\n\n        index.push_str(\"\\n### Elements by Type\\n\\n\");\n        let mut sorted_types: Vec<_> = type_counts.iter().collect();\n        sorted_types.sort_by_key(|(k, _)| k.as_str());\n        for (type_name, count) in sorted_types {\n            index.push_str(&format!(\"- {}: {}\\n\", type_name, count));\n        }\n\n        fs::write(dir.join(\"index.md\"), index)?;\n        Ok(())\n    }\n\n    fn format_element_entry(&self, elem: &CodeElement) -> String {\n        let mut entry = format!(\n            \"- [{} | {:?}] `{}` (line {}, {})\\n\",\n            language_label(&elem.language),\n            elem.element_type,\n            elem.name,\n            elem.line_number,\n            visibility_label(&elem.visibility),\n        );\n\n        if !elem.signature.is_empty()\n            && matches!(\n                elem.element_type,\n                ElementType::Function | ElementType::Struct\n            )\n        {\n            entry.push_str(&format!(\n                \"  - Signature: `{}`\\n\",\n                short_signature(&elem.signature)\n            ));\n        }\n\n        if !elem.generic_params.is_empty() {\n            entry.push_str(&format!(\n                \"  - Generics: {}\\n\",\n                elem.generic_params.join(\", \")\n            ));\n        }\n\n        if matches!(elem.element_type, ElementType::Function) && !elem.calls.is_empty() {\n            entry.push_str(&format!(\"  - Calls: {}\\n\", elem.calls.join(\", \")));\n        }\n\n        entry\n    }\n\n    fn generate_call_graph_report(&self, cf_analyzer: &ControlFlowAnalyzer) -> Result<()> {\n        let dir = self.prepare_report_dir(\"20_call_graph\")?;\n        let path = dir.join(\"index.md\");\n        let mut content = String::from(\"# Call Graph Analysis\\n\\n\");\n        content.push_str(\"This document shows the **interprocedural call graph** - which functions call which other functions.\\n\\n\");\n        content.push_str(\"> **Note:** This is NOT a control flow graph (CFG). CFG shows intraprocedural control flow (branches, loops) within individual functions.\\n\\n\");\n\n        let stats = cf_analyzer.get_statistics();\n\n        content.push_str(\"## Call Graph Statistics\\n\\n\");\n        content.push_str(&format!(\"- Total functions: {}\\n\", stats.total_functions));\n        content.push_str(&format!(\"- Total function calls: {}\\n\", stats.total_calls));\n        content.push_str(&format!(\"- Maximum call depth: {}\\n\", stats.max_depth));\n        content.push_str(&format!(\n            \"- Leaf functions (no outgoing calls): {}\\n\\n\",\n            stats.leaf_functions\n        ));\n\n        content.push_str(\"## Call Graph Visualization\\n\\n\");\n        content.push_str(&cf_analyzer.generate_mermaid());\n\n        fs::write(path, content)?;\n        Ok(())\n    }\n\n    fn generate_cfg_report(&self, cf_analyzer: &ControlFlowAnalyzer) -> Result<()> {\n        let dir = self.prepare_report_dir(\"30_cfg\")?;\n        let mut index = String::from(\"# Control Flow Graphs (CFG)\\n\\n\");\n        index.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        if cf_analyzer.cfgs().is_empty() {\n            index.push_str(\"No control flow graphs were captured.\\n\");\n            fs::write(dir.join(\"index.md\"), index)?;\n            return Ok(());\n        }\n\n        let mut grouped: BTreeMap<String, Vec<(String, &FunctionCfg)>> = BTreeMap::new();\n        for cfg in cf_analyzer.cfgs() {\n            let compressed = compress_path(&cfg.file_path);\n            let key = prefix_key_from_path(&compressed);\n            grouped\n                .entry(key)\n                .or_insert_with(Vec::new)\n                .push((compressed, cfg));\n        }\n\n        let mut grouped: Vec<_> = grouped.into_iter().collect();\n        grouped.sort_by(|a, b| group_key_cmp(&a.0, &b.0));\n\n        index.push_str(&format!(\"- Total CFGs: {}\\n\", cf_analyzer.cfgs().len()));\n        index.push_str(\n            \"- Files are grouped by MMSB directory prefix; numeric prefixes match lexical ordering.\\n\\n\",\n        );\n\n        index.push_str(\"## Group Files\\n\\n\");\n        for (idx, (group_key, _)) in grouped.iter().enumerate() {\n            let file_name = format!(\"{:03}-{}.md\", idx * 10, slugify_key(group_key));\n            index.push_str(&format!(\"- `{}`  `{}`\\n\", group_key, file_name));\n        }\n\n        for (idx, (group_key, mut entries)) in grouped.into_iter().enumerate() {\n            entries.sort_by(|a, b| a.1.function.cmp(&b.1.function));\n            let slug = slugify_key(&group_key);\n            let file_name = format!(\"{:03}-{}.md\", idx * 10, slug);\n            let mut content = format!(\"# CFG Group: {}\\n\\n\", group_key);\n\n            for (compressed, cfg) in entries {\n                content.push_str(&format!(\"## Function: `{}`\\n\\n\", cfg.function));\n                content.push_str(&format!(\n                    \"- File: {}\\n- Branches: {}\\n- Loops: {}\\n- Nodes: {}\\n- Edges: {}\\n\\n\",\n                    compressed,\n                    cfg.branch_count,\n                    cfg.loop_count,\n                    cfg.nodes.len(),\n                    cfg.edges.len(),\n                ));\n                if let Some(dot_rel) = self.dot_path_for(&compressed) {\n                    content.push_str(&format!(\"- DOT call graph: `{}`\\n\\n\", dot_rel));\n                }\n\n                content.push_str(\"```mermaid\\nflowchart TD\\n\");\n                let mut id_map = HashMap::new();\n                let prefix = sanitize_mermaid_id(&cfg.function);\n                for node in &cfg.nodes {\n                    let raw_id = format!(\"{}_{}\", prefix, node.id);\n                    let safe_id = sanitize_mermaid_id(&raw_id);\n                    id_map.insert(node.id, safe_id.clone());\n                    content.push_str(&format!(\n                        \"    {}[\\\"{}\\\"]\\n\",\n                        safe_id,\n                        sanitize_mermaid_label(&node.label)\n                    ));\n                }\n                for edge in &cfg.edges {\n                    if let (Some(src), Some(dst)) = (id_map.get(&edge.from), id_map.get(&edge.to)) {\n                        content.push_str(&format!(\"    {} --> {}\\n\", src, dst));\n                    }\n                }\n                content.push_str(\"```\\n\\n\");\n            }\n\n            fs::write(dir.join(file_name), content)?;\n        }\n\n        fs::write(dir.join(\"index.md\"), index)?;\n        Ok(())\n    }\n\n    fn generate_layer_dependency_report(\n        &self,\n        rust_layers: &LayerGraph,\n        julia_layers: &LayerGraph,\n        root_path: &Path,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"60_layer_dependencies\")?;\n        let path = dir.join(\"index.md\");\n        let mut content = String::from(\"# Layer Dependency Report\\n\\n\");\n        content.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        self.write_layer_section(&mut content, \"Rust\", rust_layers, root_path);\n        self.write_layer_section(&mut content, \"Julia\", julia_layers, root_path);\n\n        fs::write(path, content)?;\n        Ok(())\n    }\n\n    fn generate_file_ordering_report(\n        &self,\n        rust_ordering: &FileOrderingResult,\n        julia_ordering: &FileOrderingResult,\n        root_path: &Path,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"70_file_ordering\")?;\n        let path = dir.join(\"index.md\");\n        let mut content = String::from(\"# File Ordering Report\\n\\n\");\n        content.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        self.write_ordering_section(&mut content, \"Rust\", rust_ordering, root_path);\n        self.write_ordering_section(&mut content, \"Julia\", julia_ordering, root_path);\n\n        fs::write(path, content)?;\n        Ok(())\n    }\n\n    fn write_ordering_section(\n        &self,\n        content: &mut String,\n        label: &str,\n        ordering: &FileOrderingResult,\n        root_path: &Path,\n    ) {\n        content.push_str(&format!(\"## {} File Ordering\\n\\n\", label));\n        if ordering.ordered_files.is_empty() {\n            content.push_str(\"No files analyzed.\\n\\n\");\n            return;\n        }\n\n        let rename_count = ordering\n            .ordered_files\n            .iter()\n            .filter(|entry| entry.needs_rename)\n            .count();\n        content.push_str(\"### Metrics\\n\\n\");\n        content.push_str(&format!(\n            \"- Total files: {}\\n- Rename suggestions: {}\\n- Ordering violations: {}\\n- Layer violations: {}\\n- Directories: {}\\n\\n\",\n            ordering.ordered_files.len(),\n            rename_count,\n            ordering.violations.len(),\n            ordering.layer_violations.len(),\n            ordering.ordered_directories.len()\n        ));\n\n        if !ordering.cycles.is_empty() {\n            content.push_str(\"### Cycles Detected\\n\");\n            for cycle in &ordering.cycles {\n                let listing = cycle\n                    .iter()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .collect::<Vec<_>>()\n                    .join(\", \");\n                content.push_str(&format!(\"- {}\\n\", listing));\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Canonical Order\\n\\n\");\n        content.push_str(\"| Order | Current | Suggested | Rename |\\n\");\n        content.push_str(\"| --- | --- | --- | --- |\\n\");\n        for entry in &ordering.ordered_files {\n            let current = display_path(&entry.current_path, root_path);\n            let rename = if entry.needs_rename { \"yes\" } else { \"no\" };\n            content.push_str(&format!(\n                \"| {} | `{}` | `{}` | {} |\\n\",\n                entry.canonical_order, current, entry.suggested_name, rename\n            ));\n        }\n        content.push('\\n');\n\n        content.push_str(\"### Ordering Violations\\n\");\n        if ordering.violations.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for violation in &ordering.violations {\n                let file = display_path(&violation.file, root_path);\n                content.push_str(&format!(\n                    \"- `{}`: alphabetical position {}, required position {}\\n\",\n                    file, violation.current_position, violation.required_position\n                ));\n                if !violation.blocking_dependencies.is_empty() {\n                    for dep in &violation.blocking_dependencies {\n                        let dep_path = display_path(dep, root_path);\n                        content.push_str(&format!(\"  - depends on `{}`\\n\", dep_path));\n                    }\n                }\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Layer Violations\\n\");\n        if ordering.layer_violations.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for violation in &ordering.layer_violations {\n                let from = display_path(&violation.from, root_path);\n                let to = display_path(&violation.to, root_path);\n                content.push_str(&format!(\n                    \"- `{}` ({}) depends on `{}` ({})\\n\",\n                    to, violation.to_layer, from, violation.from_layer\n                ));\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Directory Order\\n\");\n        if ordering.ordered_directories.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for dir in &ordering.ordered_directories {\n                let path = display_path(dir, root_path);\n                content.push_str(&format!(\"- `{}`\\n\", path));\n            }\n            content.push('\\n');\n        }\n    }\n\n    fn generate_cohesion_report(\n        &self,\n        placements: &[FunctionPlacement],\n        clusters: &[FunctionCluster],\n        root_path: &Path,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"80_cohesion_analysis\")?;\n        let path = dir.join(\"index.md\");\n        let mut content = String::from(\"# Function Cohesion Analysis\\n\\n\");\n        content.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        if placements.is_empty() {\n            content.push_str(\"No function placement data recorded.\\n\");\n            fs::write(path, content)?;\n            return Ok(());\n        }\n\n        let mut by_file: BTreeMap<String, Vec<&FunctionPlacement>> = BTreeMap::new();\n        let avg_cohesion = if placements.is_empty() {\n            0.0\n        } else {\n            placements\n                .iter()\n                .map(|p| p.cohesion_score)\n                .sum::<f64>()\n                / placements.len() as f64\n        };\n        let move_count = placements\n            .iter()\n            .filter(|p| matches!(p.placement_status, PlacementStatus::ShouldMove { .. }))\n            .count();\n        let (orphaned, delete_candidates) =\n            filter_orphaned(placements, root_path, &self.output_dir);\n        let orphaned_count = orphaned.len();\n        let layer_violation_count = placements\n            .iter()\n            .filter(|p| matches!(p.placement_status, PlacementStatus::LayerViolation { .. }))\n            .count();\n        content.push_str(\"## Metrics\\n\\n\");\n        content.push_str(&format!(\n            \"- Avg cohesion: {:.2}\\n- Move suggestions: {}\\n- Orphaned functions: {}\\n- Layer violations: {}\\n\\n\",\n            avg_cohesion, move_count, orphaned_count, layer_violation_count\n        ));\n        for placement in placements {\n            by_file\n                .entry(placement.current_file.to_string_lossy().to_string())\n                .or_default()\n                .push(placement);\n        }\n\n        for (file, mut entries) in by_file {\n            entries.sort_by(|a, b| {\n                a.cohesion_score\n                    .partial_cmp(&b.cohesion_score)\n                    .unwrap_or(Ordering::Equal)\n            });\n            let compressed = compress_path(&file);\n            content.push_str(&format!(\"## File: {}\\n\\n\", compressed));\n            content.push_str(\"| Function | Signature | Cohesion | Calls | Type refs | Status | Suggestion |\\n\");\n            content.push_str(\"| --- | --- | --- | --- | --- | --- | --- |\\n\");\n            for entry in entries {\n                let status = placement_status_label(&entry.placement_status);\n                let mut suggestion = entry\n                    .suggested_file\n                    .as_ref()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .unwrap_or_else(|| \"-\".to_string());\n                let notes = placement_status_notes(&entry.placement_status);\n                if !notes.is_empty() {\n                    suggestion = format!(\"{} ({})\", suggestion, notes);\n                }\n                let call_summary = format!(\n                    \"intra {}, inter {}\",\n                    entry.call_analysis.intra_file_calls,\n                    entry.call_analysis.inter_file_calls.len()\n                );\n                let type_summary = format!(\n                    \"same {}, other {}\",\n                    entry.call_analysis.same_file_type_refs,\n                    entry.call_analysis.other_file_type_refs\n                );\n                content.push_str(&format!(\n                    \"| `{}` | `{}` | {:.2} | {} | {} | {} | {} |\\n\",\n                    entry.name,\n                    entry.signature.replace('|', \"\\\\|\"),\n                    entry.cohesion_score,\n                    call_summary,\n                    type_summary,\n                    status,\n                    suggestion\n                ));\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"## Orphaned Functions (Review Only)\\n\\n\");\n        content.push_str(\"Action: review each item for expected usage. Delete only if it also appears under \\\"Delete Candidates (Orphaned + Dead Code)\\\".\\n\");\n        content.push_str(\"Note: excludes public symbols referenced by other modules and entry points. Delete candidates require dead_code warnings.\\n\\n\");\n        if orphaned.is_empty() {\n            content.push_str(\"- None detected.\\n\");\n        } else {\n            for entry in orphaned {\n                let file = compress_path(entry.current_file.to_string_lossy().as_ref());\n                content.push_str(&format!(\"- `{}` in `{}`\\n\", entry.name, file));\n            }\n        }\n        content.push('\\n');\n        content.push_str(\"## Delete Candidates (Orphaned + Dead Code)\\n\\n\");\n        if delete_candidates.is_empty() {\n            content.push_str(\"- None detected.\\n\");\n        } else {\n            for entry in delete_candidates {\n                let file = compress_path(entry.current_file.to_string_lossy().as_ref());\n                content.push_str(&format!(\"- `{}` in `{}`\\n\", entry.name, file));\n            }\n        }\n        content.push('\\n');\n\n        let utility_candidates = collect_utility_candidates(placements);\n        content.push_str(\"## Utility Module Candidates\\n\\n\");\n        if utility_candidates.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for candidate in utility_candidates {\n                content.push_str(&format!(\"- {}\\n\", candidate));\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"## Function Clusters\\n\\n\");\n        if clusters.is_empty() {\n            content.push_str(\"- None detected.\\n\");\n        } else {\n            for cluster in clusters {\n                let suggested = cluster\n                    .suggested_file\n                    .as_ref()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .unwrap_or_else(|| \"-\".to_string());\n                let members = cluster\n                    .members\n                    .iter()\n                    .map(|m| compress_path(m))\n                    .collect::<Vec<_>>()\n                    .join(\", \");\n                content.push_str(&format!(\n                    \"- cohesion {:.2}, suggested `{}`\\n  - {}\\n\",\n                    cluster.cohesion, suggested, members\n                ));\n            }\n        }\n        content.push('\\n');\n\n        fs::write(path, content)?;\n        Ok(())\n    }\n\n    fn generate_refactoring_plan(\n        &self,\n        rust_ordering: &FileOrderingResult,\n        julia_ordering: &FileOrderingResult,\n        placements: &[FunctionPlacement],\n        clusters: &[FunctionCluster],\n        directory: &DirectoryAnalysis,\n        root_path: &Path,\n        correction_report: Option<&crate::correction_intelligence_report::CorrectionIntelligenceReport>,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"00_refactoring_plan\")?;\n        let generated_at = chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\").to_string();\n\n        let mut renames = collect_rename_items(rust_ordering, \"Rust\")\n            .into_iter()\n            .chain(collect_rename_items(julia_ordering, \"Julia\"))\n            .collect::<Vec<_>>();\n        renames.extend(directory_moves_to_plan(\n            \"Rust\",\n            collect_directory_moves(rust_ordering, root_path),\n        ));\n        renames.extend(directory_moves_to_plan(\n            \"Julia\",\n            collect_directory_moves(julia_ordering, root_path),\n        ));\n        let cluster_plans = collect_cluster_plans(clusters, root_path);\n        let cluster_items = collect_cluster_items(&cluster_plans);\n        let mut utility_names = BTreeSet::new();\n        for placement in placements {\n            if placement.call_analysis.calls_from_other_files.len() >= 3 {\n                utility_names.insert(placement.name.clone());\n            }\n        }\n        let mut moves = collect_move_items(placements, &utility_names, directory, root_path);\n\n        // MECHANICAL CONSTRAINT ENFORCEMENT\n        // Filter moves by invariant constraints to prevent unsafe refactorings\n        if let Ok(constraints_json) = std::fs::read_to_string(\n            std::path::Path::new(&self.output_dir).join(\"96_constraints/refactor_constraints.json\")\n        ) {\n            use crate::refactor_constraints::RefactorConstraint;\n            if let Ok(constraints) = serde_json::from_str::<Vec<RefactorConstraint>>(&constraints_json) {\n                let mut blocked_count = 0;\n\n                moves.retain(|m| {\n                    // Check if this move violates any constraint\n                    use crate::action_validator::check_move_allowed;\n\n                    // Skip items without name or current/target file paths\n                    let name = match &m.name {\n                        Some(n) => n.clone(),\n                        None => return true, // Keep if no name to check\n                    };\n\n                    let from = match &m.current_file {\n                        Some(f) => f.clone(),\n                        None => return true,\n                    };\n\n                    let to = match &m.target_file {\n                        Some(t) => t.clone(),\n                        None => return true,\n                    };\n\n                    match check_move_allowed(&name, &from, &to, &constraints) {\n                        Ok(_) => true,  // Allowed\n                        Err(reason) => {\n                            // Log rejection (only in verbose mode to avoid clutter)\n                            if std::env::var(\"VERBOSE\").is_ok() {\n                                eprintln!(\"  BLOCKED: {} - {}\", name, reason);\n                            }\n                            blocked_count += 1;\n                            false  // Filtered out\n                        }\n                    }\n                });\n\n                if blocked_count > 0 {\n                    println!(\" Constraint enforcement: {} moves allowed, {} blocked by invariants\",\n                             moves.len(), blocked_count);\n                }\n            }\n        }\n\n        let (orphaned, delete_candidates) =\n            filter_orphaned(placements, root_path, &self.output_dir);\n\n        let mut all_items = Vec::new();\n        all_items.extend(cluster_items.iter().cloned());\n        all_items.extend(renames.iter().cloned());\n        all_items.extend(moves.iter().cloned());\n\n        let mut correctness: Vec<PlanItem> = Vec::new();\n        let mut clusters_phase = Vec::new();\n        let mut structural = Vec::new();\n        let mut cohesion = Vec::new();\n        let mut ordering = Vec::new();\n\n        for item in all_items {\n            match item.kind {\n                ActionKind::Cluster => clusters_phase.push(item),\n                ActionKind::Structural => structural.push(item),\n                ActionKind::Cohesion => cohesion.push(item),\n                ActionKind::Ordering => ordering.push(item),\n            }\n        }\n\n        sort_plan_items(&mut correctness);\n        sort_cluster_items(&mut clusters_phase);\n        sort_structural_items(&mut structural);\n        sort_plan_items(&mut cohesion);\n        sort_plan_items(&mut ordering);\n\n        let config = load_report_config(&self.output_dir);\n        let dir_cohesion = compute_directory_cohesion(placements);\n        let avg_cohesion = if placements.is_empty() {\n            0.0\n        } else {\n            placements\n                .iter()\n                .map(|p| p.cohesion_score)\n                .sum::<f64>()\n                / placements.len() as f64\n        };\n        let ordering_correctness = compute_ordering_correctness(rust_ordering, julia_ordering);\n        let relocations = placements\n            .iter()\n            .filter(|p| matches!(p.placement_status, PlacementStatus::ShouldMove { .. }\n                | PlacementStatus::LayerViolation { .. }))\n            .count();\n\n        write_baseline_metrics(\n            &config,\n            &self.output_dir,\n            dir_cohesion,\n            ordering_correctness,\n            avg_cohesion,\n            renames.len(),\n            relocations,\n        );\n\n        let mut summary = String::from(\"# Refactoring Plan\\n\\n\");\n        summary.push_str(&format!(\"Generated: {}\\n\\n\", generated_at));\n        summary.push_str(\"## Summary\\n\\n\");\n        summary.push_str(\"Action: use this as the quick status snapshot for planning work.\\n\");\n        summary.push_str(\"Note: counts are derived from current analysis output.\\n\\n\");\n        summary.push_str(&format!(\n            \"- File/dir renames: {}\\n- Function moves: {}\\n- Orphaned functions: {}\\n- Clusters: {}\\n\\n\",\n            renames.len(),\n            moves.len(),\n            orphaned.len(),\n            clusters.len()\n        ));\n\n        let mut metrics = String::new();\n        metrics.push_str(\"## Metrics\\n\\n\");\n        metrics.push_str(\"Action: monitor trends and regressions across runs.\\n\");\n        metrics.push_str(\"Note: compare against baseline metrics when available.\\n\\n\");\n        metrics.push_str(&format!(\n            \"- Directory cohesion: {:.2}\\n- Ordering correctness: {:.1}%\\n- Avg function cohesion: {:.2}\\n- Rename ops needed: {}\\n- Function relocations suggested: {}\\n\\n\",\n            dir_cohesion,\n            ordering_correctness * 100.0,\n            avg_cohesion,\n            renames.len(),\n            relocations\n        ));\n\n        let mut baseline_section = String::new();\n        if let Some(baseline) = load_baseline_metrics(&config, &self.output_dir) {\n            let mut regression_warnings = Vec::new();\n            let epsilon = 0.005;\n            if let Some(prev) = baseline.get(\"directory_cohesion\") {\n                if dir_cohesion + epsilon < *prev {\n                    regression_warnings.push(format!(\n                        \"Directory cohesion dropped from {:.2} to {:.2}.\",\n                        prev, dir_cohesion\n                    ));\n                }\n            }\n            if let Some(prev) = baseline.get(\"ordering_correctness\") {\n                let current = ordering_correctness * 100.0;\n                if current + epsilon < *prev {\n                    regression_warnings.push(format!(\n                        \"Ordering correctness dropped from {:.1}% to {:.1}%.\",\n                        prev, current\n                    ));\n                }\n            }\n            if let Some(prev) = baseline.get(\"avg_function_cohesion\") {\n                if avg_cohesion + epsilon < *prev {\n                    regression_warnings.push(format!(\n                        \"Avg function cohesion dropped from {:.2} to {:.2}.\",\n                        prev, avg_cohesion\n                    ));\n                }\n            }\n            if let Some(prev) = baseline.get(\"rename_ops_needed\") {\n                if (renames.len() as f64) > *prev + epsilon {\n                    regression_warnings.push(format!(\n                        \"Rename ops needed increased from {:.0} to {}.\",\n                        prev,\n                        renames.len()\n                    ));\n                }\n            }\n            if let Some(prev) = baseline.get(\"function_relocations\") {\n                if (relocations as f64) > *prev + epsilon {\n                    regression_warnings.push(format!(\n                        \"Function relocations suggested increased from {:.0} to {}.\",\n                        prev,\n                        relocations\n                    ));\n                }\n            }\n\n            let deltas = baseline_deltas(\n                &baseline,\n                dir_cohesion,\n                ordering_correctness,\n                avg_cohesion,\n                renames.len(),\n                relocations,\n            );\n            if !deltas.is_empty() {\n                println!(\"Baseline deltas:\");\n                for line in &deltas {\n                    println!(\"  {}\", line);\n                }\n            }\n\n            baseline_section.push_str(\"## Baseline Regression Warnings\\n\\n\");\n            baseline_section\n                .push_str(\"Action: investigate any regressions before proceeding with refactors.\\n\");\n            baseline_section.push_str(\"Note: derived from the last saved baseline metrics.\\n\\n\");\n            if regression_warnings.is_empty() {\n                baseline_section.push_str(\"- None.\\n\\n\");\n            } else {\n                for warning in regression_warnings {\n                    baseline_section.push_str(&format!(\"- {}\\n\", warning));\n                }\n                baseline_section.push('\\n');\n            }\n        } else {\n            baseline_section.push_str(\"## Baseline Regression Warnings\\n\\n\");\n            baseline_section\n                .push_str(\"Action: save a baseline to enable regression tracking.\\n\");\n            baseline_section\n                .push_str(\"Note: baseline metrics file not found for this output directory.\\n\\n\");\n            baseline_section.push_str(\"- None.\\n\\n\");\n        }\n\n        let mut phase1 = String::new();\n        write_priority_section(&mut phase1, \"Phase 1: Correctness Blockers\", &correctness);\n\n        let mut phase2 = String::new();\n        write_priority_section(&mut phase2, \"Phase 2: Cluster Extraction\", &clusters_phase);\n        write_cluster_tips(&mut phase2, &cluster_plans);\n        write_cluster_batches(&mut phase2, &cluster_plans, root_path);\n\n        let mut phase3 = String::new();\n        write_priority_section(&mut phase3, \"Phase 3: Structural Constraints\", &structural);\n        write_structural_tips(&mut phase3, &structural);\n        write_structural_batches(&mut phase3, &structural);\n\n        let mut phase4 = String::new();\n        write_priority_section(&mut phase4, \"Phase 4: Cohesion Improvements\", &cohesion);\n\n        let mut phase5 = String::new();\n        write_priority_section(&mut phase5, \"Phase 5: Ordering & Renames\", &ordering);\n\n        let mut orphaned_section = String::new();\n        orphaned_section.push_str(\"## Orphaned Functions (Review Only)\\n\\n\");\n        orphaned_section.push_str(\"Action: review each item for expected usage. Delete only if it also appears under \\\"Delete Candidates (Orphaned + Dead Code)\\\".\\n\");\n        orphaned_section.push_str(\"Note: excludes public symbols referenced by other modules and entry points. Delete candidates require dead_code warnings.\\n\\n\");\n        if orphaned.is_empty() {\n            orphaned_section.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for entry in &orphaned {\n                let file = compress_path(entry.current_file.to_string_lossy().as_ref());\n                orphaned_section.push_str(&format!(\"- `{}` in `{}`\\n\", entry.name, file));\n            }\n            orphaned_section.push('\\n');\n        }\n\n        let mut delete_section = String::new();\n        delete_section.push_str(\"## Delete Candidates (Orphaned + Dead Code)\\n\\n\");\n        delete_section.push_str(\"Action: consider removal after confirming behavior and running tests.\\n\");\n        delete_section.push_str(\"Note: derived from orphaned list plus compiler dead_code warnings.\\n\\n\");\n        if delete_candidates.is_empty() {\n            delete_section.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for entry in &delete_candidates {\n                let file = compress_path(entry.current_file.to_string_lossy().as_ref());\n                delete_section.push_str(&format!(\"- `{}` in `{}`\\n\", entry.name, file));\n            }\n            delete_section.push('\\n');\n        }\n\n        let mut cluster_suggestions = String::new();\n        cluster_suggestions.push_str(\"## Suggested New Files (Clusters)\\n\\n\");\n        cluster_suggestions.push_str(\"Action: consider creating these files to improve cohesion.\\n\");\n        cluster_suggestions.push_str(\"Note: suggestions are heuristic and should be validated.\\n\\n\");\n        if clusters.is_empty() {\n            cluster_suggestions.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for cluster in clusters {\n                let suggested = cluster\n                    .suggested_file\n                    .as_ref()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .unwrap_or_else(|| \"new module\".to_string());\n                let members = cluster\n                    .members\n                    .iter()\n                    .map(|m| compress_path(m))\n                    .collect::<Vec<_>>()\n                    .join(\", \");\n                cluster_suggestions.push_str(&format!(\n                    \"- cohesion {:.2}, suggested `{}`\\n  - {}\\n\",\n                    cluster.cohesion, suggested, members\n                ));\n            }\n            cluster_suggestions.push('\\n');\n        }\n\n        let utility_candidates = collect_utility_candidates(placements);\n        let mut utility_section = String::new();\n        utility_section.push_str(\"## Utility Module Candidates\\n\\n\");\n        utility_section.push_str(\"Action: consider consolidating these into a shared utilities module.\\n\");\n        utility_section.push_str(\"Note: candidates are based on cross-file usage frequency.\\n\\n\");\n        if utility_candidates.is_empty() {\n            utility_section.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for candidate in utility_candidates {\n                utility_section.push_str(&format!(\"- {}\\n\", candidate));\n            }\n            utility_section.push('\\n');\n        }\n\n        let mut naming_warnings = Vec::new();\n        let _ = collect_naming_warnings(directory, &config, &mut naming_warnings);\n        let mut naming_section = String::new();\n        naming_section.push_str(\"## Naming Warnings\\n\\n\");\n        naming_section.push_str(\"Action: rename files if the suggested name improves ordering clarity.\\n\");\n        naming_section.push_str(\"Note: `_old` paths are excluded from naming warnings.\\n\\n\");\n        if naming_warnings.is_empty() {\n            naming_section.push_str(\"- None.\\n\\n\");\n        } else {\n            for warning in naming_warnings {\n                naming_section.push_str(&format!(\"- {}\\n\", warning));\n            }\n            naming_section.push('\\n');\n        }\n\n        let mut size_warnings = Vec::new();\n        collect_size_warnings(directory, &config, &mut size_warnings);\n        let mut size_section = String::new();\n        size_section.push_str(\"## Size Warnings\\n\\n\");\n        size_section.push_str(\"Action: consider extracting helpers to reduce file size.\\n\");\n        size_section.push_str(\"Note: thresholds come from report configuration.\\n\\n\");\n        if size_warnings.is_empty() {\n            size_section.push_str(\"- None.\\n\\n\");\n        } else {\n            for warning in size_warnings {\n                size_section.push_str(&format!(\"- {}\\n\", warning));\n            }\n            size_section.push('\\n');\n        }\n\n        let mut cargo_section = String::new();\n        if let Some(warnings) = load_cargo_warnings(&self.output_dir) {\n            cargo_section.push_str(\"## Cargo Warnings\\n\\n\");\n            cargo_section.push_str(\"Action: address compiler warnings before major refactors.\\n\");\n            cargo_section.push_str(\"Note: captured from cargo check/test outputs.\\n\\n\");\n            if warnings.trim().is_empty() {\n                cargo_section.push_str(\"- None.\\n\\n\");\n            } else {\n                cargo_section.push_str(\"```text\\n\");\n                cargo_section.push_str(warnings.trim());\n                cargo_section.push_str(\"\\n```\\n\\n\");\n            }\n        } else {\n            cargo_section.push_str(\"## Cargo Warnings\\n\\n\");\n            cargo_section.push_str(\"Action: address compiler warnings before major refactors.\\n\");\n            cargo_section.push_str(\"Note: no cargo warnings captured in this run.\\n\\n\");\n            cargo_section.push_str(\"- None.\\n\\n\");\n        }\n\n        let mut correction_section = String::new();\n        if let Some(report) = correction_report {\n            correction_section.push_str(\"## Correction Intelligence\\n\\n\");\n            correction_section.push_str(\"Action: review correction plans and verification policies before execution.\\n\");\n            correction_section.push_str(\"Note: generated for mmsb-executor ingestion; analyzer does not mutate code.\\n\\n\");\n            correction_section.push_str(&format!(\n                \"- Actions analyzed: {}\\n- Trivial: {}\\n- Moderate: {}\\n- Complex: {}\\n- Avg confidence: {:.1}%\\n\\n\",\n                report.actions_analyzed,\n                report.summary.trivial_count,\n                report.summary.moderate_count,\n                report.summary.complex_count,\n                report.summary.average_confidence * 100.0\n            ));\n            correction_section.push_str(\n                \"- JSON: `97_correction_intelligence/correction_intelligence.json`\\n\",\n            );\n            correction_section.push_str(\n                \"- Verification policy: `97_correction_intelligence/verification_policy.json`\\n\\n\",\n            );\n        }\n\n        let mut files = Vec::new();\n        files.push((\"00_summary.md\", summary));\n        files.push((\"01_metrics.md\", metrics));\n        files.push((\"02_baseline_regressions.md\", baseline_section));\n        files.push((\"03_phase1_correctness.md\", phase1));\n        files.push((\"04_phase2_clusters.md\", phase2));\n        files.push((\"05_phase3_structural.md\", phase3));\n        files.push((\"06_phase4_cohesion.md\", phase4));\n        files.push((\"07_phase5_ordering_renames.md\", phase5));\n        files.push((\"08_orphaned_functions.md\", orphaned_section));\n        files.push((\"09_delete_candidates.md\", delete_section));\n        files.push((\"10_suggested_new_files.md\", cluster_suggestions));\n        files.push((\"11_utility_module_candidates.md\", utility_section));\n        files.push((\"12_naming_warnings.md\", naming_section));\n        files.push((\"13_size_warnings.md\", size_section));\n        files.push((\"14_cargo_warnings.md\", cargo_section));\n        if correction_report.is_some() {\n            files.push((\"15_correction_intelligence.md\", correction_section));\n        }\n\n        let mut index = String::from(\"# Refactoring Plan Index\\n\\n\");\n        index.push_str(&format!(\"Generated: {}\\n\\n\", generated_at));\n        for (name, _) in &files {\n            index.push_str(&format!(\"- `{}`\\n\", name));\n        }\n        fs::write(dir.join(\"index.md\"), index)?;\n        for (name, content) in files {\n            fs::write(dir.join(name), content)?;\n        }\n        Ok(())\n    }\n\n    fn generate_file_organization_report(\n        &self,\n        directory: &DirectoryAnalysis,\n        _rust_ordering: &FileOrderingResult,\n        _julia_ordering: &FileOrderingResult,\n        root_path: &Path,\n    ) -> Result<()> {\n        let dir = self.prepare_report_dir(\"90_file_organization\")?;\n        let mut index = String::from(\"# File Organization Report\\n\\n\");\n        index.push_str(&format!(\n            \"Generated: {}\\n\\n\",\n            chrono::Local::now().format(\"%Y-%m-%d %H:%M:%S\")\n        ));\n\n        let mut entries = Vec::new();\n        collect_directories(directory, &mut entries);\n        for entry in &entries {\n            if entry.files.is_empty() {\n                continue;\n            }\n            let file_map = build_directory_entry_map(&entry.files)?;\n            let relative = entry\n                .path\n                .strip_prefix(root_path)\n                .unwrap_or(&entry.path)\n                .to_path_buf();\n            let slug = slugify_path(&relative);\n            let file_name = format!(\"{}.md\", slug);\n            index.push_str(&format!(\n                \"- `{}`  `{}`\\n\",\n                compress_path(entry.path.to_string_lossy().as_ref()),\n                file_name\n            ));\n\n            let mut content = format!(\n                \"# Directory: {}\\n\\n\",\n                compress_path(entry.path.to_string_lossy().as_ref())\n            );\n            content.push_str(&format!(\"- Layer: `{}`\\n\\n\", entry.layer));\n            content.push_str(\"## Files\\n\\n\");\n            content.push_str(\"| File | Suggested | Rename |\\n\");\n            content.push_str(\"| --- | --- | --- |\\n\");\n            let mut files = entry.files.clone();\n            files.sort();\n            for file in files {\n                let entry_info = file_map.get(&file);\n                let suggested = entry_info\n                    .map(|info| info.suggested_name.as_str())\n                    .unwrap_or(\"-\");\n                let rename = entry_info\n                    .map(|info| if info.needs_rename { \"yes\" } else { \"no\" })\n                    .unwrap_or(\"no\");\n                content.push_str(&format!(\n                    \"| `{}` | `{}` | {} |\\n\",\n                    compress_path(file.to_string_lossy().as_ref()),\n                    suggested,\n                    rename\n                ));\n            }\n            content.push('\\n');\n\n            content.push_str(\"## Dependency Graph\\n\\n\");\n            if entry.files.is_empty() {\n                content.push_str(\"No source files.\\n\\n\");\n            } else {\n                let graph = build_file_dependency_graph(&entry.files)?;\n                content.push_str(&render_mermaid_graph(&graph));\n                content.push('\\n');\n            }\n\n            fs::write(dir.join(file_name), content)?;\n        }\n\n        fs::write(dir.join(\"index.md\"), index)?;\n        Ok(())\n    }\n\n    fn write_layer_section(\n        &self,\n        content: &mut String,\n        label: &str,\n        graph: &LayerGraph,\n        root_path: &Path,\n    ) {\n        content.push_str(&format!(\"## {} Layer Graph\\n\\n\", label));\n\n        if graph.ordered_layers.is_empty() {\n            content.push_str(\"No layers discovered.\\n\\n\");\n            return;\n        }\n\n        content.push_str(\"### Layer Order\\n\");\n        for (idx, layer) in graph.ordered_layers.iter().enumerate() {\n            let cycle_tag = if graph.cycles.contains(layer) {\n                \" (cycle)\"\n            } else {\n                \"\"\n            };\n            content.push_str(&format!(\"{}. `{}`{}\\n\", idx + 1, layer, cycle_tag));\n        }\n        content.push('\\n');\n\n        if !graph.cycles.is_empty() {\n            content.push_str(\"### Cycles Detected\\n\");\n            for cycle in &graph.cycles {\n                content.push_str(&format!(\"- `{}`\\n\", cycle));\n            }\n            content.push('\\n');\n        }\n\n        let violations: Vec<_> = graph.edges.iter().filter(|e| e.violation).collect();\n        content.push_str(\"### Layer Violations\\n\");\n        if violations.is_empty() {\n            content.push_str(\"- None detected.\\n\\n\");\n        } else {\n            for edge in violations {\n                content.push_str(&format!(\n                    \"- `{}` depends on `{}` ({} references)\\n\",\n                    edge.to,\n                    edge.from,\n                    edge.references.len()\n                ));\n                for reference in &edge.references {\n                    let compressed = display_path(&reference.file, root_path);\n                    content.push_str(&format!(\"  - {} :: {}\\n\", compressed, reference.reference));\n                }\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Dependency Edges\\n\");\n        if graph.edges.is_empty() {\n            content.push_str(\"- No cross-layer dependencies recorded.\\n\\n\");\n        } else {\n            for edge in &graph.edges {\n                content.push_str(&format!(\n                    \"- `{}`  `{}` ({} references{})\\n\",\n                    edge.from,\n                    edge.to,\n                    edge.references.len(),\n                    if edge.violation { \", VIOLATION\" } else { \"\" }\n                ));\n                for reference in &edge.references {\n                    let compressed = display_path(&reference.file, root_path);\n                    content.push_str(&format!(\"  - {} :: {}\\n\", compressed, reference.reference));\n                }\n            }\n            content.push('\\n');\n        }\n\n        content.push_str(\"### Unresolved References\\n\");\n        if graph.unresolved.is_empty() {\n            content.push_str(\"- None.\\n\\n\");\n        } else {\n            for unresolved in &graph.unresolved {\n                let compressed = display_path(&unresolved.file, root_path);\n                content.push_str(&format!(\"- {}  `{}`\\n\", compressed, unresolved.reference));\n            }\n            content.push('\\n');\n        }\n    }\n\n    fn generate_module_dependencies(&self, result: &AnalysisResult) -> Result<()> {\n        let dir = self.prepare_report_dir(\"40_module_dependencies\")?;\n        let index_path = dir.join(\"index.md\");\n        let mut index = String::from(\"# Module Dependencies\\n\\n\");\n\n        if result.modules.is_empty() {\n            index.push_str(\"No module metadata captured yet.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        }\n\n        let mut modules_by_file: BTreeMap<String, ModuleAggregate> = BTreeMap::new();\n        for module in &result.modules {\n            let layer = self.extract_layer_from_path(&module.file_path);\n            let entry = modules_by_file\n                .entry(module.file_path.clone())\n                .or_insert_with(|| ModuleAggregate::new(module.name.clone(), layer.clone()));\n\n            if entry.name == \"unknown\" && !module.name.is_empty() {\n                entry.name = module.name.clone();\n            }\n\n            entry.layer = layer;\n            for import in &module.imports {\n                entry.imports.insert(normalize_use_stmt(import));\n            }\n            for export in &module.exports {\n                entry.exports.insert(normalize_use_stmt(export));\n            }\n            for sub in &module.submodules {\n                entry.submodules.insert(sub.clone());\n            }\n        }\n\n        let total_imports: usize = modules_by_file.values().map(|m| m.imports.len()).sum();\n        let total_exports: usize = modules_by_file.values().map(|m| m.exports.len()).sum();\n        let total_submodules: usize = modules_by_file.values().map(|m| m.submodules.len()).sum();\n\n        let mut modules: Vec<_> = modules_by_file.into_iter().collect();\n        modules.sort_by(|a, b| a.0.cmp(&b.0));\n\n        index.push_str(&format!(\"- Module files analyzed: {}\\n\", modules.len()));\n        index.push_str(&format!(\"- Unique imports captured: {}\\n\", total_imports));\n        index.push_str(&format!(\"- Unique exports captured: {}\\n\", total_exports));\n        index.push_str(&format!(\n            \"- Submodule declarations captured: {}\\n\\n\",\n            total_submodules\n        ));\n        index.push_str(\"## Per-file Summary\\n\\n\");\n        for (file_path, module) in &modules {\n            let compressed = compress_path(file_path);\n            index.push_str(&format!(\n                \"- `{}`  module `{}` (layer {}, {} imports / {} exports / {} submodules)\\n\",\n                compressed,\n                module.name,\n                module.layer,\n                module.imports.len(),\n                module.exports.len(),\n                module.submodules.len()\n            ));\n        }\n        index.push_str(\n            \"\\n## Detailed Files\\n\\n- `010-imports.md`  expanded import lists\\n- `020-exports.md`  export statements\\n- `030-submodules.md`  nested module declarations\\n- `040-violations.md`  placeholder for future per-module violations\\n\",\n        );\n        fs::write(&index_path, index)?;\n\n        let mut imports_doc = String::from(\"# Module Imports\\n\\n\");\n        let mut has_imports = false;\n        for (file_path, module) in &modules {\n            if module.imports.is_empty() {\n                continue;\n            }\n            has_imports = true;\n            let compressed = compress_path(file_path);\n            imports_doc.push_str(&format!(\"## {} ({})\\n\\n\", compressed, module.layer));\n            imports_doc.push_str(&format!(\"Module `{}`\\n\\n\", module.name));\n            for import in &module.imports {\n                imports_doc.push_str(&format!(\"- `{}`\\n\", import));\n            }\n            imports_doc.push('\\n');\n        }\n        if !has_imports {\n            imports_doc.push_str(\"No imports captured across modules.\\n\");\n        }\n        fs::write(dir.join(\"010-imports.md\"), imports_doc)?;\n\n        let mut exports_doc = String::from(\"# Module Exports\\n\\n\");\n        let mut has_exports = false;\n        for (file_path, module) in &modules {\n            if module.exports.is_empty() {\n                continue;\n            }\n            has_exports = true;\n            let compressed = compress_path(file_path);\n            exports_doc.push_str(&format!(\"## {} ({})\\n\\n\", compressed, module.layer));\n            exports_doc.push_str(&format!(\"Module `{}`\\n\\n\", module.name));\n            for export in &module.exports {\n                exports_doc.push_str(&format!(\"- `{}`\\n\", export));\n            }\n            exports_doc.push('\\n');\n        }\n        if !has_exports {\n            exports_doc.push_str(\"No exports captured across modules.\\n\");\n        }\n        fs::write(dir.join(\"020-exports.md\"), exports_doc)?;\n\n        let mut subs_doc = String::from(\"# Submodules\\n\\n\");\n        let mut has_submodules = false;\n        for (file_path, module) in &modules {\n            if module.submodules.is_empty() {\n                continue;\n            }\n            has_submodules = true;\n            let compressed = compress_path(file_path);\n            subs_doc.push_str(&format!(\"## {} ({})\\n\\n\", compressed, module.layer));\n            subs_doc.push_str(&format!(\"Module `{}`\\n\\n\", module.name));\n            for sub in &module.submodules {\n                subs_doc.push_str(&format!(\"- `{}`\\n\", sub));\n            }\n            subs_doc.push('\\n');\n        }\n        if !has_submodules {\n            subs_doc.push_str(\"No nested modules recorded.\\n\");\n        }\n        fs::write(dir.join(\"030-submodules.md\"), subs_doc)?;\n\n        let mut violations_doc = String::from(\"# Module Violations\\n\\n\");\n        violations_doc.push_str(\n            \"Per-module import/export violations are not computed yet.\\n\\\nRefer to `60_layer_dependencies/index.md` for cross-layer problems.\\n\",\n        );\n        fs::write(dir.join(\"040-violations.md\"), violations_doc)?;\n\n        Ok(())\n    }\n\n    fn generate_module_map_mismatch(&self, root_path: &Path) -> Result<()> {\n        let dir = self.prepare_report_dir(\"41_module_map_mismatch\")?;\n        let index_path = dir.join(\"index.md\");\n        let src_root = crate::layer_utilities::resolve_source_root(root_path);\n        let rust_files = crate::cluster_010::gather_rust_files(root_path)\n            .into_iter()\n            .filter(|path| path.starts_with(&src_root))\n            .collect::<Vec<_>>();\n\n        let mut missing_modules = Vec::new();\n        let mut ambiguous_modules = Vec::new();\n        let mut outside_root = Vec::new();\n        let mut mod_decl_count = 0usize;\n\n        for file in &rust_files {\n            let Ok(content) = fs::read_to_string(file) else {\n                continue;\n            };\n            let parent_dir = file.parent().unwrap_or(&src_root);\n            let mut pending_path: Option<String> = None;\n\n            for (idx, line) in content.lines().enumerate() {\n                let trimmed = line.trim();\n                if let Some(path_attr) = extract_path_attr(trimmed) {\n                    pending_path = Some(path_attr);\n                    continue;\n                }\n\n                if trimmed.starts_with(\"#[\") || trimmed.is_empty() || trimmed.starts_with(\"//\") {\n                    continue;\n                }\n\n                if let Some(module) = parse_mod_decl(trimmed) {\n                    mod_decl_count += 1;\n                    let line_no = idx + 1;\n                    let path_attr = pending_path.take();\n\n                    if let Some(attr) = path_attr {\n                        let resolved = resolve_path_attr(parent_dir, &attr);\n                        if !resolved.starts_with(&src_root) {\n                            outside_root.push(ModuleIssue {\n                                parent_file: file.clone(),\n                                module: module.clone(),\n                                line: line_no,\n                                details: vec![resolved],\n                                note: format!(\"path attribute `{}` resolves outside src root\", attr),\n                                kind: ModuleIssueKind::PathOutsideRoot,\n                            });\n                            continue;\n                        }\n                        if !resolved.is_file() {\n                            missing_modules.push(ModuleIssue {\n                                parent_file: file.clone(),\n                                module,\n                                line: line_no,\n                                details: vec![resolved],\n                                note: format!(\"path attribute `{}` missing\", attr),\n                                kind: ModuleIssueKind::MissingPathAttr,\n                            });\n                        }\n                        continue;\n                    }\n\n                    let direct = parent_dir.join(format!(\"{}.rs\", module));\n                    let nested = parent_dir.join(&module).join(\"mod.rs\");\n                    let direct_exists = direct.is_file();\n                    let nested_exists = nested.is_file();\n\n                    if direct_exists && nested_exists {\n                        ambiguous_modules.push(ModuleIssue {\n                            parent_file: file.clone(),\n                            module,\n                            line: line_no,\n                            details: vec![direct, nested],\n                            note: \"both module paths exist\".to_string(),\n                            kind: ModuleIssueKind::AmbiguousModulePaths,\n                        });\n                    } else if !direct_exists && !nested_exists {\n                        missing_modules.push(ModuleIssue {\n                            parent_file: file.clone(),\n                            module,\n                            line: line_no,\n                            details: vec![direct, nested],\n                            note: \"no module file found\".to_string(),\n                            kind: ModuleIssueKind::MissingModuleFile,\n                        });\n                    }\n                } else {\n                    pending_path = None;\n                }\n            }\n        }\n\n        missing_modules.sort_by(|a, b| (a.parent_file.cmp(&b.parent_file)).then(a.module.cmp(&b.module)));\n        ambiguous_modules.sort_by(|a, b| (a.parent_file.cmp(&b.parent_file)).then(a.module.cmp(&b.module)));\n        outside_root.sort_by(|a, b| (a.parent_file.cmp(&b.parent_file)).then(a.module.cmp(&b.module)));\n\n        let mut index = String::from(\"# Module Map Mismatch\\n\\n\");\n        index.push_str(\"Action: Review only. Detection-only report.\\n\\n\");\n        index.push_str(&format!(\n            \"- Rust files scanned: {}\\n\",\n            rust_files.len()\n        ));\n        index.push_str(&format!(\n            \"- mod declarations scanned: {}\\n\",\n            mod_decl_count\n        ));\n        index.push_str(&format!(\n            \"- Missing module files: {}\\n\",\n            missing_modules.len()\n        ));\n        index.push_str(&format!(\n            \"- Ambiguous module paths: {}\\n\",\n            ambiguous_modules.len()\n        ));\n        index.push_str(&format!(\n            \"- #[path] outside src root: {}\\n\\n\",\n            outside_root.len()\n        ));\n\n        if missing_modules.is_empty() && ambiguous_modules.is_empty() && outside_root.is_empty() {\n            index.push_str(\"No module map mismatches detected.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        }\n\n        if !missing_modules.is_empty() {\n            index.push_str(\"## Missing Module Files\\n\\n\");\n            for issue in &missing_modules {\n                let parent = compress_path(issue.parent_file.to_string_lossy().as_ref());\n                index.push_str(&format!(\n                    \"- `{}`:{} `mod {}`  {} ({})\\n\",\n                    parent,\n                    issue.line,\n                    issue.module,\n                    format_paths(&issue.details),\n                    issue.note\n                ));\n                index.push_str(&format!(\"  Plan: {}\\n\", issue_plan_summary(issue)));\n            }\n            index.push('\\n');\n        }\n\n        if !ambiguous_modules.is_empty() {\n            index.push_str(\"## Ambiguous Module Paths\\n\\n\");\n            for issue in &ambiguous_modules {\n                let parent = compress_path(issue.parent_file.to_string_lossy().as_ref());\n                index.push_str(&format!(\n                    \"- `{}`:{} `mod {}`  {} ({})\\n\",\n                    parent,\n                    issue.line,\n                    issue.module,\n                    format_paths(&issue.details),\n                    issue.note\n                ));\n                index.push_str(&format!(\"  Plan: {}\\n\", issue_plan_summary(issue)));\n            }\n            index.push('\\n');\n        }\n\n        if !outside_root.is_empty() {\n            index.push_str(\"## #[path] Outside Source Root\\n\\n\");\n            for issue in &outside_root {\n                let parent = compress_path(issue.parent_file.to_string_lossy().as_ref());\n                index.push_str(&format!(\n                    \"- `{}`:{} `mod {}`  {} ({})\\n\",\n                    parent,\n                    issue.line,\n                    issue.module,\n                    format_paths(&issue.details),\n                    issue.note\n                ));\n                index.push_str(&format!(\"  Plan: {}\\n\", issue_plan_summary(issue)));\n            }\n            index.push('\\n');\n        }\n\n        fs::write(index_path, index)?;\n        Ok(())\n    }\n\n    fn generate_test_topology(&self, root_path: &Path) -> Result<()> {\n        let dir = self.prepare_report_dir(\"42_test_topology\")?;\n        let index_path = dir.join(\"index.md\");\n        let src_root = crate::layer_utilities::resolve_source_root(root_path);\n\n        let rust_files = crate::cluster_010::gather_rust_files(root_path)\n            .into_iter()\n            .filter(|path| path.starts_with(&src_root))\n            .collect::<Vec<_>>();\n        let test_files = gather_test_files(root_path);\n\n        let mut issues = Vec::new();\n\n        for file in &rust_files {\n            let Ok(content) = fs::read_to_string(file) else {\n                continue;\n            };\n            let mut pending_attrs: Vec<String> = Vec::new();\n            let mut file_has_submodules = false;\n            let mut file_has_cfg_tests = false;\n\n            for (idx, line) in content.lines().enumerate() {\n                let trimmed = line.trim();\n                if trimmed.is_empty() || trimmed.starts_with(\"//\") {\n                    continue;\n                }\n                if trimmed.starts_with(\"#[\") {\n                    pending_attrs.push(trimmed.to_string());\n                    continue;\n                }\n\n                if let Some(mod_name) = parse_mod_decl(trimmed) {\n                    if mod_name != \"tests\" {\n                        file_has_submodules = true;\n                    }\n                }\n\n                if is_mod_tests_decl(trimmed) {\n                    let line_no = idx + 1;\n                    if !has_cfg_test_attr(&pending_attrs) {\n                        issues.push(TestTopologyIssue {\n                            file: file.clone(),\n                            line: line_no,\n                            kind: TestIssueKind::TestsWithoutCfg,\n                            note: \"mod tests without #[cfg(test)]\".to_string(),\n                        });\n                    } else {\n                        file_has_cfg_tests = true;\n                    }\n                }\n\n                pending_attrs.clear();\n            }\n\n            if file_has_cfg_tests && file_has_submodules {\n                issues.push(TestTopologyIssue {\n                    file: file.clone(),\n                    line: 0,\n                    kind: TestIssueKind::CfgTestsInNonLeaf,\n                    note: \"cfg(test) block in module with submodules\".to_string(),\n                });\n            }\n        }\n\n        for file in &test_files {\n            let Ok(content) = fs::read_to_string(file) else {\n                continue;\n            };\n            for (idx, line) in content.lines().enumerate() {\n                let trimmed = line.trim();\n                if trimmed.starts_with(\"use crate::\") {\n                    issues.push(TestTopologyIssue {\n                        file: file.clone(),\n                        line: idx + 1,\n                        kind: TestIssueKind::IntegrationUsesCratePath,\n                        note: \"integration test uses crate:: path (check crate name)\".to_string(),\n                    });\n                }\n                if trimmed.starts_with(\"use super::\") {\n                    issues.push(TestTopologyIssue {\n                        file: file.clone(),\n                        line: idx + 1,\n                        kind: TestIssueKind::IntegrationUsesSuper,\n                        note: \"integration test uses super:: (invalid module path)\".to_string(),\n                    });\n                }\n            }\n        }\n\n        issues.sort_by(|a, b| {\n            a.file\n                .cmp(&b.file)\n                .then(a.line.cmp(&b.line))\n                .then(a.kind.cmp(&b.kind))\n        });\n\n        let mut index = String::from(\"# Test Topology\\n\\n\");\n        index.push_str(\"Action: Review only. Detection-only report.\\n\\n\");\n        index.push_str(&format!(\n            \"- Rust source files scanned: {}\\n\",\n            rust_files.len()\n        ));\n        index.push_str(&format!(\n            \"- Integration test files scanned: {}\\n\",\n            test_files.len()\n        ));\n        index.push_str(&format!(\"- Issues detected: {}\\n\\n\", issues.len()));\n\n        if issues.is_empty() {\n            index.push_str(\"No test topology issues detected.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        }\n\n        let mut grouped: BTreeMap<TestIssueKind, Vec<&TestTopologyIssue>> = BTreeMap::new();\n        for issue in &issues {\n            grouped.entry(issue.kind).or_default().push(issue);\n        }\n\n        for (kind, entries) in grouped {\n            index.push_str(&format!(\"## {}\\n\\n\", kind.label()));\n            for issue in entries {\n                let file = compress_path(issue.file.to_string_lossy().as_ref());\n                if issue.line == 0 {\n                    index.push_str(&format!(\n                        \"- `{}`  {} (review_only)\\n\",\n                        file, issue.note\n                    ));\n                } else {\n                    index.push_str(&format!(\n                        \"- `{}`:{}  {} (review_only)\\n\",\n                        file, issue.line, issue.note\n                    ));\n                }\n            }\n            index.push('\\n');\n        }\n\n        fs::write(index_path, index)?;\n        Ok(())\n    }\n\n    fn generate_warning_hygiene(&self, root_path: &Path) -> Result<()> {\n        let dir = self.prepare_report_dir(\"43_warning_hygiene\")?;\n        let index_path = dir.join(\"index.md\");\n        let output_dir = Path::new(&self.output_dir);\n        let candidates = [\n            output_dir.join(\"cargo_warnings.txt\"),\n            root_path.join(\"cargo_warnings.txt\"),\n        ];\n        let warnings_path = candidates.iter().find(|p| p.exists());\n\n        let mut index = String::from(\"# Warning Hygiene\\n\\n\");\n        index.push_str(\"Action: Review only. Detection-only report.\\n\\n\");\n\n        let Some(path) = warnings_path else {\n            index.push_str(\"No cargo_warnings.txt found.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        };\n\n        let content = fs::read_to_string(path).unwrap_or_default();\n        let warnings = parse_cargo_warnings(&content);\n\n        index.push_str(&format!(\"- Source: `{}`\\n\", compress_path(path.to_string_lossy().as_ref())));\n        index.push_str(&format!(\"- Warnings parsed: {}\\n\\n\", warnings.len()));\n\n        if warnings.is_empty() {\n            index.push_str(\"No warnings detected.\\n\");\n            fs::write(index_path, index)?;\n            return Ok(());\n        }\n\n        let mut by_message: BTreeMap<String, usize> = BTreeMap::new();\n        for warning in &warnings {\n            *by_message.entry(warning.message.clone()).or_insert(0) += 1;\n        }\n\n        index.push_str(\"## Warning Types\\n\\n\");\n        for (message, count) in &by_message {\n            index.push_str(&format!(\"- {} ({} occurrences)\\n\", message, count));\n        }\n        index.push('\\n');\n\n        index.push_str(\"## Warning Details\\n\\n\");\n        for warning in &warnings {\n            let location = if let Some(loc) = warning.location.as_ref() {\n                format!(\"{}:{}\", compress_path(loc.file.to_string_lossy().as_ref()), loc.line)\n            } else {\n                \"unknown\".to_string()\n            };\n            index.push_str(&format!(\n                \"- `{}`  {}\\n\",\n                location, warning.message\n            ));\n        }\n        index.push('\\n');\n\n        fs::write(index_path, index)?;\n        Ok(())\n    }\n\n    fn generate_function_analysis(&self, result: &AnalysisResult) -> Result<()> {\n        let dir = self.prepare_report_dir(\"50_function_analysis\")?;\n        let mut index = String::from(\"# Function Analysis\\n\\n\");\n\n        let functions: Vec<_> = result\n            .elements\n            .iter()\n            .filter(|e| matches!(e.element_type, ElementType::Function))\n            .collect();\n\n        index.push_str(&format!(\"## Total Functions: {}\\n\\n\", functions.len()));\n        index.push_str(\n            \"Functions are bucketed alphabetically so `ls 50_function_analysis/` advertises the range.\\n\\n\",\n        );\n\n        if functions.is_empty() {\n            fs::write(dir.join(\"index.md\"), index)?;\n            return Ok(());\n        }\n\n        let bucket_labels = [\"A-F\", \"G-M\", \"N-S\", \"T-Z\", \"Other\"];\n        let mut buckets: HashMap<&'static str, Vec<&CodeElement>> = HashMap::new();\n        for label in bucket_labels {\n            buckets.insert(label, Vec::new());\n        }\n\n        for func in &functions {\n            let label = function_bucket_label(&func.name);\n            buckets.entry(label).or_insert_with(Vec::new).push(func);\n        }\n\n        index.push_str(\"## Bucket Files\\n\\n\");\n        for (idx, label) in bucket_labels.iter().enumerate() {\n            let file_name = format!(\"{:03}-functions_{}.md\", (idx + 1) * 10, label);\n            let count = buckets.get(label).map(|v| v.len()).unwrap_or(0);\n            index.push_str(&format!(\n                \"- `{}`  `{}` ({} functions)\\n\",\n                label, file_name, count\n            ));\n        }\n        fs::write(dir.join(\"index.md\"), index)?;\n\n        for (idx, label) in bucket_labels.iter().enumerate() {\n            let mut funcs = buckets.remove(label).unwrap_or_default();\n            funcs.sort_by_key(|f| (&f.layer, &f.name));\n            let file_name = format!(\"{:03}-functions_{}.md\", (idx + 1) * 10, label);\n            let mut content = format!(\"# Functions {}\\n\\n\", label);\n\n            if funcs.is_empty() {\n                content.push_str(\"No functions fell into this range.\\n\");\n                fs::write(dir.join(file_name), content)?;\n                continue;\n            }\n\n            let mut layer_map: BTreeMap<String, Vec<&CodeElement>> = BTreeMap::new();\n            for func in funcs {\n                layer_map\n                    .entry(func.layer.clone())\n                    .or_insert_with(Vec::new)\n                    .push(func);\n            }\n\n            for (layer, entries) in layer_map {\n                content.push_str(&format!(\"## Layer: {}\\n\\n\", layer));\n\n                let mut rust_funcs: Vec<_> = entries\n                    .iter()\n                    .filter(|f| matches!(f.language, Language::Rust))\n                    .collect();\n                let mut julia_funcs: Vec<_> = entries\n                    .iter()\n                    .filter(|f| matches!(f.language, Language::Julia))\n                    .collect();\n\n                rust_funcs.sort_by_key(|f| &f.name);\n                julia_funcs.sort_by_key(|f| &f.name);\n\n                if !rust_funcs.is_empty() {\n                    content.push_str(\"### Rust Functions\\n\\n\");\n                    for func in rust_funcs {\n                        content.push_str(&format!(\"#### `{}`\\n\\n\", func.name));\n                        let compressed = compress_path(&func.file_path);\n                        content.push_str(&format!(\n                            \"- **File:** {}:{}\\n\",\n                            compressed, func.line_number\n                        ));\n                        content.push_str(&format!(\"- **Visibility:** {:?}\\n\", func.visibility));\n\n                        if !func.generic_params.is_empty() {\n                            content.push_str(&format!(\n                                \"- **Generics:** {}\\n\",\n                                func.generic_params.join(\", \")\n                            ));\n                        }\n\n                        if !func.calls.is_empty() {\n                            content.push_str(\"- **Calls:**\\n\");\n                            for call in &func.calls {\n                                content.push_str(&format!(\"  - `{}`\\n\", call));\n                            }\n                        }\n                        content.push_str(\"\\n\");\n                    }\n                }\n\n                if !julia_funcs.is_empty() {\n                    content.push_str(\"### Julia Functions\\n\\n\");\n                    for func in julia_funcs {\n                        content.push_str(&format!(\"#### `{}`\\n\\n\", func.name));\n                        let compressed = compress_path(&func.file_path);\n                        content.push_str(&format!(\n                            \"- **File:** {}:{}\\n\",\n                            compressed, func.line_number\n                        ));\n                        content.push_str(&format!(\"- **Signature:** `{}`\\n\", func.signature));\n\n                        if !func.calls.is_empty() {\n                            content.push_str(\"- **Calls:**\\n\");\n                            for call in &func.calls {\n                                content.push_str(&format!(\"  - `{}`\\n\", call));\n                            }\n                        }\n                        content.push_str(\"\\n\");\n                    }\n                }\n            }\n\n            fs::write(dir.join(file_name), content)?;\n        }\n\n        Ok(())\n    }\n\n    fn extract_layer_from_path(&self, path: &str) -> String {\n        for component in path.split('/') {\n            if component\n                .chars()\n                .next()\n                .map_or(false, |c| c.is_ascii_digit())\n            {\n                if let Some(pos) = component.find('_') {\n                    if component[..pos].chars().all(|c| c.is_ascii_digit()) {\n                        return component.to_string();\n                    }\n                }\n            }\n        }\n        \"root\".to_string()\n    }\n\n    fn dot_path_for(&self, compressed_path: &str) -> Option<String> {\n        let slug = slugify_file_path(compressed_path);\n        let rel = format!(\"30_cfg/dots/{}/call_graph.dot\", slug);\n        let absolute = Path::new(&self.output_dir).join(&rel);\n        if absolute.exists() {\n            Some(rel)\n        } else {\n            None\n        }\n    }\n}\n\nfn prefix_key_from_path(path: &str) -> String {\n    let relative = path.strip_prefix(\"MMSB/\").unwrap_or(path);\n    if relative.is_empty() {\n        return \"root\".to_string();\n    }\n    let parts: Vec<&str> = relative.split('/').collect();\n    if parts.len() == 1 {\n        return \"root\".to_string();\n    }\n    if parts[0] == \"src\" && parts.len() >= 2 {\n        return format!(\"{}/{}\", parts[0], parts[1]);\n    }\n    parts[0].to_string()\n}\n\nfn slugify_key(input: &str) -> String {\n    input\n        .chars()\n        .map(|c| match c {\n            '/' => '-',\n            ' ' => '_',\n            _ if c.is_ascii_alphanumeric() || c == '-' => c.to_ascii_lowercase(),\n            _ => '_',\n        })\n        .collect()\n}\n\nfn group_key_cmp(a: &str, b: &str) -> Ordering {\n    match (a == \"root\", b == \"root\") {\n        (true, true) => Ordering::Equal,\n        (true, false) => Ordering::Less,\n        (false, true) => Ordering::Greater,\n        _ => a.cmp(b),\n    }\n}\n\nfn function_bucket_label(name: &str) -> &'static str {\n    let first = name\n        .chars()\n        .find(|c| c.is_ascii_alphabetic())\n        .map(|c| c.to_ascii_uppercase())\n        .unwrap_or('#');\n\n    match first {\n        'A'..='F' => \"A-F\",\n        'G'..='M' => \"G-M\",\n        'N'..='S' => \"N-S\",\n        'T'..='Z' => \"T-Z\",\n        _ => \"Other\",\n    }\n}\n\nfn slugify_file_path(path: &str) -> String {\n    path.trim_start_matches(\"MMSB/\")\n        .replace('/', \"-\")\n        .replace('.', \"_\")\n        .to_lowercase()\n}\n\nfn language_label(language: &Language) -> &'static str {\n    match language {\n        Language::Rust => \"Rust\",\n        Language::Julia => \"Julia\",\n    }\n}\n\nfn visibility_label(vis: &Visibility) -> &'static str {\n    match vis {\n        Visibility::Public => \"pub\",\n        Visibility::Crate => \"pub(crate)\",\n        Visibility::Private => \"priv\",\n    }\n}\n\nfn short_signature(input: &str) -> String {\n    let collapsed = input.split_whitespace().collect::<Vec<_>>().join(\" \");\n    if collapsed.len() > 120 {\n        let mut truncated = collapsed.chars().take(117).collect::<String>();\n        truncated.push_str(\"...\");\n        truncated\n    } else {\n        collapsed\n    }\n}\n\nstruct ModuleAggregate {\n    name: String,\n    layer: String,\n    imports: BTreeSet<String>,\n    exports: BTreeSet<String>,\n    submodules: BTreeSet<String>,\n}\n\nimpl ModuleAggregate {\n    fn new(name: String, layer: String) -> Self {\n        Self {\n            name: if name.is_empty() {\n                \"unknown\".to_string()\n            } else {\n                name\n            },\n            layer,\n            imports: BTreeSet::new(),\n            exports: BTreeSet::new(),\n            submodules: BTreeSet::new(),\n        }\n    }\n}\n\n#[derive(Clone)]\nstruct ModuleIssue {\n    parent_file: PathBuf,\n    module: String,\n    line: usize,\n    details: Vec<PathBuf>,\n    note: String,\n    kind: ModuleIssueKind,\n}\n\n#[derive(Clone, Copy)]\nenum ModuleIssueKind {\n    MissingModuleFile,\n    MissingPathAttr,\n    AmbiguousModulePaths,\n    PathOutsideRoot,\n}\n\nfn extract_path_attr(line: &str) -> Option<String> {\n    if !line.trim_start().starts_with(\"#[path\") {\n        return None;\n    }\n    let start = line.find('\"')?;\n    let rest = &line[start + 1..];\n    let end = rest.find('\"')?;\n    Some(rest[..end].to_string())\n}\n\nfn parse_mod_decl(line: &str) -> Option<String> {\n    let mut rest = line.trim_start();\n    if rest.starts_with(\"pub \") {\n        rest = rest.trim_start_matches(\"pub \").trim_start();\n    } else if rest.starts_with(\"pub(\") {\n        let end = rest.find(')')?;\n        rest = rest[end + 1..].trim_start();\n    }\n    if !rest.starts_with(\"mod \") {\n        return None;\n    }\n    rest = rest.trim_start_matches(\"mod \").trim_start();\n    let name: String = rest\n        .chars()\n        .take_while(|c| c.is_alphanumeric() || *c == '_')\n        .collect();\n    if name.is_empty() {\n        return None;\n    }\n    let semicolon = rest.find(';');\n    let brace = rest.find('{');\n    if brace.is_some() && (semicolon.is_none() || brace.unwrap() < semicolon.unwrap()) {\n        return None;\n    }\n    if semicolon.is_none() {\n        return None;\n    }\n    Some(name)\n}\n\nfn resolve_path_attr(parent_dir: &Path, attr: &str) -> PathBuf {\n    let candidate = PathBuf::from(attr);\n    if candidate.is_absolute() {\n        candidate\n    } else {\n        parent_dir.join(candidate)\n    }\n}\n\nfn format_paths(paths: &[PathBuf]) -> String {\n    let mut items = paths\n        .iter()\n        .map(|p| compress_path(p.to_string_lossy().as_ref()))\n        .collect::<Vec<_>>();\n    items.sort();\n    items.join(\", \")\n}\n\nfn issue_plan_summary(issue: &ModuleIssue) -> String {\n    match issue.kind {\n        ModuleIssueKind::MissingModuleFile => {\n            \"review_only. options: keep_as_is | add_mod_declaration | add_module_file\".to_string()\n        }\n        ModuleIssueKind::MissingPathAttr => {\n            \"review_only. options: keep_as_is | update_path_attr | remove_mod_decl\".to_string()\n        }\n        ModuleIssueKind::AmbiguousModulePaths => {\n            \"review_only. options: keep_as_is | choose_flat_file | choose_nested_mod\".to_string()\n        }\n        ModuleIssueKind::PathOutsideRoot => {\n            \"review_only. options: keep_as_is | relocate_module | update_path_attr\".to_string()\n        }\n    }\n}\n\n#[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\nenum TestIssueKind {\n    TestsWithoutCfg,\n    CfgTestsInNonLeaf,\n    IntegrationUsesCratePath,\n    IntegrationUsesSuper,\n}\n\nimpl TestIssueKind {\n    fn label(self) -> &'static str {\n        match self {\n            TestIssueKind::TestsWithoutCfg => \"Inline tests missing #[cfg(test)]\",\n            TestIssueKind::CfgTestsInNonLeaf => \"cfg(test) in non-leaf module\",\n            TestIssueKind::IntegrationUsesCratePath => \"Integration tests using crate::\",\n            TestIssueKind::IntegrationUsesSuper => \"Integration tests using super::\",\n        }\n    }\n}\n\nstruct TestTopologyIssue {\n    file: PathBuf,\n    line: usize,\n    kind: TestIssueKind,\n    note: String,\n}\n\nfn has_cfg_test_attr(attrs: &[String]) -> bool {\n    attrs.iter().any(|attr| attr.contains(\"cfg(test)\"))\n}\n\nfn is_mod_tests_decl(line: &str) -> bool {\n    let trimmed = line.trim_start();\n    if trimmed.starts_with(\"mod tests\") {\n        return trimmed.contains(';') || trimmed.contains('{');\n    }\n    if trimmed.starts_with(\"pub mod tests\") {\n        return trimmed.contains(';') || trimmed.contains('{');\n    }\n    false\n}\n\nfn gather_test_files(root_path: &Path) -> Vec<PathBuf> {\n    let tests_dir = root_path.join(\"tests\");\n    if !tests_dir.is_dir() {\n        return Vec::new();\n    }\n    WalkDir::new(&tests_dir)\n        .into_iter()\n        .filter_map(|entry| entry.ok())\n        .filter(|entry| entry.path().extension().map_or(false, |ext| ext == \"rs\"))\n        .map(|entry| entry.into_path())\n        .collect()\n}\n\nstruct WarningLocation {\n    file: PathBuf,\n    line: usize,\n}\n\nstruct WarningEntry {\n    message: String,\n    location: Option<WarningLocation>,\n}\n\nfn parse_cargo_warnings(content: &str) -> Vec<WarningEntry> {\n    let mut warnings = Vec::new();\n    let mut pending_message: Option<String> = None;\n\n    for line in content.lines() {\n        let trimmed = line.trim_start();\n        if let Some(msg) = trimmed.strip_prefix(\"warning:\") {\n            let message = msg.trim().to_string();\n            pending_message = Some(message);\n            continue;\n        }\n\n        if let Some(rest) = trimmed.strip_prefix(\"-->\") {\n            if let Some(message) = pending_message.take() {\n                if let Some(location) = parse_location(rest.trim()) {\n                    warnings.push(WarningEntry {\n                        message,\n                        location: Some(location),\n                    });\n                } else {\n                    warnings.push(WarningEntry {\n                        message,\n                        location: None,\n                    });\n                }\n            }\n            continue;\n        }\n\n        if trimmed.is_empty() && pending_message.is_some() {\n            let message = pending_message.take().unwrap_or_default();\n            warnings.push(WarningEntry {\n                message,\n                location: None,\n            });\n        }\n    }\n\n    if let Some(message) = pending_message.take() {\n        warnings.push(WarningEntry {\n            message,\n            location: None,\n        });\n    }\n\n    warnings\n}\n\nfn parse_location(raw: &str) -> Option<WarningLocation> {\n    let parts: Vec<&str> = raw.split(':').collect();\n    if parts.len() < 3 {\n        return None;\n    }\n    let file = parts[0].trim();\n    let line = parts[1].trim().parse::<usize>().ok()?;\n    Some(WarningLocation {\n        file: PathBuf::from(file),\n        line,\n    })\n}\n\nfn normalize_use_stmt(stmt: &str) -> String {\n    let collapsed = stmt.replace('\\n', \" \");\n    let mut cleaned = collapsed.split_whitespace().collect::<Vec<_>>().join(\" \");\n    if let Some(idx) = cleaned.find(';') {\n        cleaned.truncate(idx);\n    }\n    cleaned = cleaned.trim().to_string();\n    if cleaned.starts_with(\"pub\") {\n        if let Some(pos) = cleaned.find(' ') {\n            cleaned = cleaned[pos + 1..].trim().to_string();\n        }\n    }\n    if let Some(stripped) = cleaned.strip_prefix(\"use \") {\n        cleaned = stripped.trim().to_string();\n    }\n    cleaned\n}\n\nfn sanitize_mermaid_id(input: &str) -> String {\n    input\n        .chars()\n        .map(|c| if c.is_ascii_alphanumeric() { c } else { '_' })\n        .collect()\n}\n\nfn sanitize_mermaid_label(label: &str) -> String {\n    label.replace('\"', \"'\").replace('`', \"'\")\n}\n\npub fn compress_path(path: &str) -> String {\n    // Find MMSB in the path and return everything from there\n    if let Some(idx) = path.find(\"/MMSB/\") {\n        return format!(\"MMSB{}\", &path[idx + 5..]);\n    }\n    // If already starts with MMSB/, return as-is\n    if path.starts_with(\"MMSB/\") {\n        return path.to_string();\n    }\n    // Fallback: try to find src/ or other common markers\n    if let Some(idx) = path.rfind(\"/src/\") {\n        return format!(\"MMSB/src{}\", &path[idx + 4..]);\n    }\n    // Last resort: return original\n    path.to_string()\n}\n\npub fn collect_directory_files(directory: &DirectoryAnalysis, out: &mut Vec<PathBuf>) {\n    out.extend(directory.files.iter().cloned());\n    for sub in &directory.subdirectories {\n        collect_directory_files(sub, out);\n    }\n}\n\npub fn path_common_prefix_len(a: &Path, b: &Path) -> isize {\n    let mut count = 0isize;\n    for (a_comp, b_comp) in a.components().zip(b.components()) {\n        if a_comp == b_comp {\n            count += 1;\n        } else {\n            break;\n        }\n    }\n    count\n}\n\npub fn compute_move_metrics(\n    placement: &FunctionPlacement,\n) -> (usize, usize, usize, usize, Vec<PathBuf>, Vec<PathBuf>) {\n    let incoming_calls = placement\n        .call_analysis\n        .calls_from_other_files\n        .iter()\n        .map(|(_, count)| *count)\n        .sum::<usize>();\n    let callers = placement.call_analysis.calls_from_other_files.len();\n    let mut touched = BTreeSet::new();\n    touched.insert(placement.current_file.clone());\n    let mut outgoing_files = Vec::new();\n    for (path, _) in &placement.call_analysis.inter_file_calls {\n        touched.insert(path.clone());\n        outgoing_files.push(path.clone());\n    }\n    let mut caller_files = Vec::new();\n    for (path, _) in &placement.call_analysis.calls_from_other_files {\n        touched.insert(path.clone());\n        caller_files.push(path.clone());\n    }\n    let cost = touched.len().max(1);\n    let benefit = 1 + callers;\n    (incoming_calls, benefit, cost, callers, caller_files, outgoing_files)\n}\n\npub fn generate_canonical_name(path: &Path, number: usize) -> String {\n    let stem = path\n        .file_stem()\n        .and_then(|s| s.to_str())\n        .unwrap_or(\"unknown\");\n    let ext = path\n        .extension()\n        .and_then(|s| s.to_str())\n        .unwrap_or(\"\");\n    let clean_stem = strip_numeric_prefix(stem);\n    if ext.is_empty() {\n        format!(\"{:03}_{}\", number, clean_stem)\n    } else {\n        format!(\"{:03}_{}.{}\", number, clean_stem, ext)\n    }\n}\n\npub fn collect_directory_moves(\n    ordering: &crate::types::FileOrderingResult,\n    root_path: &Path,\n) -> Vec<crate::file_ordering::DirectoryMove> {\n    let mut moves = Vec::new();\n    let mut by_parent: BTreeMap<PathBuf, Vec<PathBuf>> = BTreeMap::new();\n    let src_dir = root_path.join(\"src\");\n\n    for dir in &ordering.ordered_directories {\n        if dir == root_path {\n            continue;\n        }\n        if dir == &src_dir {\n            continue;\n        }\n        if let Some(parent) = dir.parent() {\n            by_parent\n                .entry(parent.to_path_buf())\n                .or_default()\n                .push(dir.clone());\n        }\n    }\n\n    for (parent, mut dirs) in by_parent {\n        dirs.sort_by(|a, b| crate::cluster_008::compare_dir_layers(a, b));\n        for (idx, dir) in dirs.iter().enumerate() {\n            let Some(name) = dir.file_name().and_then(|n| n.to_str()) else {\n                continue;\n            };\n            let clean = strip_numeric_prefix(name);\n            let suggested = format!(\"{:03}_{}\", idx * 10, clean);\n            if name == suggested {\n                continue;\n            }\n            let to = parent.join(&suggested);\n            moves.push(crate::file_ordering::DirectoryMove {\n                from: dir.clone(),\n                to,\n            });\n        }\n    }\n\n    moves\n}\n\npub fn write_structural_batches(content: &mut String, items: &[PlanItem]) {\n    if items.is_empty() {\n        return;\n    }\n\n    let mut ordered_targets = Vec::new();\n    let mut batches: HashMap<PathBuf, Vec<&PlanItem>> = HashMap::new();\n    for item in items {\n        let Some(target) = &item.target_file else {\n            continue;\n        };\n        let entry = batches.entry(target.clone()).or_default();\n        if entry.is_empty() {\n            ordered_targets.push(target.clone());\n        }\n        entry.push(item);\n    }\n\n    content.push_str(\"### Phase 3 Batches\\n\\n\");\n    content.push_str(\"Action: execute batches in order and verify after each batch.\\n\");\n    content.push_str(\"Note: each batch targets one destination module.\\n\\n\");\n    for (idx, target) in ordered_targets.iter().enumerate() {\n        let empty: Vec<&PlanItem> = Vec::new();\n        let items = batches.get(target).unwrap_or(&empty);\n        content.push_str(&format!(\n            \"#### Batch {}: target `{}`\\n\\n\",\n            idx + 1,\n            compress_path(target.to_string_lossy().as_ref())\n        ));\n        content.push_str(\"Action: move the listed functions into the target module.\\n\");\n        content.push_str(\"Note: use the rg commands to locate definitions and callers.\\n\\n\");\n        let mut commands: Vec<String> = Vec::new();\n        if !target.exists() {\n            let target_label = compress_path(target.to_string_lossy().as_ref());\n            content.push_str(&format!(\n                \"- Create target file: `{}`\\n\",\n                target_label\n            ));\n            commands.push(format!(\"touch \\\"{}\\\"\", target.to_string_lossy()));\n        }\n        for item in items {\n            let name = item.name.as_deref().unwrap_or(\"function\");\n            let current = item\n                .current_file\n                .as_ref()\n                .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                .unwrap_or_else(|| \"-\".to_string());\n            let ratio = if item.cost == 0 {\n                0.0\n            } else {\n                item.benefit as f64 / item.cost as f64\n            };\n            let caller_hint = if item.callers == 0 {\n                \"no external callers\".to_string()\n            } else {\n                format!(\"update {} caller files\", item.callers)\n            };\n            content.push_str(&format!(\n                \"- Move `{}` from `{}` (impact {}, benefit/cost {:.2}, touches {} files; {})\\n\",\n                name,\n                current,\n                item.impact_weight,\n                ratio,\n                item.cost,\n                caller_hint\n            ));\n            if let Some(current_file) = &item.current_file {\n                commands.push(format!(\n                    \"rg -n \\\"{}\\\" \\\"{}\\\"\",\n                    name,\n                    current_file.to_string_lossy()\n                ));\n            }\n            let mut callers = item.caller_files.clone();\n            callers.sort();\n            callers.dedup();\n            if !callers.is_empty() {\n                content.push_str(\"- Update imports in:\\n\");\n                for caller in callers {\n                    content.push_str(&format!(\n                        \"  - `{}`\\n\",\n                        compress_path(caller.to_string_lossy().as_ref())\n                    ));\n                    commands.push(format!(\n                        \"rg -n \\\"{}\\\" \\\"{}\\\"\",\n                        name,\n                        caller.to_string_lossy()\n                    ));\n                }\n            }\n        }\n        content.push_str(\"- Verification gate: `cargo test`\\n\");\n        if !commands.is_empty() {\n            content.push_str(\"\\n```bash\\n\");\n            for command in commands {\n                content.push_str(&format!(\"{}\\n\", command));\n            }\n            content.push_str(\"```\\n\");\n        }\n        content.push('\\n');\n    }\n}\n\npub fn write_cluster_batches(content: &mut String, plans: &[ClusterPlan], root_path: &Path) {\n    if plans.is_empty() {\n        return;\n    }\n    content.push_str(\"### Phase 2 Batches\\n\\n\");\n    content.push_str(\"Action: execute batches in order and verify after each batch.\\n\");\n    content.push_str(\"Note: each batch creates or fills a cluster file.\\n\\n\");\n    for (idx, plan) in plans.iter().enumerate() {\n        content.push_str(&format!(\n            \"#### Batch {}: target `{}`\\n\\n\",\n            idx + 1,\n            compress_path(plan.target.to_string_lossy().as_ref())\n        ));\n        content.push_str(\"Action: move the listed functions into the target module.\\n\");\n        content.push_str(\"Note: use the rg commands to locate definitions and callers.\\n\\n\");\n        let mut commands = Vec::new();\n        if !plan.target.exists() {\n            content.push_str(&format!(\n                \"- Create target file: `{}`\\n\",\n                compress_path(plan.target.to_string_lossy().as_ref())\n            ));\n            commands.push(format!(\"touch \\\"{}\\\"\", plan.target.to_string_lossy()));\n        }\n        content.push_str(&format!(\n            \"- Cluster cohesion {:.2}, {} functions\\n\",\n            plan.cohesion,\n            plan.members.len()\n        ));\n        for member in &plan.members {\n            let file = compress_path(member.file.to_string_lossy().as_ref());\n            content.push_str(&format!(\"- Move `{}` from `{}`\\n\", member.name, file));\n            commands.push(format!(\n                \"rg -n \\\"{}\\\" \\\"{}\\\"\",\n                member.name,\n                member.file.to_string_lossy()\n            ));\n            commands.push(format!(\n                \"rg -n \\\"{}\\\" \\\"{}\\\"\",\n                member.name,\n                root_path.to_string_lossy()\n            ));\n        }\n        content.push_str(\"- Verification gate: `cargo test`\\n\");\n        if !commands.is_empty() {\n            content.push_str(\"\\n```bash\\n\");\n            for command in commands {\n                content.push_str(&format!(\"{}\\n\", command));\n            }\n            content.push_str(\"```\\n\");\n        }\n        content.push('\\n');\n    }\n}\n\npub fn resolve_required_layer_path(\n    required_layer: &str,\n    current_file: &Path,\n    directory: &DirectoryAnalysis,\n    root_path: &Path,\n) -> PathBuf {\n    let mut files = Vec::new();\n    collect_directory_files(directory, &mut files);\n    let candidates = files\n        .into_iter()\n        .filter(|path| {\n            path.file_name()\n                .and_then(|name| name.to_str())\n                .map(|name| name == required_layer)\n                .unwrap_or(false)\n        })\n        .collect::<Vec<_>>();\n    if candidates.is_empty() {\n        return current_file\n            .parent()\n            .unwrap_or(root_path)\n            .join(required_layer);\n    }\n\n    let current_dir = current_file.parent().unwrap_or(root_path);\n    let mut best = None;\n    let mut best_score = -1isize;\n    for candidate in candidates {\n        let candidate_dir = candidate.parent().unwrap_or(root_path);\n        let score = path_common_prefix_len(current_dir, candidate_dir);\n        let length = candidate.components().count() as isize;\n        let combined = score * 1000 - length;\n        if combined > best_score {\n            best_score = combined;\n            best = Some(candidate);\n        }\n    }\n    best.unwrap_or_else(|| {\n        current_file\n            .parent()\n            .unwrap_or(root_path)\n            .join(required_layer)\n    })\n}\n\npub fn collect_move_items(\n    placements: &[FunctionPlacement],\n    utility_names: &BTreeSet<String>,\n    directory: &DirectoryAnalysis,\n    root_path: &Path,\n) -> Vec<PlanItem> {\n    let mut items = Vec::new();\n    for placement in placements {\n        match &placement.placement_status {\n            PlacementStatus::ShouldMove { reason, impact } => {\n                let priority = if *impact >= 0.5 {\n                    Priority::Critical\n                } else if *impact >= 0.2 {\n                    Priority::High\n                } else if *impact >= 0.1 {\n                    Priority::Medium\n                } else {\n                    Priority::Low\n                };\n                let (impact_weight, benefit, cost, callers, caller_files, outgoing_files) =\n                    compute_move_metrics(placement);\n                let to = placement\n                    .suggested_file\n                    .as_ref()\n                    .map(|p| compress_path(p.to_string_lossy().as_ref()))\n                    .unwrap_or_else(|| \"-\".to_string());\n                items.push(PlanItem {\n                    kind: ActionKind::Cohesion,\n                    priority,\n                    description: format!(\n                        \"`{}` from `{}` to `{}`: {} (impact {:.2})\",\n                        placement.name,\n                        compress_path(placement.current_file.to_string_lossy().as_ref()),\n                        to,\n                        reason,\n                        impact\n                    ),\n                    command: String::new(),\n                    current_layer: None,\n                    required_layer: None,\n                    is_utility: utility_names.contains(&placement.name),\n                    impact_weight,\n                    benefit,\n                    cost,\n                    callers,\n                    caller_files,\n                    current_file: Some(placement.current_file.clone()),\n                    target_file: placement.suggested_file.clone(),\n                    outgoing_files,\n                    name: Some(placement.name.clone()),\n                    cluster_cohesion: 0.0,\n                    member_count: 0,\n                });\n            }\n            PlacementStatus::LayerViolation {\n                current_layer,\n                required_layer,\n            } => {\n                let target_path = resolve_required_layer_path(\n                    required_layer,\n                    &placement.current_file,\n                    directory,\n                    root_path,\n                );\n                let to = compress_path(target_path.to_string_lossy().as_ref());\n                let (impact_weight, benefit, cost, callers, caller_files, outgoing_files) =\n                    compute_move_metrics(placement);\n                items.push(PlanItem {\n                    kind: ActionKind::Structural,\n                    priority: Priority::Critical,\n                    description: format!(\n                        \"`{}` from `{}` to `{}`: layer violation {} -> {}\",\n                        placement.name,\n                        compress_path(placement.current_file.to_string_lossy().as_ref()),\n                        to,\n                        current_layer,\n                        required_layer\n                    ),\n                    command: String::new(),\n                    current_layer: Some(current_layer.clone()),\n                    required_layer: Some(required_layer.clone()),\n                    is_utility: utility_names.contains(&placement.name),\n                    impact_weight,\n                    benefit,\n                    cost,\n                    callers,\n                    caller_files,\n                    current_file: Some(placement.current_file.clone()),\n                    target_file: Some(target_path),\n                    outgoing_files,\n                    name: Some(placement.name.clone()),\n                    cluster_cohesion: 0.0,\n                    member_count: 0,\n                });\n            }\n            _ => {}\n        }\n    }\n    items\n}\n"
        }
      ],
      "applied": false,
      "errors": []
    }
  ]
}